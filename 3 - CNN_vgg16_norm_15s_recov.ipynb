{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK : CNN_vgg16_norm_cutting=15s recov for bulls detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guyot/miniconda3/envs/my_env/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "/home/guyot/miniconda3/envs/my_env/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torchaudio.set_audio_backend(\"sox_io\") # PG\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Code for big plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval of audios and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make panda dataframe with paths and labels of audio files\n",
    "\n",
    "def getAudioFiles(path_directory):\n",
    "        \n",
    "        files_path = []\n",
    "        files_name = []\n",
    "\n",
    "        for path, subdirs, files in os.walk(path_directory):\n",
    "            files.sort()\n",
    "            for name in files :\n",
    "                if name.endswith(\".wav\"):\n",
    "                    files_path.append(path + os.path.sep + name)\n",
    "        #print(\"-\", len(files_path), \"files found in the directory\", path_directory,'\\n')\n",
    "\n",
    "        return files_path\n",
    "    \n",
    "\n",
    "#folder_audio = \"C:/Users/thomas guerin/Documents/COURS IMT MINES ALES/Département 2IA/3A/S10/Etude technique/DATA/lgi2p-alose/tmp/bulls_audio/audio_out\"\n",
    "#folder_audio = \"/mnt/Baie-MD1400/data/guyot/dev/MRM/lgi2p-alose/tmp/bulls_audio/audio_out\"\n",
    "folder_audio = \"/mnt/Baie-MD1400/data/guyot/dev/MRM/EtudeTechnique2021/Alose2021/tmp/bulls_audio_recov/audio_out\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files_path = getAudioFiles(folder_audio)\n",
    "number = len(files_path)\n",
    "\n",
    "filenames = []\n",
    "dic_Labels = {}\n",
    "#pathOfLabels = \"C:/Users/thomas guerin/Documents/COURS IMT MINES ALES/Département 2IA/3A/S10/Etude technique/DATA/lgi2p-alose/tmp/bulls_audio/audio_annotated\"\n",
    "#pathOfLabels = \"/mnt/Baie-MD1400/data/guyot/dev/MRM/lgi2p-alose/tmp/bulls_audio/audio_annotated\"\n",
    "pathOfLabels = \"/mnt/Baie-MD1400/data/guyot/dev/MRM/EtudeTechnique2021/Alose2021/tmp/bulls_audio_recov/audio_annotated\"\n",
    "\n",
    "\n",
    "for path, subdirs, files in os.walk(pathOfLabels):\n",
    "    for filename in sorted(files) :\n",
    "        with open(os.path.join(pathOfLabels, filename),'r') as labels_file:\n",
    "            lines = labels_file.readlines()\n",
    "            labels_file.close()\n",
    "            for line in lines :\n",
    "                split_line = line.split(' ')\n",
    "                filenames.append(line)\n",
    "                file = split_line[0]\n",
    "                file_name, extension = os.path.splitext(file)\n",
    "                dic_Labels[file_name] = split_line[1][0]\n",
    "                \n",
    "y = np.zeros(number)\n",
    "for idx_file, file_path in enumerate(files_path):\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    y[idx_file] = int(dic_Labels[file_name])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of dataloaders (for the use of data \"on the fly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, files, labels, transform):\n",
    "    super(MyDataset,self).__init__()\n",
    "    self.files = files_path\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.files)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    wave = torchaudio.load(self.files[idx])[0] # Il faudrait déterminer les paramètres de transformation\n",
    "    melspectro = self.transform(wave)\n",
    "    label = self.labels[idx]\n",
    "    return melspectro,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_indexes(text):\n",
    "    l = []\n",
    "    n = len(files_path)\n",
    "    for i in range(n):\n",
    "        if text in files_path[i]:\n",
    "            l.append(i)\n",
    "    return [l[0],l[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for validation and test\n",
    "\n",
    "index_ceze_2017_p1 = return_indexes(text = \"2017_05_22-23_13_00\")\n",
    "\n",
    "index_ceze_2017_p2 = return_indexes(text = \"2017_05_24-23_15_00\")\n",
    "\n",
    "index_ceze_2017_p3 = return_indexes(text = \"2017_05_26-23_03_00\")\n",
    "\n",
    "index_ceze_2017_p4 = return_indexes(text = \"2017_06_01-23_20_00\")\n",
    "\n",
    "index_ceze_2018 = return_indexes(text = \"2018-06-10_22-25\")\n",
    "\n",
    "index_ardoise_2014_p1 = return_indexes(text = \"2014_05_24-01_41_10\")\n",
    "\n",
    "index_ardoise_2014_p2 = return_indexes(text = \"2014_05_24-23_14_00\")\n",
    "\n",
    "\n",
    "validation_index = list(range(index_ardoise_2014_p2[0]+1738,index_ardoise_2014_p2[1]+1)) + list(range(index_ceze_2017_p1[0],index_ceze_2017_p1[1]+1)) + list(range(index_ceze_2017_p2[0],index_ceze_2017_p2[1]+1)) + list(range(index_ceze_2017_p3[0],index_ceze_2017_p3[1]+1)) \n",
    "test_index = list(range(index_ardoise_2014_p1[0],index_ardoise_2014_p1[1]+1)) + list(range(index_ardoise_2014_p2[0],index_ardoise_2014_p2[0]+1738)) + list(range(index_ceze_2017_p4[0],index_ceze_2017_p4[1]+1)) + list(range(index_ceze_2018[0],index_ceze_2018[1]+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_importation_for_normalization(shuffle=True):\n",
    "    \n",
    "    # Transforming audio files into melspectrograms\n",
    "    transform = transforms.Compose([\n",
    "        torchaudio.transforms.MelSpectrogram(n_fft=4096, hop_length=4096//4),\n",
    "        transforms.Resize((128,646))\n",
    "    ]) \n",
    "    \n",
    "    df = MyDataset(files_path, y, transform)\n",
    "    \n",
    "    validation_indexes = validation_index\n",
    "    test_indexes = test_index\n",
    "    train_indexes = list( set(range(len(df))) - set(validation_indexes) - set(test_indexes) )\n",
    "    \n",
    "    train_set = torch.utils.data.Subset(df, train_indexes)\n",
    "    \n",
    "    trainloader = DataLoader(train_set, batch_size=3000, shuffle=shuffle, num_workers=0)\n",
    "    \n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "    x_train = audio_importation_for_normalization()\n",
    "    concat = torch.empty((0,646))\n",
    "    for elements in x_train:\n",
    "        for image in elements[0]:\n",
    "            concat = torch.cat((concat,image[0]),0)\n",
    "        break\n",
    "    mean = torch.mean(concat).item()\n",
    "    std = torch.std(concat,unbiased=False).item()\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_importation(shuffle=False):\n",
    "    \n",
    "    # Transforming audio files into melspectrograms\n",
    "    transform = transforms.Compose([\n",
    "        torchaudio.transforms.MelSpectrogram(n_fft=4096, hop_length=4096//4),\n",
    "        transforms.Resize((128,646)),\n",
    "        transforms.Normalize((normalize()[0],),(normalize()[1],))\n",
    "    ]) \n",
    "    \n",
    "    df = MyDataset(files_path, y, transform)\n",
    "    \n",
    "    validation_indexes = validation_index\n",
    "    test_indexes = test_index\n",
    "    train_indexes = list( set(range(len(df))) - set(validation_indexes) - set(test_indexes) )\n",
    "    \n",
    "\n",
    "    train_set = torch.utils.data.Subset(df, train_indexes)\n",
    "    validation_set = torch.utils.data.Subset(df, validation_indexes)\n",
    "    test_set = torch.utils.data.Subset(df, test_indexes)\n",
    "    \n",
    "    trainloader = DataLoader(train_set, batch_size=8, shuffle=shuffle, num_workers=0)\n",
    "    validationloader = DataLoader(validation_set, batch_size=8, shuffle=False, num_workers=0)\n",
    "    testloader = DataLoader(test_set, batch_size=8, shuffle=False, num_workers=0)\n",
    "    \n",
    "    bulls_proportion = (list(y[:train_indexes[-1]]).count(1))/len(train_indexes)\n",
    "    weight_bulls = 1 - bulls_proportion \n",
    "    weight_no_bulls = bulls_proportion\n",
    "    # Those weights will be used to manage the problem of unbalanced classes ( nb(no_bulls)>>nb(bulls) )\n",
    "    \n",
    "    return trainloader,validationloader,testloader,weight_bulls,weight_no_bulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_(pretrained):\n",
    "    vgg16 = models.vgg16(pretrained=pretrained)\n",
    "    return vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_vgg16_norm(torch.nn.Module):\n",
    "    def __init__(self, pretrained=False, freeze=False):\n",
    "        super(model_vgg16_norm, self).__init__()\n",
    "        vgg16 = vgg16_(pretrained=pretrained)\n",
    "        if freeze:\n",
    "            vgg16 = vgg16_(pretrained=True)\n",
    "            freeze_model(vgg16)\n",
    "        self.conv1 = torch.nn.Conv2d(1, 3, (1,1), stride=(1,1), padding=0, bias=True)\n",
    "        self.vgg16 = vgg16\n",
    "        self.drop1 = torch.nn.Dropout(0.3)\n",
    "        self.lin1 = torch.nn.Linear(in_features=1000, out_features=100, bias=True)\n",
    "        self.drop2 = torch.nn.Dropout(0.2)\n",
    "        self.lin2 = torch.nn.Linear(in_features=100, out_features=2, bias=True)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        x = F.relu(self.vgg16(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, name_model, device, epochs, learning_rate=1e-4, batch_size=128, early_stop_nb = 5):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    weight = torch.tensor([weight_no_bulls,weight_bulls])\n",
    "    weight = weight.to(device)\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='mean',weight=weight)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_score = 0\n",
    "    early_stop_count = 0\n",
    "    \n",
    "    epoch_improvement = [1]\n",
    "    \n",
    "    list_train_loss_cumul = []\n",
    "    list_metric = []\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        \n",
    "        model.train() # we specify that we are training the model\n",
    "        \n",
    "        # At each epoch, the training set will be processed as a set of batches\n",
    "        \n",
    "        # We use accumulated gradients ( ex: batch_size = 128 = 8 * (16 batches) ) to avoid memory pb\n",
    "        \n",
    "        accum_step = batch_size//8\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss_cumul = 0\n",
    "        \n",
    "        for batch_id,  batch in enumerate(trainloader) :\n",
    "            \n",
    "            images, labels  = batch\n",
    "            \n",
    "            labels = labels.long()\n",
    "            \n",
    "            bulls = torch.tensor([1 for i in range(labels.shape[0])])\n",
    "            no_bulls = torch.tensor([0 for i in range(labels.shape[0])])\n",
    "            bulls = bulls.to(device)\n",
    "            no_bulls = no_bulls.to(device)\n",
    "            \n",
    "            # we put the data on the same device\n",
    "            images , labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            y_pred = model(images) # forward pass output=logits\n",
    "            \n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            \n",
    "            loss /= accum_step  # Because the cross entropy loss is a mean\n",
    "            \n",
    "            train_loss_cumul += loss.item()\n",
    "            \n",
    "            loss.backward(retain_graph=True)       # update the gradient (cf https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa#:~:text=Gradient%20accumulation%20means%20running%20a,Yes%2C%20it's%20really%20that%20simple.)\n",
    "            \n",
    "            if ( ( (batch_id + 1) % accum_step == 0 ) or ( (batch_id + 1) == len(trainloader)  ) ):\n",
    "                \n",
    "                optimizer.step() # update the model parameters using the gradient\n",
    "                \n",
    "                optimizer.zero_grad() # clear the gradient before backward\n",
    "                \n",
    "                print(\"epoch: {:03d}, batch: {:03d}, loss: {:.3f} \".format(t+1, ceil((batch_id+1)/accum_step), loss.item()*accum_step))\n",
    "                #print(\"e: {:03d}, b: {:03d}, l: {:.3f} \".format(t+1, (batch_id+1)//accum_step, loss.item()*accum_step), end='')\n",
    "                \n",
    "                \n",
    "        \n",
    "        # Training score\n",
    "        \n",
    "        list_train_loss_cumul.append(train_loss_cumul)\n",
    "            \n",
    "        print(\"epoch: {:03d} ------------------------------------------------\".format(t+1)+ \"\\n\")\n",
    "        print(\"[train] loss: {:.3f}\\n\".format(train_loss_cumul))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Validation score\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        total_real_bulls = 0\n",
    "        total_real_no_bulls = 0\n",
    "        correct_real_bulls = 0\n",
    "        correct_real_no_bulls = 0\n",
    "        \n",
    "        for batch_id, batch in enumerate(validationloader):\n",
    "            \n",
    "            images , labels = batch\n",
    "            \n",
    "            labels = labels.long() # float --> Long\n",
    "            \n",
    "            bulls = torch.tensor([1 for i in range(labels.shape[0])])\n",
    "            no_bulls = torch.tensor([0 for i in range(labels.shape[0])])\n",
    "            bulls = bulls.to(device)\n",
    "            no_bulls = no_bulls.to(device)\n",
    "            \n",
    "            images , labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            y_pred = model(images) # forward computes the logits\n",
    "            sf_y_pred = torch.nn.Softmax(dim=1)(y_pred) # softmax to obtain the probability distribution\n",
    "            _, predicted = torch.max(sf_y_pred , 1)     # decision rule, we select the max\n",
    "            \n",
    "            total_real_bulls += (labels == bulls).sum().item()\n",
    "            total_real_no_bulls += (labels == no_bulls).sum().item()\n",
    "            correct_real_bulls += ( (predicted == labels) & (labels == bulls) ).sum().item()\n",
    "            correct_real_no_bulls += ( (predicted == labels) & (labels == no_bulls) ).sum().item()\n",
    "        \n",
    "            \n",
    "        bulls_recall = correct_real_bulls / (total_real_bulls + 0.01)\n",
    "            \n",
    "        no_bulls_recall = correct_real_no_bulls / (total_real_no_bulls + 0.01)\n",
    "        \n",
    "        metric = (bulls_recall + no_bulls_recall)/2\n",
    "        \n",
    "        list_metric.append(metric)\n",
    "            \n",
    "        print(\"[validation] bulls_recall: {:.3f}%\\n\".format(100*bulls_recall))\n",
    "        print(\"[validation] no_bulls_recall: {:.3f}%\\n\".format(100*no_bulls_recall))\n",
    "        print(\"[validation] scoring metric (average recall): \" + str(metric) + \"\\n\")\n",
    "        \n",
    "        \n",
    "        # Early Stopping\n",
    "        \n",
    "        val_score = metric\n",
    "        \n",
    "        if val_score >= best_score:\n",
    "            best_score = val_score\n",
    "            early_stop_count = 0\n",
    "            path = name_model + \"__epoch\" + str(epoch_improvement[-1]) + \".pth\"\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            epoch_improvement.append(t+1)\n",
    "            new_path = name_model + \"__epoch\" + str(epoch_improvement[-1]) + \".pth\"\n",
    "            torch.save(model, new_path)\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "        if early_stop_count == early_stop_nb:\n",
    "            break\n",
    "        \n",
    "    print(\"\\n\" + \"Final nb epochs : \" + str(epoch_improvement[-1]))\n",
    "    print(\"Best validation score (= best bulls_fscore) : \" + str(best_score))\n",
    "    \n",
    "    \n",
    "    # We plot graphs for training and validation errors\n",
    "    \n",
    "    num_epochs = list(range(1,t+2))\n",
    "    \n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"training loss\")\n",
    "    plt.plot(num_epochs, list_train_loss_cumul)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"metric (on validation dataset)\")\n",
    "    plt.plot(num_epochs, list_metric)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # We return the best model\n",
    "    \n",
    "    model = torch.load(new_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total_real_bulls = 0\n",
    "    total_real_no_bulls = 0\n",
    "    total_predicted_bulls = 0\n",
    "    total_predicted_no_bulls = 0\n",
    "    correct_bulls = 0\n",
    "    correct_no_bulls = 0\n",
    "    \n",
    "    for batch_id, batch in enumerate(testloader):\n",
    "        \n",
    "        images , labels = batch\n",
    "        \n",
    "        bulls = torch.tensor([1 for i in range(labels.shape[0])])\n",
    "        no_bulls = torch.tensor([0 for i in range(labels.shape[0])])\n",
    "        \n",
    "        bulls = bulls.to(device)\n",
    "        no_bulls = no_bulls.to(device)\n",
    "        \n",
    "        labels = labels.long() # float --> Long\n",
    "        \n",
    "        images , labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        y_pred = model(images) # forward computes the logits\n",
    "        sf_y_pred = torch.nn.Softmax(dim=1)(y_pred) # softmax to obtain the probability distribution\n",
    "        _, predicted = torch.max(sf_y_pred , 1)     # decision rule, we select the max\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_real_bulls += (labels == bulls).sum().item()\n",
    "        total_real_no_bulls += (labels == no_bulls).sum().item()\n",
    "        total_predicted_bulls += (predicted == bulls).sum().item()\n",
    "        total_predicted_no_bulls += (predicted == no_bulls).sum().item()\n",
    "        correct_bulls += ( (predicted == labels) & (labels == bulls) ).sum().item()\n",
    "        correct_no_bulls += ( (predicted == labels) & (labels == no_bulls) ).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    \n",
    "    bulls_recall = correct_bulls / (total_real_bulls + 0.01)\n",
    "    bulls_precision = correct_bulls / (total_predicted_bulls + 0.01)\n",
    "    \n",
    "    no_bulls_recall = correct_no_bulls / (total_real_no_bulls + 0.01)\n",
    "    no_bulls_precision = correct_no_bulls / (total_predicted_no_bulls + 0.01)\n",
    "    \n",
    "    metric = (bulls_recall + no_bulls_recall)/2\n",
    "    \n",
    "    print(\"Confusion matrix (rows : real (no_bulls and bulls)  ;  columns : predicted (same) ): \")\n",
    "    print(str(correct_bulls) + \"  |  \" + str(total_real_bulls - correct_bulls))\n",
    "    print(str(total_real_no_bulls - correct_no_bulls) + \"  |  \" + str(correct_no_bulls) + \"\\n\")\n",
    "    print(\"[test] accuracy: {:.3f}%\\n\".format(100*accuracy) + \"\\n\")\n",
    "    print(\"[test] bulls_recall: {:.3f}%\\n\".format(100*bulls_recall))\n",
    "    print(\"[test] bulls_precision: {:.3f}%\\n\".format(100*bulls_precision) + \"\\n\")\n",
    "    print(\"[test] no_bulls_recall: {:.3f}%\\n\".format(100*no_bulls_recall))\n",
    "    print(\"[test] no_bulls_precision: {:.3f}%\\n\".format(100*no_bulls_precision) + \"\\n\")\n",
    "    print(\"[test] scoring metric (average recall): \" + str(metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guyot/miniconda3/envs/my_env/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/guyot/miniconda3/envs/my_env/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001, batch: 001, loss: 0.600 \n",
      "epoch: 001, batch: 002, loss: 0.447 \n",
      "epoch: 001, batch: 003, loss: 0.321 \n",
      "epoch: 001, batch: 004, loss: 0.238 \n",
      "epoch: 001, batch: 005, loss: 0.224 \n",
      "epoch: 001, batch: 006, loss: 0.727 \n",
      "epoch: 001, batch: 007, loss: 0.208 \n",
      "epoch: 001, batch: 008, loss: 0.311 \n",
      "epoch: 001, batch: 009, loss: 0.322 \n",
      "epoch: 001, batch: 010, loss: 0.794 \n",
      "epoch: 001, batch: 011, loss: 0.316 \n",
      "epoch: 001, batch: 012, loss: 0.233 \n",
      "epoch: 001, batch: 013, loss: 0.198 \n",
      "epoch: 001, batch: 014, loss: 0.080 \n",
      "epoch: 001, batch: 015, loss: 0.159 \n",
      "epoch: 001, batch: 016, loss: 0.331 \n",
      "epoch: 001, batch: 017, loss: 0.286 \n",
      "epoch: 001, batch: 018, loss: 0.127 \n",
      "epoch: 001, batch: 019, loss: 0.115 \n",
      "epoch: 001, batch: 020, loss: 1.147 \n",
      "epoch: 001, batch: 021, loss: 0.244 \n",
      "epoch: 001, batch: 022, loss: 0.229 \n",
      "epoch: 001, batch: 023, loss: 0.313 \n",
      "epoch: 001, batch: 024, loss: 1.358 \n",
      "epoch: 001, batch: 025, loss: 0.738 \n",
      "epoch: 001, batch: 026, loss: 0.181 \n",
      "epoch: 001, batch: 027, loss: 0.209 \n",
      "epoch: 001, batch: 028, loss: 1.617 \n",
      "epoch: 001, batch: 029, loss: 0.201 \n",
      "epoch: 001, batch: 030, loss: 0.178 \n",
      "epoch: 001, batch: 031, loss: 0.122 \n",
      "epoch: 001, batch: 032, loss: 0.237 \n",
      "epoch: 001, batch: 033, loss: 0.515 \n",
      "epoch: 001, batch: 034, loss: 0.490 \n",
      "epoch: 001, batch: 035, loss: 0.310 \n",
      "epoch: 001, batch: 036, loss: 0.369 \n",
      "epoch: 001, batch: 037, loss: 0.066 \n",
      "epoch: 001, batch: 038, loss: 0.131 \n",
      "epoch: 001, batch: 039, loss: 0.043 \n",
      "epoch: 001, batch: 040, loss: 0.043 \n",
      "epoch: 001, batch: 041, loss: 2.067 \n",
      "epoch: 001, batch: 042, loss: 0.135 \n",
      "epoch: 001, batch: 043, loss: 0.236 \n",
      "epoch: 001, batch: 044, loss: 0.115 \n",
      "epoch: 001, batch: 045, loss: 0.180 \n",
      "epoch: 001, batch: 046, loss: 0.226 \n",
      "epoch: 001, batch: 047, loss: 0.178 \n",
      "epoch: 001, batch: 048, loss: 0.343 \n",
      "epoch: 001, batch: 049, loss: 0.428 \n",
      "epoch: 001, batch: 050, loss: 0.183 \n",
      "epoch: 001, batch: 051, loss: 0.103 \n",
      "epoch: 001, batch: 052, loss: 1.319 \n",
      "epoch: 001, batch: 053, loss: 1.009 \n",
      "epoch: 001, batch: 054, loss: 1.081 \n",
      "epoch: 001, batch: 055, loss: 0.208 \n",
      "epoch: 001, batch: 056, loss: 0.110 \n",
      "epoch: 001, batch: 057, loss: 0.094 \n",
      "epoch: 001, batch: 058, loss: 1.788 \n",
      "epoch: 001, batch: 059, loss: 0.069 \n",
      "epoch: 001, batch: 060, loss: 0.269 \n",
      "epoch: 001, batch: 061, loss: 0.075 \n",
      "epoch: 001, batch: 062, loss: 0.259 \n",
      "epoch: 001, batch: 063, loss: 0.218 \n",
      "epoch: 001, batch: 064, loss: 0.300 \n",
      "epoch: 001, batch: 065, loss: 0.215 \n",
      "epoch: 001, batch: 066, loss: 0.188 \n",
      "epoch: 001, batch: 067, loss: 0.219 \n",
      "epoch: 001, batch: 068, loss: 0.093 \n",
      "epoch: 001, batch: 069, loss: 0.044 \n",
      "epoch: 001, batch: 070, loss: 0.053 \n",
      "epoch: 001, batch: 071, loss: 0.019 \n",
      "epoch: 001, batch: 072, loss: 0.084 \n",
      "epoch: 001, batch: 073, loss: 0.213 \n",
      "epoch: 001, batch: 074, loss: 0.167 \n",
      "epoch: 001, batch: 075, loss: 0.088 \n",
      "epoch: 001, batch: 076, loss: 0.078 \n",
      "epoch: 001, batch: 077, loss: 0.224 \n",
      "epoch: 001, batch: 078, loss: 0.055 \n",
      "epoch: 001, batch: 079, loss: 0.518 \n",
      "epoch: 001, batch: 080, loss: 0.053 \n",
      "epoch: 001, batch: 081, loss: 0.085 \n",
      "epoch: 001, batch: 082, loss: 0.112 \n",
      "epoch: 001, batch: 083, loss: 0.077 \n",
      "epoch: 001, batch: 084, loss: 1.242 \n",
      "epoch: 001, batch: 085, loss: 0.121 \n",
      "epoch: 001, batch: 086, loss: 0.194 \n",
      "epoch: 001, batch: 087, loss: 0.262 \n",
      "epoch: 001, batch: 088, loss: 0.364 \n",
      "epoch: 001, batch: 089, loss: 0.468 \n",
      "epoch: 001, batch: 090, loss: 0.146 \n",
      "epoch: 001, batch: 091, loss: 0.184 \n",
      "epoch: 001, batch: 092, loss: 1.071 \n",
      "epoch: 001, batch: 093, loss: 0.043 \n",
      "epoch: 001, batch: 094, loss: 0.036 \n",
      "epoch: 001, batch: 095, loss: 0.011 \n",
      "epoch: 001, batch: 096, loss: 0.114 \n",
      "epoch: 001, batch: 097, loss: 0.166 \n",
      "epoch: 001, batch: 098, loss: 0.047 \n",
      "epoch: 001, batch: 099, loss: 1.447 \n",
      "epoch: 001, batch: 100, loss: 1.427 \n",
      "epoch: 001, batch: 101, loss: 0.012 \n",
      "epoch: 001, batch: 102, loss: 0.432 \n",
      "epoch: 001, batch: 103, loss: 0.202 \n",
      "epoch: 001, batch: 104, loss: 0.051 \n",
      "epoch: 001, batch: 105, loss: 0.130 \n",
      "epoch: 001, batch: 106, loss: 0.458 \n",
      "epoch: 001, batch: 107, loss: 0.136 \n",
      "epoch: 001, batch: 108, loss: 0.090 \n",
      "epoch: 001, batch: 109, loss: 0.187 \n",
      "epoch: 001, batch: 110, loss: 1.026 \n",
      "epoch: 001, batch: 111, loss: 0.046 \n",
      "epoch: 001, batch: 112, loss: 0.334 \n",
      "epoch: 001, batch: 113, loss: 0.042 \n",
      "epoch: 001, batch: 114, loss: 0.022 \n",
      "epoch: 001, batch: 115, loss: 0.167 \n",
      "epoch: 001, batch: 116, loss: 0.092 \n",
      "epoch: 001, batch: 117, loss: 0.107 \n",
      "epoch: 001, batch: 118, loss: 0.064 \n",
      "epoch: 001, batch: 119, loss: 0.146 \n",
      "epoch: 001, batch: 120, loss: 0.026 \n",
      "epoch: 001, batch: 121, loss: 0.035 \n",
      "epoch: 001, batch: 122, loss: 0.088 \n",
      "epoch: 001, batch: 123, loss: 0.099 \n",
      "epoch: 001, batch: 124, loss: 0.073 \n",
      "epoch: 001, batch: 125, loss: 1.094 \n",
      "epoch: 001, batch: 126, loss: 0.137 \n",
      "epoch: 001, batch: 127, loss: 0.023 \n",
      "epoch: 001, batch: 128, loss: 0.052 \n",
      "epoch: 001, batch: 129, loss: 0.010 \n",
      "epoch: 001, batch: 130, loss: 0.015 \n",
      "epoch: 001, batch: 131, loss: 0.058 \n",
      "epoch: 001, batch: 132, loss: 0.143 \n",
      "epoch: 001, batch: 133, loss: 0.077 \n",
      "epoch: 001, batch: 134, loss: 0.130 \n",
      "epoch: 001, batch: 135, loss: 0.141 \n",
      "epoch: 001, batch: 136, loss: 0.044 \n",
      "epoch: 001, batch: 137, loss: 0.088 \n",
      "epoch: 001, batch: 138, loss: 0.043 \n",
      "epoch: 001, batch: 139, loss: 0.133 \n",
      "epoch: 001, batch: 140, loss: 2.127 \n",
      "epoch: 001, batch: 141, loss: 0.017 \n",
      "epoch: 001, batch: 142, loss: 0.209 \n",
      "epoch: 001, batch: 143, loss: 0.111 \n",
      "epoch: 001, batch: 144, loss: 0.294 \n",
      "epoch: 001, batch: 145, loss: 0.037 \n",
      "epoch: 001, batch: 146, loss: 0.047 \n",
      "epoch: 001, batch: 147, loss: 0.146 \n",
      "epoch: 001, batch: 148, loss: 0.039 \n",
      "epoch: 001, batch: 149, loss: 0.227 \n",
      "epoch: 001, batch: 150, loss: 1.521 \n",
      "epoch: 001, batch: 151, loss: 0.095 \n",
      "epoch: 001, batch: 152, loss: 0.072 \n",
      "epoch: 001, batch: 153, loss: 0.099 \n",
      "epoch: 001, batch: 154, loss: 0.067 \n",
      "epoch: 001, batch: 155, loss: 0.237 \n",
      "epoch: 001, batch: 156, loss: 0.065 \n",
      "epoch: 001, batch: 157, loss: 0.070 \n",
      "epoch: 001, batch: 158, loss: 0.088 \n",
      "epoch: 001, batch: 159, loss: 0.085 \n",
      "epoch: 001, batch: 160, loss: 0.042 \n",
      "epoch: 001, batch: 161, loss: 0.078 \n",
      "epoch: 001, batch: 162, loss: 0.097 \n",
      "epoch: 001, batch: 163, loss: 0.111 \n",
      "epoch: 001, batch: 164, loss: 0.015 \n",
      "epoch: 001, batch: 165, loss: 0.031 \n",
      "epoch: 001, batch: 166, loss: 0.024 \n",
      "epoch: 001, batch: 167, loss: 0.014 \n",
      "epoch: 001, batch: 168, loss: 0.813 \n",
      "epoch: 001, batch: 169, loss: 0.165 \n",
      "epoch: 001, batch: 170, loss: 0.032 \n",
      "epoch: 001, batch: 171, loss: 0.058 \n",
      "epoch: 001, batch: 172, loss: 0.071 \n",
      "epoch: 001, batch: 173, loss: 0.141 \n",
      "epoch: 001, batch: 174, loss: 1.088 \n",
      "epoch: 001, batch: 175, loss: 0.160 \n",
      "epoch: 001, batch: 176, loss: 0.231 \n",
      "epoch: 001, batch: 177, loss: 0.049 \n",
      "epoch: 001, batch: 178, loss: 0.210 \n",
      "epoch: 001, batch: 179, loss: 0.057 \n",
      "epoch: 001, batch: 180, loss: 0.009 \n",
      "epoch: 001, batch: 181, loss: 0.013 \n",
      "epoch: 001, batch: 182, loss: 3.629 \n",
      "epoch: 001, batch: 183, loss: 0.485 \n",
      "epoch: 001, batch: 184, loss: 0.031 \n",
      "epoch: 001, batch: 185, loss: 0.179 \n",
      "epoch: 001, batch: 186, loss: 0.082 \n",
      "epoch: 001, batch: 187, loss: 0.151 \n",
      "epoch: 001, batch: 188, loss: 0.168 \n",
      "epoch: 001, batch: 189, loss: 0.102 \n",
      "epoch: 001, batch: 190, loss: 0.037 \n",
      "epoch: 001, batch: 191, loss: 0.373 \n",
      "epoch: 001, batch: 192, loss: 0.068 \n",
      "epoch: 001, batch: 193, loss: 0.020 \n",
      "epoch: 001, batch: 194, loss: 0.010 \n",
      "epoch: 001, batch: 195, loss: 0.146 \n",
      "epoch: 001, batch: 196, loss: 0.145 \n",
      "epoch: 001, batch: 197, loss: 0.281 \n",
      "epoch: 001, batch: 198, loss: 0.077 \n",
      "epoch: 001, batch: 199, loss: 0.209 \n",
      "epoch: 001, batch: 200, loss: 0.159 \n",
      "epoch: 001, batch: 201, loss: 0.137 \n",
      "epoch: 001, batch: 202, loss: 0.223 \n",
      "epoch: 001, batch: 203, loss: 0.767 \n",
      "epoch: 001, batch: 204, loss: 0.027 \n",
      "epoch: 001, batch: 205, loss: 3.563 \n",
      "epoch: 001, batch: 206, loss: 1.674 \n",
      "epoch: 001, batch: 207, loss: 0.537 \n",
      "epoch: 001, batch: 208, loss: 0.110 \n",
      "epoch: 001, batch: 209, loss: 0.029 \n",
      "epoch: 001, batch: 210, loss: 0.109 \n",
      "epoch: 001, batch: 211, loss: 0.061 \n",
      "epoch: 001, batch: 212, loss: 0.080 \n",
      "epoch: 001, batch: 213, loss: 0.541 \n",
      "epoch: 001, batch: 214, loss: 0.099 \n",
      "epoch: 001, batch: 215, loss: 0.171 \n",
      "epoch: 001, batch: 216, loss: 0.159 \n",
      "epoch: 001, batch: 217, loss: 0.247 \n",
      "epoch: 001, batch: 218, loss: 0.208 \n",
      "epoch: 001, batch: 219, loss: 0.233 \n",
      "epoch: 001, batch: 220, loss: 0.146 \n",
      "epoch: 001, batch: 221, loss: 0.127 \n",
      "epoch: 001, batch: 222, loss: 0.106 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001, batch: 223, loss: 0.293 \n",
      "epoch: 001, batch: 224, loss: 0.127 \n",
      "epoch: 001, batch: 225, loss: 0.092 \n",
      "epoch: 001, batch: 226, loss: 0.019 \n",
      "epoch: 001, batch: 227, loss: 0.000 \n",
      "epoch: 001 ------------------------------------------------\n",
      "\n",
      "[train] loss: 74.997\n",
      "\n",
      "[validation] bulls_recall: 96.076%\n",
      "\n",
      "[validation] no_bulls_recall: 12.740%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5440796186808827\n",
      "\n",
      "epoch: 002, batch: 001, loss: 0.024 \n",
      "epoch: 002, batch: 002, loss: 0.111 \n",
      "epoch: 002, batch: 003, loss: 0.026 \n",
      "epoch: 002, batch: 004, loss: 0.396 \n",
      "epoch: 002, batch: 005, loss: 0.209 \n",
      "epoch: 002, batch: 006, loss: 0.120 \n",
      "epoch: 002, batch: 007, loss: 0.191 \n",
      "epoch: 002, batch: 008, loss: 0.106 \n",
      "epoch: 002, batch: 009, loss: 0.114 \n",
      "epoch: 002, batch: 010, loss: 0.186 \n",
      "epoch: 002, batch: 011, loss: 0.957 \n",
      "epoch: 002, batch: 012, loss: 0.178 \n",
      "epoch: 002, batch: 013, loss: 0.420 \n",
      "epoch: 002, batch: 014, loss: 1.315 \n",
      "epoch: 002, batch: 015, loss: 0.173 \n",
      "epoch: 002, batch: 016, loss: 0.159 \n",
      "epoch: 002, batch: 017, loss: 0.051 \n",
      "epoch: 002, batch: 018, loss: 0.042 \n",
      "epoch: 002, batch: 019, loss: 0.296 \n",
      "epoch: 002, batch: 020, loss: 1.325 \n",
      "epoch: 002, batch: 021, loss: 0.178 \n",
      "epoch: 002, batch: 022, loss: 0.131 \n",
      "epoch: 002, batch: 023, loss: 0.282 \n",
      "epoch: 002, batch: 024, loss: 0.708 \n",
      "epoch: 002, batch: 025, loss: 0.087 \n",
      "epoch: 002, batch: 026, loss: 0.278 \n",
      "epoch: 002, batch: 027, loss: 0.227 \n",
      "epoch: 002, batch: 028, loss: 0.182 \n",
      "epoch: 002, batch: 029, loss: 0.205 \n",
      "epoch: 002, batch: 030, loss: 1.218 \n",
      "epoch: 002, batch: 031, loss: 0.676 \n",
      "epoch: 002, batch: 032, loss: 0.426 \n",
      "epoch: 002, batch: 033, loss: 0.414 \n",
      "epoch: 002, batch: 034, loss: 0.437 \n",
      "epoch: 002, batch: 035, loss: 0.039 \n",
      "epoch: 002, batch: 036, loss: 0.043 \n",
      "epoch: 002, batch: 037, loss: 0.609 \n",
      "epoch: 002, batch: 038, loss: 2.656 \n",
      "epoch: 002, batch: 039, loss: 0.025 \n",
      "epoch: 002, batch: 040, loss: 0.230 \n",
      "epoch: 002, batch: 041, loss: 0.190 \n",
      "epoch: 002, batch: 042, loss: 0.207 \n",
      "epoch: 002, batch: 043, loss: 0.242 \n",
      "epoch: 002, batch: 044, loss: 0.206 \n",
      "epoch: 002, batch: 045, loss: 0.197 \n",
      "epoch: 002, batch: 046, loss: 0.081 \n",
      "epoch: 002, batch: 047, loss: 0.007 \n",
      "epoch: 002, batch: 048, loss: 0.012 \n",
      "epoch: 002, batch: 049, loss: 0.019 \n",
      "epoch: 002, batch: 050, loss: 0.171 \n",
      "epoch: 002, batch: 051, loss: 0.254 \n",
      "epoch: 002, batch: 052, loss: 0.061 \n",
      "epoch: 002, batch: 053, loss: 0.088 \n",
      "epoch: 002, batch: 054, loss: 0.352 \n",
      "epoch: 002, batch: 055, loss: 0.133 \n",
      "epoch: 002, batch: 056, loss: 0.006 \n",
      "epoch: 002, batch: 057, loss: 2.220 \n",
      "epoch: 002, batch: 058, loss: 0.023 \n",
      "epoch: 002, batch: 059, loss: 0.081 \n",
      "epoch: 002, batch: 060, loss: 0.056 \n",
      "epoch: 002, batch: 061, loss: 0.048 \n",
      "epoch: 002, batch: 062, loss: 0.132 \n",
      "epoch: 002, batch: 063, loss: 0.081 \n",
      "epoch: 002, batch: 064, loss: 0.130 \n",
      "epoch: 002, batch: 065, loss: 0.062 \n",
      "epoch: 002, batch: 066, loss: 0.073 \n",
      "epoch: 002, batch: 067, loss: 1.130 \n",
      "epoch: 002, batch: 068, loss: 0.051 \n",
      "epoch: 002, batch: 069, loss: 0.101 \n",
      "epoch: 002, batch: 070, loss: 0.112 \n",
      "epoch: 002, batch: 071, loss: 0.348 \n",
      "epoch: 002, batch: 072, loss: 0.244 \n",
      "epoch: 002, batch: 073, loss: 0.121 \n",
      "epoch: 002, batch: 074, loss: 0.244 \n",
      "epoch: 002, batch: 075, loss: 0.044 \n",
      "epoch: 002, batch: 076, loss: 0.004 \n",
      "epoch: 002, batch: 077, loss: 0.308 \n",
      "epoch: 002, batch: 078, loss: 0.029 \n",
      "epoch: 002, batch: 079, loss: 0.070 \n",
      "epoch: 002, batch: 080, loss: 0.135 \n",
      "epoch: 002, batch: 081, loss: 0.008 \n",
      "epoch: 002, batch: 082, loss: 0.165 \n",
      "epoch: 002, batch: 083, loss: 0.041 \n",
      "epoch: 002, batch: 084, loss: 0.073 \n",
      "epoch: 002, batch: 085, loss: 0.467 \n",
      "epoch: 002, batch: 086, loss: 0.064 \n",
      "epoch: 002, batch: 087, loss: 0.145 \n",
      "epoch: 002, batch: 088, loss: 0.412 \n",
      "epoch: 002, batch: 089, loss: 0.097 \n",
      "epoch: 002, batch: 090, loss: 0.035 \n",
      "epoch: 002, batch: 091, loss: 0.037 \n",
      "epoch: 002, batch: 092, loss: 0.013 \n",
      "epoch: 002, batch: 093, loss: 0.115 \n",
      "epoch: 002, batch: 094, loss: 0.218 \n",
      "epoch: 002, batch: 095, loss: 0.047 \n",
      "epoch: 002, batch: 096, loss: 0.315 \n",
      "epoch: 002, batch: 097, loss: 0.048 \n",
      "epoch: 002, batch: 098, loss: 0.018 \n",
      "epoch: 002, batch: 099, loss: 0.083 \n",
      "epoch: 002, batch: 100, loss: 0.034 \n",
      "epoch: 002, batch: 101, loss: 1.069 \n",
      "epoch: 002, batch: 102, loss: 0.279 \n",
      "epoch: 002, batch: 103, loss: 0.124 \n",
      "epoch: 002, batch: 104, loss: 0.103 \n",
      "epoch: 002, batch: 105, loss: 0.153 \n",
      "epoch: 002, batch: 106, loss: 0.074 \n",
      "epoch: 002, batch: 107, loss: 0.278 \n",
      "epoch: 002, batch: 108, loss: 0.108 \n",
      "epoch: 002, batch: 109, loss: 0.069 \n",
      "epoch: 002, batch: 110, loss: 0.639 \n",
      "epoch: 002, batch: 111, loss: 0.178 \n",
      "epoch: 002, batch: 112, loss: 0.195 \n",
      "epoch: 002, batch: 113, loss: 0.135 \n",
      "epoch: 002, batch: 114, loss: 0.151 \n",
      "epoch: 002, batch: 115, loss: 0.192 \n",
      "epoch: 002, batch: 116, loss: 0.151 \n",
      "epoch: 002, batch: 117, loss: 0.027 \n",
      "epoch: 002, batch: 118, loss: 0.451 \n",
      "epoch: 002, batch: 119, loss: 0.008 \n",
      "epoch: 002, batch: 120, loss: 0.040 \n",
      "epoch: 002, batch: 121, loss: 0.115 \n",
      "epoch: 002, batch: 122, loss: 0.207 \n",
      "epoch: 002, batch: 123, loss: 0.098 \n",
      "epoch: 002, batch: 124, loss: 0.156 \n",
      "epoch: 002, batch: 125, loss: 0.034 \n",
      "epoch: 002, batch: 126, loss: 0.042 \n",
      "epoch: 002, batch: 127, loss: 0.023 \n",
      "epoch: 002, batch: 128, loss: 0.152 \n",
      "epoch: 002, batch: 129, loss: 0.129 \n",
      "epoch: 002, batch: 130, loss: 0.220 \n",
      "epoch: 002, batch: 131, loss: 0.088 \n",
      "epoch: 002, batch: 132, loss: 0.234 \n",
      "epoch: 002, batch: 133, loss: 0.121 \n",
      "epoch: 002, batch: 134, loss: 0.128 \n",
      "epoch: 002, batch: 135, loss: 0.209 \n",
      "epoch: 002, batch: 136, loss: 0.062 \n",
      "epoch: 002, batch: 137, loss: 0.091 \n",
      "epoch: 002, batch: 138, loss: 0.052 \n",
      "epoch: 002, batch: 139, loss: 0.081 \n",
      "epoch: 002, batch: 140, loss: 0.318 \n",
      "epoch: 002, batch: 141, loss: 0.049 \n",
      "epoch: 002, batch: 142, loss: 0.119 \n",
      "epoch: 002, batch: 143, loss: 1.287 \n",
      "epoch: 002, batch: 144, loss: 0.058 \n",
      "epoch: 002, batch: 145, loss: 0.311 \n",
      "epoch: 002, batch: 146, loss: 0.103 \n",
      "epoch: 002, batch: 147, loss: 0.112 \n",
      "epoch: 002, batch: 148, loss: 0.050 \n",
      "epoch: 002, batch: 149, loss: 0.043 \n",
      "epoch: 002, batch: 150, loss: 0.052 \n",
      "epoch: 002, batch: 151, loss: 0.974 \n",
      "epoch: 002, batch: 152, loss: 0.056 \n",
      "epoch: 002, batch: 153, loss: 0.058 \n",
      "epoch: 002, batch: 154, loss: 0.035 \n",
      "epoch: 002, batch: 155, loss: 0.017 \n",
      "epoch: 002, batch: 156, loss: 1.008 \n",
      "epoch: 002, batch: 157, loss: 0.135 \n",
      "epoch: 002, batch: 158, loss: 0.499 \n",
      "epoch: 002, batch: 159, loss: 0.306 \n",
      "epoch: 002, batch: 160, loss: 0.108 \n",
      "epoch: 002, batch: 161, loss: 0.043 \n",
      "epoch: 002, batch: 162, loss: 0.033 \n",
      "epoch: 002, batch: 163, loss: 0.039 \n",
      "epoch: 002, batch: 164, loss: 0.024 \n",
      "epoch: 002, batch: 165, loss: 0.006 \n",
      "epoch: 002, batch: 166, loss: 0.514 \n",
      "epoch: 002, batch: 167, loss: 0.077 \n",
      "epoch: 002, batch: 168, loss: 0.279 \n",
      "epoch: 002, batch: 169, loss: 0.100 \n",
      "epoch: 002, batch: 170, loss: 0.534 \n",
      "epoch: 002, batch: 171, loss: 0.180 \n",
      "epoch: 002, batch: 172, loss: 0.019 \n",
      "epoch: 002, batch: 173, loss: 0.020 \n",
      "epoch: 002, batch: 174, loss: 0.072 \n",
      "epoch: 002, batch: 175, loss: 0.009 \n",
      "epoch: 002, batch: 176, loss: 0.004 \n",
      "epoch: 002, batch: 177, loss: 0.003 \n",
      "epoch: 002, batch: 178, loss: 0.061 \n",
      "epoch: 002, batch: 179, loss: 0.122 \n",
      "epoch: 002, batch: 180, loss: 0.082 \n",
      "epoch: 002, batch: 181, loss: 0.271 \n",
      "epoch: 002, batch: 182, loss: 0.565 \n",
      "epoch: 002, batch: 183, loss: 0.033 \n",
      "epoch: 002, batch: 184, loss: 0.032 \n",
      "epoch: 002, batch: 185, loss: 0.049 \n",
      "epoch: 002, batch: 186, loss: 0.018 \n",
      "epoch: 002, batch: 187, loss: 0.009 \n",
      "epoch: 002, batch: 188, loss: 2.193 \n",
      "epoch: 002, batch: 189, loss: 0.073 \n",
      "epoch: 002, batch: 190, loss: 1.584 \n",
      "epoch: 002, batch: 191, loss: 0.209 \n",
      "epoch: 002, batch: 192, loss: 0.034 \n",
      "epoch: 002, batch: 193, loss: 0.143 \n",
      "epoch: 002, batch: 194, loss: 0.071 \n",
      "epoch: 002, batch: 195, loss: 0.105 \n",
      "epoch: 002, batch: 196, loss: 0.101 \n",
      "epoch: 002, batch: 197, loss: 0.212 \n",
      "epoch: 002, batch: 198, loss: 0.168 \n",
      "epoch: 002, batch: 199, loss: 0.057 \n",
      "epoch: 002, batch: 200, loss: 0.045 \n",
      "epoch: 002, batch: 201, loss: 1.030 \n",
      "epoch: 002, batch: 202, loss: 0.118 \n",
      "epoch: 002, batch: 203, loss: 0.013 \n",
      "epoch: 002, batch: 204, loss: 0.017 \n",
      "epoch: 002, batch: 205, loss: 0.009 \n",
      "epoch: 002, batch: 206, loss: 0.030 \n",
      "epoch: 002, batch: 207, loss: 0.355 \n",
      "epoch: 002, batch: 208, loss: 0.127 \n",
      "epoch: 002, batch: 209, loss: 0.434 \n",
      "epoch: 002, batch: 210, loss: 1.418 \n",
      "epoch: 002, batch: 211, loss: 0.051 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002, batch: 212, loss: 0.029 \n",
      "epoch: 002, batch: 213, loss: 0.121 \n",
      "epoch: 002, batch: 214, loss: 0.277 \n",
      "epoch: 002, batch: 215, loss: 0.008 \n",
      "epoch: 002, batch: 216, loss: 0.041 \n",
      "epoch: 002, batch: 217, loss: 0.021 \n",
      "epoch: 002, batch: 218, loss: 0.017 \n",
      "epoch: 002, batch: 219, loss: 0.076 \n",
      "epoch: 002, batch: 220, loss: 0.097 \n",
      "epoch: 002, batch: 221, loss: 0.346 \n",
      "epoch: 002, batch: 222, loss: 0.246 \n",
      "epoch: 002, batch: 223, loss: 0.031 \n",
      "epoch: 002, batch: 224, loss: 0.227 \n",
      "epoch: 002, batch: 225, loss: 0.144 \n",
      "epoch: 002, batch: 226, loss: 0.242 \n",
      "epoch: 002, batch: 227, loss: 0.016 \n",
      "epoch: 002 ------------------------------------------------\n",
      "\n",
      "[train] loss: 56.498\n",
      "\n",
      "[validation] bulls_recall: 98.317%\n",
      "\n",
      "[validation] no_bulls_recall: 15.895%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5710562893832178\n",
      "\n",
      "epoch: 003, batch: 001, loss: 0.058 \n",
      "epoch: 003, batch: 002, loss: 3.823 \n",
      "epoch: 003, batch: 003, loss: 0.087 \n",
      "epoch: 003, batch: 004, loss: 0.003 \n",
      "epoch: 003, batch: 005, loss: 0.090 \n",
      "epoch: 003, batch: 006, loss: 0.315 \n",
      "epoch: 003, batch: 007, loss: 0.073 \n",
      "epoch: 003, batch: 008, loss: 0.156 \n",
      "epoch: 003, batch: 009, loss: 0.068 \n",
      "epoch: 003, batch: 010, loss: 0.161 \n",
      "epoch: 003, batch: 011, loss: 0.153 \n",
      "epoch: 003, batch: 012, loss: 0.230 \n",
      "epoch: 003, batch: 013, loss: 0.067 \n",
      "epoch: 003, batch: 014, loss: 1.685 \n",
      "epoch: 003, batch: 015, loss: 0.030 \n",
      "epoch: 003, batch: 016, loss: 1.757 \n",
      "epoch: 003, batch: 017, loss: 0.150 \n",
      "epoch: 003, batch: 018, loss: 0.379 \n",
      "epoch: 003, batch: 019, loss: 0.077 \n",
      "epoch: 003, batch: 020, loss: 0.122 \n",
      "epoch: 003, batch: 021, loss: 0.092 \n",
      "epoch: 003, batch: 022, loss: 0.099 \n",
      "epoch: 003, batch: 023, loss: 0.093 \n",
      "epoch: 003, batch: 024, loss: 0.117 \n",
      "epoch: 003, batch: 025, loss: 0.071 \n",
      "epoch: 003, batch: 026, loss: 0.012 \n",
      "epoch: 003, batch: 027, loss: 0.012 \n",
      "epoch: 003, batch: 028, loss: 0.249 \n",
      "epoch: 003, batch: 029, loss: 0.014 \n",
      "epoch: 003, batch: 030, loss: 0.135 \n",
      "epoch: 003, batch: 031, loss: 0.380 \n",
      "epoch: 003, batch: 032, loss: 0.206 \n",
      "epoch: 003, batch: 033, loss: 0.183 \n",
      "epoch: 003, batch: 034, loss: 0.094 \n",
      "epoch: 003, batch: 035, loss: 0.084 \n",
      "epoch: 003, batch: 036, loss: 1.725 \n",
      "epoch: 003, batch: 037, loss: 0.143 \n",
      "epoch: 003, batch: 038, loss: 0.051 \n",
      "epoch: 003, batch: 039, loss: 1.154 \n",
      "epoch: 003, batch: 040, loss: 0.100 \n",
      "epoch: 003, batch: 041, loss: 0.079 \n",
      "epoch: 003, batch: 042, loss: 0.086 \n",
      "epoch: 003, batch: 043, loss: 0.068 \n",
      "epoch: 003, batch: 044, loss: 0.069 \n",
      "epoch: 003, batch: 045, loss: 0.034 \n",
      "epoch: 003, batch: 046, loss: 0.236 \n",
      "epoch: 003, batch: 047, loss: 0.323 \n",
      "epoch: 003, batch: 048, loss: 0.929 \n",
      "epoch: 003, batch: 049, loss: 0.056 \n",
      "epoch: 003, batch: 050, loss: 0.031 \n",
      "epoch: 003, batch: 051, loss: 0.052 \n",
      "epoch: 003, batch: 052, loss: 0.144 \n",
      "epoch: 003, batch: 053, loss: 0.034 \n",
      "epoch: 003, batch: 054, loss: 1.563 \n",
      "epoch: 003, batch: 055, loss: 0.258 \n",
      "epoch: 003, batch: 056, loss: 0.023 \n",
      "epoch: 003, batch: 057, loss: 0.029 \n",
      "epoch: 003, batch: 058, loss: 1.817 \n",
      "epoch: 003, batch: 059, loss: 0.014 \n",
      "epoch: 003, batch: 060, loss: 0.015 \n",
      "epoch: 003, batch: 061, loss: 0.450 \n",
      "epoch: 003, batch: 062, loss: 0.017 \n",
      "epoch: 003, batch: 063, loss: 0.157 \n",
      "epoch: 003, batch: 064, loss: 0.210 \n",
      "epoch: 003, batch: 065, loss: 0.083 \n",
      "epoch: 003, batch: 066, loss: 0.125 \n",
      "epoch: 003, batch: 067, loss: 0.087 \n",
      "epoch: 003, batch: 068, loss: 0.058 \n",
      "epoch: 003, batch: 069, loss: 0.089 \n",
      "epoch: 003, batch: 070, loss: 0.227 \n",
      "epoch: 003, batch: 071, loss: 0.044 \n",
      "epoch: 003, batch: 072, loss: 0.041 \n",
      "epoch: 003, batch: 073, loss: 0.063 \n",
      "epoch: 003, batch: 074, loss: 0.044 \n",
      "epoch: 003, batch: 075, loss: 0.018 \n",
      "epoch: 003, batch: 076, loss: 0.034 \n",
      "epoch: 003, batch: 077, loss: 0.153 \n",
      "epoch: 003, batch: 078, loss: 0.570 \n",
      "epoch: 003, batch: 079, loss: 0.432 \n",
      "epoch: 003, batch: 080, loss: 0.133 \n",
      "epoch: 003, batch: 081, loss: 0.122 \n",
      "epoch: 003, batch: 082, loss: 0.253 \n",
      "epoch: 003, batch: 083, loss: 0.059 \n",
      "epoch: 003, batch: 084, loss: 0.079 \n",
      "epoch: 003, batch: 085, loss: 0.088 \n",
      "epoch: 003, batch: 086, loss: 0.189 \n",
      "epoch: 003, batch: 087, loss: 0.105 \n",
      "epoch: 003, batch: 088, loss: 0.377 \n",
      "epoch: 003, batch: 089, loss: 0.090 \n",
      "epoch: 003, batch: 090, loss: 0.062 \n",
      "epoch: 003, batch: 091, loss: 0.347 \n",
      "epoch: 003, batch: 092, loss: 0.167 \n",
      "epoch: 003, batch: 093, loss: 0.025 \n",
      "epoch: 003, batch: 094, loss: 0.042 \n",
      "epoch: 003, batch: 095, loss: 0.024 \n",
      "epoch: 003, batch: 096, loss: 1.593 \n",
      "epoch: 003, batch: 097, loss: 0.020 \n",
      "epoch: 003, batch: 098, loss: 0.034 \n",
      "epoch: 003, batch: 099, loss: 0.093 \n",
      "epoch: 003, batch: 100, loss: 0.021 \n",
      "epoch: 003, batch: 101, loss: 0.127 \n",
      "epoch: 003, batch: 102, loss: 0.044 \n",
      "epoch: 003, batch: 103, loss: 0.031 \n",
      "epoch: 003, batch: 104, loss: 0.038 \n",
      "epoch: 003, batch: 105, loss: 0.045 \n",
      "epoch: 003, batch: 106, loss: 0.043 \n",
      "epoch: 003, batch: 107, loss: 0.013 \n",
      "epoch: 003, batch: 108, loss: 0.098 \n",
      "epoch: 003, batch: 109, loss: 0.021 \n",
      "epoch: 003, batch: 110, loss: 0.013 \n",
      "epoch: 003, batch: 111, loss: 0.075 \n",
      "epoch: 003, batch: 112, loss: 0.085 \n",
      "epoch: 003, batch: 113, loss: 0.085 \n",
      "epoch: 003, batch: 114, loss: 0.028 \n",
      "epoch: 003, batch: 115, loss: 0.012 \n",
      "epoch: 003, batch: 116, loss: 0.012 \n",
      "epoch: 003, batch: 117, loss: 0.009 \n",
      "epoch: 003, batch: 118, loss: 0.023 \n",
      "epoch: 003, batch: 119, loss: 0.033 \n",
      "epoch: 003, batch: 120, loss: 0.060 \n",
      "epoch: 003, batch: 121, loss: 0.503 \n",
      "epoch: 003, batch: 122, loss: 0.283 \n",
      "epoch: 003, batch: 123, loss: 0.143 \n",
      "epoch: 003, batch: 124, loss: 0.108 \n",
      "epoch: 003, batch: 125, loss: 0.199 \n",
      "epoch: 003, batch: 126, loss: 0.096 \n",
      "epoch: 003, batch: 127, loss: 0.288 \n",
      "epoch: 003, batch: 128, loss: 0.096 \n",
      "epoch: 003, batch: 129, loss: 0.163 \n",
      "epoch: 003, batch: 130, loss: 0.060 \n",
      "epoch: 003, batch: 131, loss: 0.038 \n",
      "epoch: 003, batch: 132, loss: 0.029 \n",
      "epoch: 003, batch: 133, loss: 0.020 \n",
      "epoch: 003, batch: 134, loss: 0.015 \n",
      "epoch: 003, batch: 135, loss: 0.020 \n",
      "epoch: 003, batch: 136, loss: 0.006 \n",
      "epoch: 003, batch: 137, loss: 0.023 \n",
      "epoch: 003, batch: 138, loss: 0.028 \n",
      "epoch: 003, batch: 139, loss: 0.043 \n",
      "epoch: 003, batch: 140, loss: 0.169 \n",
      "epoch: 003, batch: 141, loss: 0.371 \n",
      "epoch: 003, batch: 142, loss: 0.212 \n",
      "epoch: 003, batch: 143, loss: 0.134 \n",
      "epoch: 003, batch: 144, loss: 0.116 \n",
      "epoch: 003, batch: 145, loss: 0.732 \n",
      "epoch: 003, batch: 146, loss: 0.122 \n",
      "epoch: 003, batch: 147, loss: 0.462 \n",
      "epoch: 003, batch: 148, loss: 0.651 \n",
      "epoch: 003, batch: 149, loss: 0.415 \n",
      "epoch: 003, batch: 150, loss: 0.094 \n",
      "epoch: 003, batch: 151, loss: 0.341 \n",
      "epoch: 003, batch: 152, loss: 0.144 \n",
      "epoch: 003, batch: 153, loss: 0.244 \n",
      "epoch: 003, batch: 154, loss: 0.077 \n",
      "epoch: 003, batch: 155, loss: 0.122 \n",
      "epoch: 003, batch: 156, loss: 0.091 \n",
      "epoch: 003, batch: 157, loss: 0.273 \n",
      "epoch: 003, batch: 158, loss: 0.027 \n",
      "epoch: 003, batch: 159, loss: 0.182 \n",
      "epoch: 003, batch: 160, loss: 1.143 \n",
      "epoch: 003, batch: 161, loss: 0.172 \n",
      "epoch: 003, batch: 162, loss: 0.213 \n",
      "epoch: 003, batch: 163, loss: 0.030 \n",
      "epoch: 003, batch: 164, loss: 0.075 \n",
      "epoch: 003, batch: 165, loss: 0.039 \n",
      "epoch: 003, batch: 166, loss: 0.023 \n",
      "epoch: 003, batch: 167, loss: 0.111 \n",
      "epoch: 003, batch: 168, loss: 0.010 \n",
      "epoch: 003, batch: 169, loss: 0.017 \n",
      "epoch: 003, batch: 170, loss: 0.031 \n",
      "epoch: 003, batch: 171, loss: 0.191 \n",
      "epoch: 003, batch: 172, loss: 0.111 \n",
      "epoch: 003, batch: 173, loss: 0.030 \n",
      "epoch: 003, batch: 174, loss: 0.035 \n",
      "epoch: 003, batch: 175, loss: 0.039 \n",
      "epoch: 003, batch: 176, loss: 0.102 \n",
      "epoch: 003, batch: 177, loss: 0.061 \n",
      "epoch: 003, batch: 178, loss: 0.120 \n",
      "epoch: 003, batch: 179, loss: 1.091 \n",
      "epoch: 003, batch: 180, loss: 0.144 \n",
      "epoch: 003, batch: 181, loss: 0.133 \n",
      "epoch: 003, batch: 182, loss: 0.174 \n",
      "epoch: 003, batch: 183, loss: 0.199 \n",
      "epoch: 003, batch: 184, loss: 0.117 \n",
      "epoch: 003, batch: 185, loss: 0.045 \n",
      "epoch: 003, batch: 186, loss: 0.391 \n",
      "epoch: 003, batch: 187, loss: 0.044 \n",
      "epoch: 003, batch: 188, loss: 0.068 \n",
      "epoch: 003, batch: 189, loss: 0.004 \n",
      "epoch: 003, batch: 190, loss: 0.164 \n",
      "epoch: 003, batch: 191, loss: 0.014 \n",
      "epoch: 003, batch: 192, loss: 0.013 \n",
      "epoch: 003, batch: 193, loss: 0.008 \n",
      "epoch: 003, batch: 194, loss: 0.029 \n",
      "epoch: 003, batch: 195, loss: 0.070 \n",
      "epoch: 003, batch: 196, loss: 0.362 \n",
      "epoch: 003, batch: 197, loss: 0.329 \n",
      "epoch: 003, batch: 198, loss: 0.324 \n",
      "epoch: 003, batch: 199, loss: 0.026 \n",
      "epoch: 003, batch: 200, loss: 0.034 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003, batch: 201, loss: 0.034 \n",
      "epoch: 003, batch: 202, loss: 0.041 \n",
      "epoch: 003, batch: 203, loss: 0.029 \n",
      "epoch: 003, batch: 204, loss: 0.973 \n",
      "epoch: 003, batch: 205, loss: 0.064 \n",
      "epoch: 003, batch: 206, loss: 0.031 \n",
      "epoch: 003, batch: 207, loss: 0.313 \n",
      "epoch: 003, batch: 208, loss: 0.049 \n",
      "epoch: 003, batch: 209, loss: 0.027 \n",
      "epoch: 003, batch: 210, loss: 0.045 \n",
      "epoch: 003, batch: 211, loss: 0.138 \n",
      "epoch: 003, batch: 212, loss: 0.113 \n",
      "epoch: 003, batch: 213, loss: 0.246 \n",
      "epoch: 003, batch: 214, loss: 0.051 \n",
      "epoch: 003, batch: 215, loss: 0.010 \n",
      "epoch: 003, batch: 216, loss: 0.010 \n",
      "epoch: 003, batch: 217, loss: 0.099 \n",
      "epoch: 003, batch: 218, loss: 0.020 \n",
      "epoch: 003, batch: 219, loss: 0.043 \n",
      "epoch: 003, batch: 220, loss: 1.203 \n",
      "epoch: 003, batch: 221, loss: 0.341 \n",
      "epoch: 003, batch: 222, loss: 0.232 \n",
      "epoch: 003, batch: 223, loss: 0.026 \n",
      "epoch: 003, batch: 224, loss: 0.024 \n",
      "epoch: 003, batch: 225, loss: 0.403 \n",
      "epoch: 003, batch: 226, loss: 0.021 \n",
      "epoch: 003, batch: 227, loss: 0.032 \n",
      "epoch: 003 ------------------------------------------------\n",
      "\n",
      "[train] loss: 50.433\n",
      "\n",
      "[validation] bulls_recall: 96.356%\n",
      "\n",
      "[validation] no_bulls_recall: 51.572%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.7396374270707966\n",
      "\n",
      "epoch: 004, batch: 001, loss: 0.391 \n",
      "epoch: 004, batch: 002, loss: 0.006 \n",
      "epoch: 004, batch: 003, loss: 0.018 \n",
      "epoch: 004, batch: 004, loss: 0.019 \n",
      "epoch: 004, batch: 005, loss: 0.023 \n",
      "epoch: 004, batch: 006, loss: 0.222 \n",
      "epoch: 004, batch: 007, loss: 0.012 \n",
      "epoch: 004, batch: 008, loss: 0.006 \n",
      "epoch: 004, batch: 009, loss: 0.020 \n",
      "epoch: 004, batch: 010, loss: 0.041 \n",
      "epoch: 004, batch: 011, loss: 0.043 \n",
      "epoch: 004, batch: 012, loss: 0.154 \n",
      "epoch: 004, batch: 013, loss: 0.331 \n",
      "epoch: 004, batch: 014, loss: 0.044 \n",
      "epoch: 004, batch: 015, loss: 0.221 \n",
      "epoch: 004, batch: 016, loss: 0.033 \n",
      "epoch: 004, batch: 017, loss: 0.123 \n",
      "epoch: 004, batch: 018, loss: 0.023 \n",
      "epoch: 004, batch: 019, loss: 0.021 \n",
      "epoch: 004, batch: 020, loss: 0.017 \n",
      "epoch: 004, batch: 021, loss: 0.027 \n",
      "epoch: 004, batch: 022, loss: 0.016 \n",
      "epoch: 004, batch: 023, loss: 0.140 \n",
      "epoch: 004, batch: 024, loss: 0.344 \n",
      "epoch: 004, batch: 025, loss: 3.701 \n",
      "epoch: 004, batch: 026, loss: 0.026 \n",
      "epoch: 004, batch: 027, loss: 0.118 \n",
      "epoch: 004, batch: 028, loss: 0.011 \n",
      "epoch: 004, batch: 029, loss: 0.047 \n",
      "epoch: 004, batch: 030, loss: 0.017 \n",
      "epoch: 004, batch: 031, loss: 0.001 \n",
      "epoch: 004, batch: 032, loss: 0.138 \n",
      "epoch: 004, batch: 033, loss: 0.238 \n",
      "epoch: 004, batch: 034, loss: 0.005 \n",
      "epoch: 004, batch: 035, loss: 0.159 \n",
      "epoch: 004, batch: 036, loss: 0.014 \n",
      "epoch: 004, batch: 037, loss: 0.010 \n",
      "epoch: 004, batch: 038, loss: 0.039 \n",
      "epoch: 004, batch: 039, loss: 0.006 \n",
      "epoch: 004, batch: 040, loss: 0.122 \n",
      "epoch: 004, batch: 041, loss: 0.025 \n",
      "epoch: 004, batch: 042, loss: 0.009 \n",
      "epoch: 004, batch: 043, loss: 0.794 \n",
      "epoch: 004, batch: 044, loss: 0.013 \n",
      "epoch: 004, batch: 045, loss: 0.382 \n",
      "epoch: 004, batch: 046, loss: 0.003 \n",
      "epoch: 004, batch: 047, loss: 0.005 \n",
      "epoch: 004, batch: 048, loss: 0.343 \n",
      "epoch: 004, batch: 049, loss: 0.013 \n",
      "epoch: 004, batch: 050, loss: 0.007 \n",
      "epoch: 004, batch: 051, loss: 0.037 \n",
      "epoch: 004, batch: 052, loss: 0.017 \n",
      "epoch: 004, batch: 053, loss: 0.034 \n",
      "epoch: 004, batch: 054, loss: 0.012 \n",
      "epoch: 004, batch: 055, loss: 0.023 \n",
      "epoch: 004, batch: 056, loss: 0.043 \n",
      "epoch: 004, batch: 057, loss: 0.288 \n",
      "epoch: 004, batch: 058, loss: 0.013 \n",
      "epoch: 004, batch: 059, loss: 0.003 \n",
      "epoch: 004, batch: 060, loss: 0.034 \n",
      "epoch: 004, batch: 061, loss: 0.029 \n",
      "epoch: 004, batch: 062, loss: 0.029 \n",
      "epoch: 004, batch: 063, loss: 0.014 \n",
      "epoch: 004, batch: 064, loss: 0.020 \n",
      "epoch: 004, batch: 065, loss: 0.072 \n",
      "epoch: 004, batch: 066, loss: 0.055 \n",
      "epoch: 004, batch: 067, loss: 0.003 \n",
      "epoch: 004, batch: 068, loss: 0.310 \n",
      "epoch: 004, batch: 069, loss: 0.058 \n",
      "epoch: 004, batch: 070, loss: 0.031 \n",
      "epoch: 004, batch: 071, loss: 0.012 \n",
      "epoch: 004, batch: 072, loss: 0.318 \n",
      "epoch: 004, batch: 073, loss: 0.005 \n",
      "epoch: 004, batch: 074, loss: 0.003 \n",
      "epoch: 004, batch: 075, loss: 0.005 \n",
      "epoch: 004, batch: 076, loss: 0.033 \n",
      "epoch: 004, batch: 077, loss: 0.070 \n",
      "epoch: 004, batch: 078, loss: 0.014 \n",
      "epoch: 004, batch: 079, loss: 0.415 \n",
      "epoch: 004, batch: 080, loss: 0.247 \n",
      "epoch: 004, batch: 081, loss: 0.180 \n",
      "epoch: 004, batch: 082, loss: 0.477 \n",
      "epoch: 004, batch: 083, loss: 0.018 \n",
      "epoch: 004, batch: 084, loss: 0.126 \n",
      "epoch: 004, batch: 085, loss: 0.034 \n",
      "epoch: 004, batch: 086, loss: 0.080 \n",
      "epoch: 004, batch: 087, loss: 0.074 \n",
      "epoch: 004, batch: 088, loss: 0.201 \n",
      "epoch: 004, batch: 089, loss: 0.010 \n",
      "epoch: 004, batch: 090, loss: 0.100 \n",
      "epoch: 004, batch: 091, loss: 0.217 \n",
      "epoch: 004, batch: 092, loss: 0.078 \n",
      "epoch: 004, batch: 093, loss: 0.090 \n",
      "epoch: 004, batch: 094, loss: 0.275 \n",
      "epoch: 004, batch: 095, loss: 0.379 \n",
      "epoch: 004, batch: 096, loss: 0.002 \n",
      "epoch: 004, batch: 097, loss: 0.006 \n",
      "epoch: 004, batch: 098, loss: 0.062 \n",
      "epoch: 004, batch: 099, loss: 0.228 \n",
      "epoch: 004, batch: 100, loss: 0.002 \n",
      "epoch: 004, batch: 101, loss: 0.365 \n",
      "epoch: 004, batch: 102, loss: 0.002 \n",
      "epoch: 004, batch: 103, loss: 0.017 \n",
      "epoch: 004, batch: 104, loss: 0.001 \n",
      "epoch: 004, batch: 105, loss: 0.070 \n",
      "epoch: 004, batch: 106, loss: 0.196 \n",
      "epoch: 004, batch: 107, loss: 0.013 \n",
      "epoch: 004, batch: 108, loss: 0.031 \n",
      "epoch: 004, batch: 109, loss: 0.231 \n",
      "epoch: 004, batch: 110, loss: 0.003 \n",
      "epoch: 004, batch: 111, loss: 0.457 \n",
      "epoch: 004, batch: 112, loss: 0.143 \n",
      "epoch: 004, batch: 113, loss: 0.054 \n",
      "epoch: 004, batch: 114, loss: 0.002 \n",
      "epoch: 004, batch: 115, loss: 0.001 \n",
      "epoch: 004, batch: 116, loss: 0.000 \n",
      "epoch: 004, batch: 117, loss: 0.001 \n",
      "epoch: 004, batch: 118, loss: 0.724 \n",
      "epoch: 004, batch: 119, loss: 0.265 \n",
      "epoch: 004, batch: 120, loss: 0.141 \n",
      "epoch: 004, batch: 121, loss: 0.088 \n",
      "epoch: 004, batch: 122, loss: 0.107 \n",
      "epoch: 004, batch: 123, loss: 0.087 \n",
      "epoch: 004, batch: 124, loss: 2.270 \n",
      "epoch: 004, batch: 125, loss: 0.017 \n",
      "epoch: 004, batch: 126, loss: 0.017 \n",
      "epoch: 004, batch: 127, loss: 0.095 \n",
      "epoch: 004, batch: 128, loss: 0.434 \n",
      "epoch: 004, batch: 129, loss: 0.158 \n",
      "epoch: 004, batch: 130, loss: 0.102 \n",
      "epoch: 004, batch: 131, loss: 0.032 \n",
      "epoch: 004, batch: 132, loss: 0.021 \n",
      "epoch: 004, batch: 133, loss: 0.017 \n",
      "epoch: 004, batch: 134, loss: 0.133 \n",
      "epoch: 004, batch: 135, loss: 0.007 \n",
      "epoch: 004, batch: 136, loss: 2.014 \n",
      "epoch: 004, batch: 137, loss: 0.018 \n",
      "epoch: 004, batch: 138, loss: 0.009 \n",
      "epoch: 004, batch: 139, loss: 0.019 \n",
      "epoch: 004, batch: 140, loss: 0.205 \n",
      "epoch: 004, batch: 141, loss: 0.019 \n",
      "epoch: 004, batch: 142, loss: 0.025 \n",
      "epoch: 004, batch: 143, loss: 0.157 \n",
      "epoch: 004, batch: 144, loss: 2.227 \n",
      "epoch: 004, batch: 145, loss: 0.172 \n",
      "epoch: 004, batch: 146, loss: 0.126 \n",
      "epoch: 004, batch: 147, loss: 0.235 \n",
      "epoch: 004, batch: 148, loss: 0.008 \n",
      "epoch: 004, batch: 149, loss: 0.011 \n",
      "epoch: 004, batch: 150, loss: 0.026 \n",
      "epoch: 004, batch: 151, loss: 0.027 \n",
      "epoch: 004, batch: 152, loss: 0.029 \n",
      "epoch: 004, batch: 153, loss: 0.060 \n",
      "epoch: 004, batch: 154, loss: 0.084 \n",
      "epoch: 004, batch: 155, loss: 0.052 \n",
      "epoch: 004, batch: 156, loss: 0.025 \n",
      "epoch: 004, batch: 157, loss: 0.190 \n",
      "epoch: 004, batch: 158, loss: 0.026 \n",
      "epoch: 004, batch: 159, loss: 0.017 \n",
      "epoch: 004, batch: 160, loss: 0.036 \n",
      "epoch: 004, batch: 161, loss: 0.262 \n",
      "epoch: 004, batch: 162, loss: 1.173 \n",
      "epoch: 004, batch: 163, loss: 0.017 \n",
      "epoch: 004, batch: 164, loss: 0.008 \n",
      "epoch: 004, batch: 165, loss: 0.021 \n",
      "epoch: 004, batch: 166, loss: 0.007 \n",
      "epoch: 004, batch: 167, loss: 0.023 \n",
      "epoch: 004, batch: 168, loss: 0.003 \n",
      "epoch: 004, batch: 169, loss: 0.020 \n",
      "epoch: 004, batch: 170, loss: 0.504 \n",
      "epoch: 004, batch: 171, loss: 0.012 \n",
      "epoch: 004, batch: 172, loss: 0.005 \n",
      "epoch: 004, batch: 173, loss: 0.127 \n",
      "epoch: 004, batch: 174, loss: 0.044 \n",
      "epoch: 004, batch: 175, loss: 0.054 \n",
      "epoch: 004, batch: 176, loss: 0.062 \n",
      "epoch: 004, batch: 177, loss: 0.008 \n",
      "epoch: 004, batch: 178, loss: 0.006 \n",
      "epoch: 004, batch: 179, loss: 0.017 \n",
      "epoch: 004, batch: 180, loss: 0.115 \n",
      "epoch: 004, batch: 181, loss: 0.198 \n",
      "epoch: 004, batch: 182, loss: 0.017 \n",
      "epoch: 004, batch: 183, loss: 0.021 \n",
      "epoch: 004, batch: 184, loss: 1.817 \n",
      "epoch: 004, batch: 185, loss: 0.015 \n",
      "epoch: 004, batch: 186, loss: 0.044 \n",
      "epoch: 004, batch: 187, loss: 0.104 \n",
      "epoch: 004, batch: 188, loss: 0.044 \n",
      "epoch: 004, batch: 189, loss: 0.888 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004, batch: 190, loss: 0.123 \n",
      "epoch: 004, batch: 191, loss: 0.033 \n",
      "epoch: 004, batch: 192, loss: 0.090 \n",
      "epoch: 004, batch: 193, loss: 0.085 \n",
      "epoch: 004, batch: 194, loss: 0.029 \n",
      "epoch: 004, batch: 195, loss: 0.067 \n",
      "epoch: 004, batch: 196, loss: 0.007 \n",
      "epoch: 004, batch: 197, loss: 2.779 \n",
      "epoch: 004, batch: 198, loss: 0.070 \n",
      "epoch: 004, batch: 199, loss: 0.032 \n",
      "epoch: 004, batch: 200, loss: 0.003 \n",
      "epoch: 004, batch: 201, loss: 0.500 \n",
      "epoch: 004, batch: 202, loss: 0.011 \n",
      "epoch: 004, batch: 203, loss: 0.014 \n",
      "epoch: 004, batch: 204, loss: 0.029 \n",
      "epoch: 004, batch: 205, loss: 0.005 \n",
      "epoch: 004, batch: 206, loss: 0.008 \n",
      "epoch: 004, batch: 207, loss: 0.024 \n",
      "epoch: 004, batch: 208, loss: 0.302 \n",
      "epoch: 004, batch: 209, loss: 0.019 \n",
      "epoch: 004, batch: 210, loss: 0.014 \n",
      "epoch: 004, batch: 211, loss: 0.120 \n",
      "epoch: 004, batch: 212, loss: 0.007 \n",
      "epoch: 004, batch: 213, loss: 0.047 \n",
      "epoch: 004, batch: 214, loss: 0.123 \n",
      "epoch: 004, batch: 215, loss: 0.099 \n",
      "epoch: 004, batch: 216, loss: 0.019 \n",
      "epoch: 004, batch: 217, loss: 0.020 \n",
      "epoch: 004, batch: 218, loss: 0.017 \n",
      "epoch: 004, batch: 219, loss: 0.014 \n",
      "epoch: 004, batch: 220, loss: 0.820 \n",
      "epoch: 004, batch: 221, loss: 0.005 \n",
      "epoch: 004, batch: 222, loss: 0.009 \n",
      "epoch: 004, batch: 223, loss: 0.016 \n",
      "epoch: 004, batch: 224, loss: 0.006 \n",
      "epoch: 004, batch: 225, loss: 0.221 \n",
      "epoch: 004, batch: 226, loss: 0.230 \n",
      "epoch: 004, batch: 227, loss: 0.046 \n",
      "epoch: 004 ------------------------------------------------\n",
      "\n",
      "[train] loss: 34.785\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 2.577%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5128705745028468\n",
      "\n",
      "epoch: 005, batch: 001, loss: 0.136 \n",
      "epoch: 005, batch: 002, loss: 0.019 \n",
      "epoch: 005, batch: 003, loss: 0.010 \n",
      "epoch: 005, batch: 004, loss: 0.035 \n",
      "epoch: 005, batch: 005, loss: 0.191 \n",
      "epoch: 005, batch: 006, loss: 0.023 \n",
      "epoch: 005, batch: 007, loss: 0.087 \n",
      "epoch: 005, batch: 008, loss: 0.113 \n",
      "epoch: 005, batch: 009, loss: 0.005 \n",
      "epoch: 005, batch: 010, loss: 0.130 \n",
      "epoch: 005, batch: 011, loss: 0.020 \n",
      "epoch: 005, batch: 012, loss: 0.012 \n",
      "epoch: 005, batch: 013, loss: 0.036 \n",
      "epoch: 005, batch: 014, loss: 0.121 \n",
      "epoch: 005, batch: 015, loss: 0.213 \n",
      "epoch: 005, batch: 016, loss: 0.005 \n",
      "epoch: 005, batch: 017, loss: 0.006 \n",
      "epoch: 005, batch: 018, loss: 0.004 \n",
      "epoch: 005, batch: 019, loss: 0.510 \n",
      "epoch: 005, batch: 020, loss: 0.002 \n",
      "epoch: 005, batch: 021, loss: 0.007 \n",
      "epoch: 005, batch: 022, loss: 0.032 \n",
      "epoch: 005, batch: 023, loss: 0.129 \n",
      "epoch: 005, batch: 024, loss: 0.079 \n",
      "epoch: 005, batch: 025, loss: 0.008 \n",
      "epoch: 005, batch: 026, loss: 0.257 \n",
      "epoch: 005, batch: 027, loss: 0.178 \n",
      "epoch: 005, batch: 028, loss: 0.049 \n",
      "epoch: 005, batch: 029, loss: 0.115 \n",
      "epoch: 005, batch: 030, loss: 0.023 \n",
      "epoch: 005, batch: 031, loss: 0.640 \n",
      "epoch: 005, batch: 032, loss: 0.692 \n",
      "epoch: 005, batch: 033, loss: 0.012 \n",
      "epoch: 005, batch: 034, loss: 0.123 \n",
      "epoch: 005, batch: 035, loss: 0.007 \n",
      "epoch: 005, batch: 036, loss: 0.004 \n",
      "epoch: 005, batch: 037, loss: 0.014 \n",
      "epoch: 005, batch: 038, loss: 0.006 \n",
      "epoch: 005, batch: 039, loss: 0.003 \n",
      "epoch: 005, batch: 040, loss: 0.013 \n",
      "epoch: 005, batch: 041, loss: 0.472 \n",
      "epoch: 005, batch: 042, loss: 0.014 \n",
      "epoch: 005, batch: 043, loss: 0.016 \n",
      "epoch: 005, batch: 044, loss: 0.015 \n",
      "epoch: 005, batch: 045, loss: 0.033 \n",
      "epoch: 005, batch: 046, loss: 0.219 \n",
      "epoch: 005, batch: 047, loss: 0.303 \n",
      "epoch: 005, batch: 048, loss: 0.012 \n",
      "epoch: 005, batch: 049, loss: 0.011 \n",
      "epoch: 005, batch: 050, loss: 0.192 \n",
      "epoch: 005, batch: 051, loss: 0.007 \n",
      "epoch: 005, batch: 052, loss: 0.006 \n",
      "epoch: 005, batch: 053, loss: 0.060 \n",
      "epoch: 005, batch: 054, loss: 0.005 \n",
      "epoch: 005, batch: 055, loss: 0.021 \n",
      "epoch: 005, batch: 056, loss: 0.011 \n",
      "epoch: 005, batch: 057, loss: 0.346 \n",
      "epoch: 005, batch: 058, loss: 0.016 \n",
      "epoch: 005, batch: 059, loss: 0.100 \n",
      "epoch: 005, batch: 060, loss: 0.021 \n",
      "epoch: 005, batch: 061, loss: 0.017 \n",
      "epoch: 005, batch: 062, loss: 0.561 \n",
      "epoch: 005, batch: 063, loss: 0.003 \n",
      "epoch: 005, batch: 064, loss: 0.043 \n",
      "epoch: 005, batch: 065, loss: 0.009 \n",
      "epoch: 005, batch: 066, loss: 0.026 \n",
      "epoch: 005, batch: 067, loss: 0.260 \n",
      "epoch: 005, batch: 068, loss: 0.004 \n",
      "epoch: 005, batch: 069, loss: 0.006 \n",
      "epoch: 005, batch: 070, loss: 0.014 \n",
      "epoch: 005, batch: 071, loss: 0.010 \n",
      "epoch: 005, batch: 072, loss: 0.135 \n",
      "epoch: 005, batch: 073, loss: 0.006 \n",
      "epoch: 005, batch: 074, loss: 0.016 \n",
      "epoch: 005, batch: 075, loss: 2.334 \n",
      "epoch: 005, batch: 076, loss: 0.017 \n",
      "epoch: 005, batch: 077, loss: 0.488 \n",
      "epoch: 005, batch: 078, loss: 0.009 \n",
      "epoch: 005, batch: 079, loss: 0.017 \n",
      "epoch: 005, batch: 080, loss: 0.011 \n",
      "epoch: 005, batch: 081, loss: 0.012 \n",
      "epoch: 005, batch: 082, loss: 0.015 \n",
      "epoch: 005, batch: 083, loss: 0.012 \n",
      "epoch: 005, batch: 084, loss: 0.008 \n",
      "epoch: 005, batch: 085, loss: 1.572 \n",
      "epoch: 005, batch: 086, loss: 0.011 \n",
      "epoch: 005, batch: 087, loss: 0.017 \n",
      "epoch: 005, batch: 088, loss: 0.156 \n",
      "epoch: 005, batch: 089, loss: 0.251 \n",
      "epoch: 005, batch: 090, loss: 0.143 \n",
      "epoch: 005, batch: 091, loss: 0.031 \n",
      "epoch: 005, batch: 092, loss: 0.126 \n",
      "epoch: 005, batch: 093, loss: 0.053 \n",
      "epoch: 005, batch: 094, loss: 0.079 \n",
      "epoch: 005, batch: 095, loss: 0.019 \n",
      "epoch: 005, batch: 096, loss: 0.013 \n",
      "epoch: 005, batch: 097, loss: 0.038 \n",
      "epoch: 005, batch: 098, loss: 0.113 \n",
      "epoch: 005, batch: 099, loss: 0.027 \n",
      "epoch: 005, batch: 100, loss: 0.087 \n",
      "epoch: 005, batch: 101, loss: 0.196 \n",
      "epoch: 005, batch: 102, loss: 0.279 \n",
      "epoch: 005, batch: 103, loss: 0.030 \n",
      "epoch: 005, batch: 104, loss: 0.011 \n",
      "epoch: 005, batch: 105, loss: 0.134 \n",
      "epoch: 005, batch: 106, loss: 0.116 \n",
      "epoch: 005, batch: 107, loss: 0.014 \n",
      "epoch: 005, batch: 108, loss: 0.002 \n",
      "epoch: 005, batch: 109, loss: 0.154 \n",
      "epoch: 005, batch: 110, loss: 0.131 \n",
      "epoch: 005, batch: 111, loss: 0.018 \n",
      "epoch: 005, batch: 112, loss: 0.006 \n",
      "epoch: 005, batch: 113, loss: 0.007 \n",
      "epoch: 005, batch: 114, loss: 0.036 \n",
      "epoch: 005, batch: 115, loss: 0.025 \n",
      "epoch: 005, batch: 116, loss: 0.035 \n",
      "epoch: 005, batch: 117, loss: 0.046 \n",
      "epoch: 005, batch: 118, loss: 0.013 \n",
      "epoch: 005, batch: 119, loss: 0.003 \n",
      "epoch: 005, batch: 120, loss: 0.012 \n",
      "epoch: 005, batch: 121, loss: 0.100 \n",
      "epoch: 005, batch: 122, loss: 0.004 \n",
      "epoch: 005, batch: 123, loss: 0.020 \n",
      "epoch: 005, batch: 124, loss: 0.357 \n",
      "epoch: 005, batch: 125, loss: 0.045 \n",
      "epoch: 005, batch: 126, loss: 0.141 \n",
      "epoch: 005, batch: 127, loss: 0.833 \n",
      "epoch: 005, batch: 128, loss: 0.006 \n",
      "epoch: 005, batch: 129, loss: 0.011 \n",
      "epoch: 005, batch: 130, loss: 0.002 \n",
      "epoch: 005, batch: 131, loss: 0.004 \n",
      "epoch: 005, batch: 132, loss: 0.002 \n",
      "epoch: 005, batch: 133, loss: 0.001 \n",
      "epoch: 005, batch: 134, loss: 0.002 \n",
      "epoch: 005, batch: 135, loss: 0.003 \n",
      "epoch: 005, batch: 136, loss: 0.005 \n",
      "epoch: 005, batch: 137, loss: 0.028 \n",
      "epoch: 005, batch: 138, loss: 0.037 \n",
      "epoch: 005, batch: 139, loss: 0.252 \n",
      "epoch: 005, batch: 140, loss: 0.009 \n",
      "epoch: 005, batch: 141, loss: 0.019 \n",
      "epoch: 005, batch: 142, loss: 0.022 \n",
      "epoch: 005, batch: 143, loss: 2.246 \n",
      "epoch: 005, batch: 144, loss: 0.246 \n",
      "epoch: 005, batch: 145, loss: 0.420 \n",
      "epoch: 005, batch: 146, loss: 0.007 \n",
      "epoch: 005, batch: 147, loss: 0.044 \n",
      "epoch: 005, batch: 148, loss: 0.023 \n",
      "epoch: 005, batch: 149, loss: 0.025 \n",
      "epoch: 005, batch: 150, loss: 0.009 \n",
      "epoch: 005, batch: 151, loss: 0.124 \n",
      "epoch: 005, batch: 152, loss: 0.430 \n",
      "epoch: 005, batch: 153, loss: 0.061 \n",
      "epoch: 005, batch: 154, loss: 0.011 \n",
      "epoch: 005, batch: 155, loss: 0.061 \n",
      "epoch: 005, batch: 156, loss: 0.048 \n",
      "epoch: 005, batch: 157, loss: 0.039 \n",
      "epoch: 005, batch: 158, loss: 0.011 \n",
      "epoch: 005, batch: 159, loss: 0.013 \n",
      "epoch: 005, batch: 160, loss: 0.026 \n",
      "epoch: 005, batch: 161, loss: 0.048 \n",
      "epoch: 005, batch: 162, loss: 0.132 \n",
      "epoch: 005, batch: 163, loss: 0.073 \n",
      "epoch: 005, batch: 164, loss: 0.043 \n",
      "epoch: 005, batch: 165, loss: 0.068 \n",
      "epoch: 005, batch: 166, loss: 0.028 \n",
      "epoch: 005, batch: 167, loss: 0.028 \n",
      "epoch: 005, batch: 168, loss: 0.021 \n",
      "epoch: 005, batch: 169, loss: 0.002 \n",
      "epoch: 005, batch: 170, loss: 0.026 \n",
      "epoch: 005, batch: 171, loss: 0.012 \n",
      "epoch: 005, batch: 172, loss: 0.016 \n",
      "epoch: 005, batch: 173, loss: 0.114 \n",
      "epoch: 005, batch: 174, loss: 0.009 \n",
      "epoch: 005, batch: 175, loss: 0.015 \n",
      "epoch: 005, batch: 176, loss: 0.024 \n",
      "epoch: 005, batch: 177, loss: 0.010 \n",
      "epoch: 005, batch: 178, loss: 0.020 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005, batch: 179, loss: 0.141 \n",
      "epoch: 005, batch: 180, loss: 0.019 \n",
      "epoch: 005, batch: 181, loss: 0.162 \n",
      "epoch: 005, batch: 182, loss: 0.046 \n",
      "epoch: 005, batch: 183, loss: 0.223 \n",
      "epoch: 005, batch: 184, loss: 0.100 \n",
      "epoch: 005, batch: 185, loss: 0.225 \n",
      "epoch: 005, batch: 186, loss: 0.074 \n",
      "epoch: 005, batch: 187, loss: 0.071 \n",
      "epoch: 005, batch: 188, loss: 0.057 \n",
      "epoch: 005, batch: 189, loss: 0.048 \n",
      "epoch: 005, batch: 190, loss: 0.097 \n",
      "epoch: 005, batch: 191, loss: 0.018 \n",
      "epoch: 005, batch: 192, loss: 0.125 \n",
      "epoch: 005, batch: 193, loss: 0.013 \n",
      "epoch: 005, batch: 194, loss: 1.115 \n",
      "epoch: 005, batch: 195, loss: 0.011 \n",
      "epoch: 005, batch: 196, loss: 0.177 \n",
      "epoch: 005, batch: 197, loss: 0.191 \n",
      "epoch: 005, batch: 198, loss: 0.074 \n",
      "epoch: 005, batch: 199, loss: 0.001 \n",
      "epoch: 005, batch: 200, loss: 0.021 \n",
      "epoch: 005, batch: 201, loss: 0.405 \n",
      "epoch: 005, batch: 202, loss: 0.003 \n",
      "epoch: 005, batch: 203, loss: 0.001 \n",
      "epoch: 005, batch: 204, loss: 0.012 \n",
      "epoch: 005, batch: 205, loss: 0.157 \n",
      "epoch: 005, batch: 206, loss: 0.004 \n",
      "epoch: 005, batch: 207, loss: 0.005 \n",
      "epoch: 005, batch: 208, loss: 0.016 \n",
      "epoch: 005, batch: 209, loss: 0.111 \n",
      "epoch: 005, batch: 210, loss: 0.002 \n",
      "epoch: 005, batch: 211, loss: 0.134 \n",
      "epoch: 005, batch: 212, loss: 0.015 \n",
      "epoch: 005, batch: 213, loss: 0.544 \n",
      "epoch: 005, batch: 214, loss: 0.172 \n",
      "epoch: 005, batch: 215, loss: 0.147 \n",
      "epoch: 005, batch: 216, loss: 0.012 \n",
      "epoch: 005, batch: 217, loss: 0.003 \n",
      "epoch: 005, batch: 218, loss: 0.122 \n",
      "epoch: 005, batch: 219, loss: 0.116 \n",
      "epoch: 005, batch: 220, loss: 0.002 \n",
      "epoch: 005, batch: 221, loss: 0.001 \n",
      "epoch: 005, batch: 222, loss: 0.018 \n",
      "epoch: 005, batch: 223, loss: 0.005 \n",
      "epoch: 005, batch: 224, loss: 0.064 \n",
      "epoch: 005, batch: 225, loss: 0.177 \n",
      "epoch: 005, batch: 226, loss: 0.048 \n",
      "epoch: 005, batch: 227, loss: 0.085 \n",
      "epoch: 005 ------------------------------------------------\n",
      "\n",
      "[train] loss: 26.706\n",
      "\n",
      "[validation] bulls_recall: 99.717%\n",
      "\n",
      "[validation] no_bulls_recall: 16.794%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5825573898554369\n",
      "\n",
      "epoch: 006, batch: 001, loss: 0.024 \n",
      "epoch: 006, batch: 002, loss: 0.008 \n",
      "epoch: 006, batch: 003, loss: 0.011 \n",
      "epoch: 006, batch: 004, loss: 0.003 \n",
      "epoch: 006, batch: 005, loss: 0.003 \n",
      "epoch: 006, batch: 006, loss: 0.090 \n",
      "epoch: 006, batch: 007, loss: 0.001 \n",
      "epoch: 006, batch: 008, loss: 0.020 \n",
      "epoch: 006, batch: 009, loss: 0.465 \n",
      "epoch: 006, batch: 010, loss: 0.136 \n",
      "epoch: 006, batch: 011, loss: 0.010 \n",
      "epoch: 006, batch: 012, loss: 0.004 \n",
      "epoch: 006, batch: 013, loss: 0.142 \n",
      "epoch: 006, batch: 014, loss: 0.030 \n",
      "epoch: 006, batch: 015, loss: 0.012 \n",
      "epoch: 006, batch: 016, loss: 0.025 \n",
      "epoch: 006, batch: 017, loss: 0.090 \n",
      "epoch: 006, batch: 018, loss: 0.157 \n",
      "epoch: 006, batch: 019, loss: 0.163 \n",
      "epoch: 006, batch: 020, loss: 0.079 \n",
      "epoch: 006, batch: 021, loss: 0.012 \n",
      "epoch: 006, batch: 022, loss: 0.199 \n",
      "epoch: 006, batch: 023, loss: 0.017 \n",
      "epoch: 006, batch: 024, loss: 0.013 \n",
      "epoch: 006, batch: 025, loss: 0.054 \n",
      "epoch: 006, batch: 026, loss: 0.024 \n",
      "epoch: 006, batch: 027, loss: 0.046 \n",
      "epoch: 006, batch: 028, loss: 0.009 \n",
      "epoch: 006, batch: 029, loss: 0.044 \n",
      "epoch: 006, batch: 030, loss: 0.009 \n",
      "epoch: 006, batch: 031, loss: 0.039 \n",
      "epoch: 006, batch: 032, loss: 0.011 \n",
      "epoch: 006, batch: 033, loss: 0.271 \n",
      "epoch: 006, batch: 034, loss: 0.143 \n",
      "epoch: 006, batch: 035, loss: 0.023 \n",
      "epoch: 006, batch: 036, loss: 0.046 \n",
      "epoch: 006, batch: 037, loss: 0.013 \n",
      "epoch: 006, batch: 038, loss: 0.059 \n",
      "epoch: 006, batch: 039, loss: 0.132 \n",
      "epoch: 006, batch: 040, loss: 0.007 \n",
      "epoch: 006, batch: 041, loss: 0.005 \n",
      "epoch: 006, batch: 042, loss: 0.108 \n",
      "epoch: 006, batch: 043, loss: 0.182 \n",
      "epoch: 006, batch: 044, loss: 0.017 \n",
      "epoch: 006, batch: 045, loss: 0.003 \n",
      "epoch: 006, batch: 046, loss: 0.007 \n",
      "epoch: 006, batch: 047, loss: 0.190 \n",
      "epoch: 006, batch: 048, loss: 0.038 \n",
      "epoch: 006, batch: 049, loss: 0.026 \n",
      "epoch: 006, batch: 050, loss: 0.004 \n",
      "epoch: 006, batch: 051, loss: 0.007 \n",
      "epoch: 006, batch: 052, loss: 0.002 \n",
      "epoch: 006, batch: 053, loss: 0.016 \n",
      "epoch: 006, batch: 054, loss: 0.004 \n",
      "epoch: 006, batch: 055, loss: 0.064 \n",
      "epoch: 006, batch: 056, loss: 0.025 \n",
      "epoch: 006, batch: 057, loss: 0.207 \n",
      "epoch: 006, batch: 058, loss: 0.026 \n",
      "epoch: 006, batch: 059, loss: 0.018 \n",
      "epoch: 006, batch: 060, loss: 0.010 \n",
      "epoch: 006, batch: 061, loss: 0.035 \n",
      "epoch: 006, batch: 062, loss: 0.226 \n",
      "epoch: 006, batch: 063, loss: 0.011 \n",
      "epoch: 006, batch: 064, loss: 0.015 \n",
      "epoch: 006, batch: 065, loss: 0.046 \n",
      "epoch: 006, batch: 066, loss: 0.107 \n",
      "epoch: 006, batch: 067, loss: 0.368 \n",
      "epoch: 006, batch: 068, loss: 0.196 \n",
      "epoch: 006, batch: 069, loss: 0.091 \n",
      "epoch: 006, batch: 070, loss: 0.375 \n",
      "epoch: 006, batch: 071, loss: 1.974 \n",
      "epoch: 006, batch: 072, loss: 1.139 \n",
      "epoch: 006, batch: 073, loss: 0.072 \n",
      "epoch: 006, batch: 074, loss: 0.022 \n",
      "epoch: 006, batch: 075, loss: 0.028 \n",
      "epoch: 006, batch: 076, loss: 0.041 \n",
      "epoch: 006, batch: 077, loss: 0.064 \n",
      "epoch: 006, batch: 078, loss: 0.011 \n",
      "epoch: 006, batch: 079, loss: 0.009 \n",
      "epoch: 006, batch: 080, loss: 0.043 \n",
      "epoch: 006, batch: 081, loss: 0.009 \n",
      "epoch: 006, batch: 082, loss: 0.697 \n",
      "epoch: 006, batch: 083, loss: 0.009 \n",
      "epoch: 006, batch: 084, loss: 0.030 \n",
      "epoch: 006, batch: 085, loss: 0.017 \n",
      "epoch: 006, batch: 086, loss: 0.029 \n",
      "epoch: 006, batch: 087, loss: 0.005 \n",
      "epoch: 006, batch: 088, loss: 0.010 \n",
      "epoch: 006, batch: 089, loss: 0.086 \n",
      "epoch: 006, batch: 090, loss: 0.026 \n",
      "epoch: 006, batch: 091, loss: 0.057 \n",
      "epoch: 006, batch: 092, loss: 0.176 \n",
      "epoch: 006, batch: 093, loss: 0.083 \n",
      "epoch: 006, batch: 094, loss: 0.220 \n",
      "epoch: 006, batch: 095, loss: 0.003 \n",
      "epoch: 006, batch: 096, loss: 0.009 \n",
      "epoch: 006, batch: 097, loss: 0.003 \n",
      "epoch: 006, batch: 098, loss: 0.110 \n",
      "epoch: 006, batch: 099, loss: 0.008 \n",
      "epoch: 006, batch: 100, loss: 0.006 \n",
      "epoch: 006, batch: 101, loss: 0.048 \n",
      "epoch: 006, batch: 102, loss: 0.167 \n",
      "epoch: 006, batch: 103, loss: 0.005 \n",
      "epoch: 006, batch: 104, loss: 0.055 \n",
      "epoch: 006, batch: 105, loss: 0.003 \n",
      "epoch: 006, batch: 106, loss: 0.192 \n",
      "epoch: 006, batch: 107, loss: 0.003 \n",
      "epoch: 006, batch: 108, loss: 0.017 \n",
      "epoch: 006, batch: 109, loss: 0.371 \n",
      "epoch: 006, batch: 110, loss: 0.113 \n",
      "epoch: 006, batch: 111, loss: 0.041 \n",
      "epoch: 006, batch: 112, loss: 0.014 \n",
      "epoch: 006, batch: 113, loss: 0.100 \n",
      "epoch: 006, batch: 114, loss: 0.446 \n",
      "epoch: 006, batch: 115, loss: 0.019 \n",
      "epoch: 006, batch: 116, loss: 0.086 \n",
      "epoch: 006, batch: 117, loss: 0.122 \n",
      "epoch: 006, batch: 118, loss: 0.083 \n",
      "epoch: 006, batch: 119, loss: 0.020 \n",
      "epoch: 006, batch: 120, loss: 0.027 \n",
      "epoch: 006, batch: 121, loss: 0.078 \n",
      "epoch: 006, batch: 122, loss: 0.058 \n",
      "epoch: 006, batch: 123, loss: 0.291 \n",
      "epoch: 006, batch: 124, loss: 0.007 \n",
      "epoch: 006, batch: 125, loss: 0.264 \n",
      "epoch: 006, batch: 126, loss: 0.005 \n",
      "epoch: 006, batch: 127, loss: 0.028 \n",
      "epoch: 006, batch: 128, loss: 0.010 \n",
      "epoch: 006, batch: 129, loss: 0.028 \n",
      "epoch: 006, batch: 130, loss: 0.002 \n",
      "epoch: 006, batch: 131, loss: 0.005 \n",
      "epoch: 006, batch: 132, loss: 0.003 \n",
      "epoch: 006, batch: 133, loss: 0.010 \n",
      "epoch: 006, batch: 134, loss: 0.013 \n",
      "epoch: 006, batch: 135, loss: 0.010 \n",
      "epoch: 006, batch: 136, loss: 0.002 \n",
      "epoch: 006, batch: 137, loss: 0.028 \n",
      "epoch: 006, batch: 138, loss: 0.013 \n",
      "epoch: 006, batch: 139, loss: 0.174 \n",
      "epoch: 006, batch: 140, loss: 0.020 \n",
      "epoch: 006, batch: 141, loss: 0.008 \n",
      "epoch: 006, batch: 142, loss: 0.005 \n",
      "epoch: 006, batch: 143, loss: 0.067 \n",
      "epoch: 006, batch: 144, loss: 0.073 \n",
      "epoch: 006, batch: 145, loss: 0.014 \n",
      "epoch: 006, batch: 146, loss: 0.012 \n",
      "epoch: 006, batch: 147, loss: 0.008 \n",
      "epoch: 006, batch: 148, loss: 0.069 \n",
      "epoch: 006, batch: 149, loss: 0.025 \n",
      "epoch: 006, batch: 150, loss: 0.045 \n",
      "epoch: 006, batch: 151, loss: 0.077 \n",
      "epoch: 006, batch: 152, loss: 0.590 \n",
      "epoch: 006, batch: 153, loss: 0.002 \n",
      "epoch: 006, batch: 154, loss: 1.002 \n",
      "epoch: 006, batch: 155, loss: 0.173 \n",
      "epoch: 006, batch: 156, loss: 0.027 \n",
      "epoch: 006, batch: 157, loss: 0.005 \n",
      "epoch: 006, batch: 158, loss: 0.164 \n",
      "epoch: 006, batch: 159, loss: 0.008 \n",
      "epoch: 006, batch: 160, loss: 0.002 \n",
      "epoch: 006, batch: 161, loss: 0.004 \n",
      "epoch: 006, batch: 162, loss: 0.003 \n",
      "epoch: 006, batch: 163, loss: 0.074 \n",
      "epoch: 006, batch: 164, loss: 0.070 \n",
      "epoch: 006, batch: 165, loss: 0.023 \n",
      "epoch: 006, batch: 166, loss: 0.014 \n",
      "epoch: 006, batch: 167, loss: 0.047 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006, batch: 168, loss: 0.075 \n",
      "epoch: 006, batch: 169, loss: 0.005 \n",
      "epoch: 006, batch: 170, loss: 0.071 \n",
      "epoch: 006, batch: 171, loss: 0.565 \n",
      "epoch: 006, batch: 172, loss: 0.016 \n",
      "epoch: 006, batch: 173, loss: 0.010 \n",
      "epoch: 006, batch: 174, loss: 0.259 \n",
      "epoch: 006, batch: 175, loss: 0.005 \n",
      "epoch: 006, batch: 176, loss: 0.054 \n",
      "epoch: 006, batch: 177, loss: 0.037 \n",
      "epoch: 006, batch: 178, loss: 0.033 \n",
      "epoch: 006, batch: 179, loss: 0.310 \n",
      "epoch: 006, batch: 180, loss: 0.008 \n",
      "epoch: 006, batch: 181, loss: 0.016 \n",
      "epoch: 006, batch: 182, loss: 0.027 \n",
      "epoch: 006, batch: 183, loss: 0.065 \n",
      "epoch: 006, batch: 184, loss: 0.011 \n",
      "epoch: 006, batch: 185, loss: 0.005 \n",
      "epoch: 006, batch: 186, loss: 0.005 \n",
      "epoch: 006, batch: 187, loss: 0.019 \n",
      "epoch: 006, batch: 188, loss: 0.006 \n",
      "epoch: 006, batch: 189, loss: 0.005 \n",
      "epoch: 006, batch: 190, loss: 0.005 \n",
      "epoch: 006, batch: 191, loss: 0.054 \n",
      "epoch: 006, batch: 192, loss: 0.008 \n",
      "epoch: 006, batch: 193, loss: 0.027 \n",
      "epoch: 006, batch: 194, loss: 0.012 \n",
      "epoch: 006, batch: 195, loss: 0.006 \n",
      "epoch: 006, batch: 196, loss: 0.033 \n",
      "epoch: 006, batch: 197, loss: 0.008 \n",
      "epoch: 006, batch: 198, loss: 0.058 \n",
      "epoch: 006, batch: 199, loss: 0.013 \n",
      "epoch: 006, batch: 200, loss: 0.016 \n",
      "epoch: 006, batch: 201, loss: 0.053 \n",
      "epoch: 006, batch: 202, loss: 0.947 \n",
      "epoch: 006, batch: 203, loss: 0.003 \n",
      "epoch: 006, batch: 204, loss: 0.311 \n",
      "epoch: 006, batch: 205, loss: 0.046 \n",
      "epoch: 006, batch: 206, loss: 0.016 \n",
      "epoch: 006, batch: 207, loss: 0.129 \n",
      "epoch: 006, batch: 208, loss: 0.087 \n",
      "epoch: 006, batch: 209, loss: 0.007 \n",
      "epoch: 006, batch: 210, loss: 0.222 \n",
      "epoch: 006, batch: 211, loss: 0.028 \n",
      "epoch: 006, batch: 212, loss: 0.019 \n",
      "epoch: 006, batch: 213, loss: 0.058 \n",
      "epoch: 006, batch: 214, loss: 0.182 \n",
      "epoch: 006, batch: 215, loss: 0.259 \n",
      "epoch: 006, batch: 216, loss: 0.030 \n",
      "epoch: 006, batch: 217, loss: 0.027 \n",
      "epoch: 006, batch: 218, loss: 0.056 \n",
      "epoch: 006, batch: 219, loss: 0.129 \n",
      "epoch: 006, batch: 220, loss: 0.040 \n",
      "epoch: 006, batch: 221, loss: 0.077 \n",
      "epoch: 006, batch: 222, loss: 0.112 \n",
      "epoch: 006, batch: 223, loss: 0.129 \n",
      "epoch: 006, batch: 224, loss: 0.080 \n",
      "epoch: 006, batch: 225, loss: 0.113 \n",
      "epoch: 006, batch: 226, loss: 0.058 \n",
      "epoch: 006, batch: 227, loss: 0.012 \n",
      "epoch: 006 ------------------------------------------------\n",
      "\n",
      "[train] loss: 28.024\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 1.411%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5070391914431812\n",
      "\n",
      "epoch: 007, batch: 001, loss: 0.046 \n",
      "epoch: 007, batch: 002, loss: 0.045 \n",
      "epoch: 007, batch: 003, loss: 0.030 \n",
      "epoch: 007, batch: 004, loss: 0.011 \n",
      "epoch: 007, batch: 005, loss: 0.127 \n",
      "epoch: 007, batch: 006, loss: 0.045 \n",
      "epoch: 007, batch: 007, loss: 0.181 \n",
      "epoch: 007, batch: 008, loss: 0.216 \n",
      "epoch: 007, batch: 009, loss: 0.005 \n",
      "epoch: 007, batch: 010, loss: 0.004 \n",
      "epoch: 007, batch: 011, loss: 0.007 \n",
      "epoch: 007, batch: 012, loss: 0.002 \n",
      "epoch: 007, batch: 013, loss: 0.012 \n",
      "epoch: 007, batch: 014, loss: 0.007 \n",
      "epoch: 007, batch: 015, loss: 0.038 \n",
      "epoch: 007, batch: 016, loss: 0.191 \n",
      "epoch: 007, batch: 017, loss: 0.037 \n",
      "epoch: 007, batch: 018, loss: 0.128 \n",
      "epoch: 007, batch: 019, loss: 0.018 \n",
      "epoch: 007, batch: 020, loss: 0.137 \n",
      "epoch: 007, batch: 021, loss: 0.084 \n",
      "epoch: 007, batch: 022, loss: 0.006 \n",
      "epoch: 007, batch: 023, loss: 0.067 \n",
      "epoch: 007, batch: 024, loss: 0.072 \n",
      "epoch: 007, batch: 025, loss: 0.019 \n",
      "epoch: 007, batch: 026, loss: 0.001 \n",
      "epoch: 007, batch: 027, loss: 0.003 \n",
      "epoch: 007, batch: 028, loss: 0.009 \n",
      "epoch: 007, batch: 029, loss: 0.003 \n",
      "epoch: 007, batch: 030, loss: 0.291 \n",
      "epoch: 007, batch: 031, loss: 0.005 \n",
      "epoch: 007, batch: 032, loss: 0.002 \n",
      "epoch: 007, batch: 033, loss: 0.288 \n",
      "epoch: 007, batch: 034, loss: 0.041 \n",
      "epoch: 007, batch: 035, loss: 1.915 \n",
      "epoch: 007, batch: 036, loss: 0.226 \n",
      "epoch: 007, batch: 037, loss: 0.368 \n",
      "epoch: 007, batch: 038, loss: 0.717 \n",
      "epoch: 007, batch: 039, loss: 0.099 \n",
      "epoch: 007, batch: 040, loss: 0.040 \n",
      "epoch: 007, batch: 041, loss: 0.057 \n",
      "epoch: 007, batch: 042, loss: 0.013 \n",
      "epoch: 007, batch: 043, loss: 0.120 \n",
      "epoch: 007, batch: 044, loss: 0.090 \n",
      "epoch: 007, batch: 045, loss: 0.025 \n",
      "epoch: 007, batch: 046, loss: 0.014 \n",
      "epoch: 007, batch: 047, loss: 0.028 \n",
      "epoch: 007, batch: 048, loss: 0.010 \n",
      "epoch: 007, batch: 049, loss: 0.078 \n",
      "epoch: 007, batch: 050, loss: 0.228 \n",
      "epoch: 007, batch: 051, loss: 0.029 \n",
      "epoch: 007, batch: 052, loss: 0.017 \n",
      "epoch: 007, batch: 053, loss: 0.004 \n",
      "epoch: 007, batch: 054, loss: 0.115 \n",
      "epoch: 007, batch: 055, loss: 1.208 \n",
      "epoch: 007, batch: 056, loss: 0.031 \n",
      "epoch: 007, batch: 057, loss: 0.040 \n",
      "epoch: 007, batch: 058, loss: 0.062 \n",
      "epoch: 007, batch: 059, loss: 0.040 \n",
      "epoch: 007, batch: 060, loss: 0.055 \n",
      "epoch: 007, batch: 061, loss: 0.207 \n",
      "epoch: 007, batch: 062, loss: 0.052 \n",
      "epoch: 007, batch: 063, loss: 0.036 \n",
      "epoch: 007, batch: 064, loss: 0.077 \n",
      "epoch: 007, batch: 065, loss: 0.174 \n",
      "epoch: 007, batch: 066, loss: 0.330 \n",
      "epoch: 007, batch: 067, loss: 0.075 \n",
      "epoch: 007, batch: 068, loss: 0.112 \n",
      "epoch: 007, batch: 069, loss: 1.136 \n",
      "epoch: 007, batch: 070, loss: 0.009 \n",
      "epoch: 007, batch: 071, loss: 0.060 \n",
      "epoch: 007, batch: 072, loss: 0.334 \n",
      "epoch: 007, batch: 073, loss: 0.259 \n",
      "epoch: 007, batch: 074, loss: 0.124 \n",
      "epoch: 007, batch: 075, loss: 0.094 \n",
      "epoch: 007, batch: 076, loss: 0.008 \n",
      "epoch: 007, batch: 077, loss: 0.014 \n",
      "epoch: 007, batch: 078, loss: 0.041 \n",
      "epoch: 007, batch: 079, loss: 0.011 \n",
      "epoch: 007, batch: 080, loss: 0.342 \n",
      "epoch: 007, batch: 081, loss: 0.406 \n",
      "epoch: 007, batch: 082, loss: 0.102 \n",
      "epoch: 007, batch: 083, loss: 0.016 \n",
      "epoch: 007, batch: 084, loss: 0.009 \n",
      "epoch: 007, batch: 085, loss: 0.005 \n",
      "epoch: 007, batch: 086, loss: 0.006 \n",
      "epoch: 007, batch: 087, loss: 0.098 \n",
      "epoch: 007, batch: 088, loss: 0.006 \n",
      "epoch: 007, batch: 089, loss: 0.015 \n",
      "epoch: 007, batch: 090, loss: 0.030 \n",
      "epoch: 007, batch: 091, loss: 0.017 \n",
      "epoch: 007, batch: 092, loss: 0.238 \n",
      "epoch: 007, batch: 093, loss: 0.030 \n",
      "epoch: 007, batch: 094, loss: 0.033 \n",
      "epoch: 007, batch: 095, loss: 0.019 \n",
      "epoch: 007, batch: 096, loss: 0.006 \n",
      "epoch: 007, batch: 097, loss: 0.024 \n",
      "epoch: 007, batch: 098, loss: 0.009 \n",
      "epoch: 007, batch: 099, loss: 0.134 \n",
      "epoch: 007, batch: 100, loss: 0.003 \n",
      "epoch: 007, batch: 101, loss: 0.009 \n",
      "epoch: 007, batch: 102, loss: 0.012 \n",
      "epoch: 007, batch: 103, loss: 0.009 \n",
      "epoch: 007, batch: 104, loss: 0.034 \n",
      "epoch: 007, batch: 105, loss: 0.057 \n",
      "epoch: 007, batch: 106, loss: 0.174 \n",
      "epoch: 007, batch: 107, loss: 0.049 \n",
      "epoch: 007, batch: 108, loss: 0.024 \n",
      "epoch: 007, batch: 109, loss: 0.051 \n",
      "epoch: 007, batch: 110, loss: 0.005 \n",
      "epoch: 007, batch: 111, loss: 0.127 \n",
      "epoch: 007, batch: 112, loss: 0.002 \n",
      "epoch: 007, batch: 113, loss: 0.226 \n",
      "epoch: 007, batch: 114, loss: 0.011 \n",
      "epoch: 007, batch: 115, loss: 0.012 \n",
      "epoch: 007, batch: 116, loss: 0.030 \n",
      "epoch: 007, batch: 117, loss: 0.013 \n",
      "epoch: 007, batch: 118, loss: 0.045 \n",
      "epoch: 007, batch: 119, loss: 0.833 \n",
      "epoch: 007, batch: 120, loss: 0.065 \n",
      "epoch: 007, batch: 121, loss: 0.132 \n",
      "epoch: 007, batch: 122, loss: 0.079 \n",
      "epoch: 007, batch: 123, loss: 0.095 \n",
      "epoch: 007, batch: 124, loss: 0.025 \n",
      "epoch: 007, batch: 125, loss: 0.031 \n",
      "epoch: 007, batch: 126, loss: 0.008 \n",
      "epoch: 007, batch: 127, loss: 0.007 \n",
      "epoch: 007, batch: 128, loss: 0.006 \n",
      "epoch: 007, batch: 129, loss: 0.142 \n",
      "epoch: 007, batch: 130, loss: 0.154 \n",
      "epoch: 007, batch: 131, loss: 0.007 \n",
      "epoch: 007, batch: 132, loss: 0.117 \n",
      "epoch: 007, batch: 133, loss: 0.029 \n",
      "epoch: 007, batch: 134, loss: 0.051 \n",
      "epoch: 007, batch: 135, loss: 0.010 \n",
      "epoch: 007, batch: 136, loss: 0.025 \n",
      "epoch: 007, batch: 137, loss: 0.004 \n",
      "epoch: 007, batch: 138, loss: 0.110 \n",
      "epoch: 007, batch: 139, loss: 0.010 \n",
      "epoch: 007, batch: 140, loss: 0.219 \n",
      "epoch: 007, batch: 141, loss: 0.001 \n",
      "epoch: 007, batch: 142, loss: 0.005 \n",
      "epoch: 007, batch: 143, loss: 0.018 \n",
      "epoch: 007, batch: 144, loss: 0.010 \n",
      "epoch: 007, batch: 145, loss: 0.146 \n",
      "epoch: 007, batch: 146, loss: 0.087 \n",
      "epoch: 007, batch: 147, loss: 0.011 \n",
      "epoch: 007, batch: 148, loss: 0.025 \n",
      "epoch: 007, batch: 149, loss: 0.100 \n",
      "epoch: 007, batch: 150, loss: 0.319 \n",
      "epoch: 007, batch: 151, loss: 0.213 \n",
      "epoch: 007, batch: 152, loss: 0.424 \n",
      "epoch: 007, batch: 153, loss: 0.015 \n",
      "epoch: 007, batch: 154, loss: 0.140 \n",
      "epoch: 007, batch: 155, loss: 0.617 \n",
      "epoch: 007, batch: 156, loss: 0.004 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007, batch: 157, loss: 0.434 \n",
      "epoch: 007, batch: 158, loss: 0.006 \n",
      "epoch: 007, batch: 159, loss: 0.004 \n",
      "epoch: 007, batch: 160, loss: 0.065 \n",
      "epoch: 007, batch: 161, loss: 0.002 \n",
      "epoch: 007, batch: 162, loss: 0.004 \n",
      "epoch: 007, batch: 163, loss: 0.077 \n",
      "epoch: 007, batch: 164, loss: 0.102 \n",
      "epoch: 007, batch: 165, loss: 0.036 \n",
      "epoch: 007, batch: 166, loss: 0.002 \n",
      "epoch: 007, batch: 167, loss: 0.003 \n",
      "epoch: 007, batch: 168, loss: 0.005 \n",
      "epoch: 007, batch: 169, loss: 0.032 \n",
      "epoch: 007, batch: 170, loss: 0.026 \n",
      "epoch: 007, batch: 171, loss: 0.005 \n",
      "epoch: 007, batch: 172, loss: 0.001 \n",
      "epoch: 007, batch: 173, loss: 0.032 \n",
      "epoch: 007, batch: 174, loss: 0.032 \n",
      "epoch: 007, batch: 175, loss: 0.002 \n",
      "epoch: 007, batch: 176, loss: 0.102 \n",
      "epoch: 007, batch: 177, loss: 0.211 \n",
      "epoch: 007, batch: 178, loss: 0.337 \n",
      "epoch: 007, batch: 179, loss: 0.081 \n",
      "epoch: 007, batch: 180, loss: 0.112 \n",
      "epoch: 007, batch: 181, loss: 0.130 \n",
      "epoch: 007, batch: 182, loss: 0.069 \n",
      "epoch: 007, batch: 183, loss: 0.050 \n",
      "epoch: 007, batch: 184, loss: 0.117 \n",
      "epoch: 007, batch: 185, loss: 0.054 \n",
      "epoch: 007, batch: 186, loss: 0.205 \n",
      "epoch: 007, batch: 187, loss: 0.020 \n",
      "epoch: 007, batch: 188, loss: 0.038 \n",
      "epoch: 007, batch: 189, loss: 0.007 \n",
      "epoch: 007, batch: 190, loss: 0.803 \n",
      "epoch: 007, batch: 191, loss: 4.510 \n",
      "epoch: 007, batch: 192, loss: 0.309 \n",
      "epoch: 007, batch: 193, loss: 0.080 \n",
      "epoch: 007, batch: 194, loss: 0.010 \n",
      "epoch: 007, batch: 195, loss: 0.059 \n",
      "epoch: 007, batch: 196, loss: 0.033 \n",
      "epoch: 007, batch: 197, loss: 0.007 \n",
      "epoch: 007, batch: 198, loss: 0.005 \n",
      "epoch: 007, batch: 199, loss: 0.002 \n",
      "epoch: 007, batch: 200, loss: 0.029 \n",
      "epoch: 007, batch: 201, loss: 0.022 \n",
      "epoch: 007, batch: 202, loss: 0.019 \n",
      "epoch: 007, batch: 203, loss: 0.009 \n",
      "epoch: 007, batch: 204, loss: 0.114 \n",
      "epoch: 007, batch: 205, loss: 0.019 \n",
      "epoch: 007, batch: 206, loss: 0.017 \n",
      "epoch: 007, batch: 207, loss: 0.108 \n",
      "epoch: 007, batch: 208, loss: 0.026 \n",
      "epoch: 007, batch: 209, loss: 0.062 \n",
      "epoch: 007, batch: 210, loss: 0.004 \n",
      "epoch: 007, batch: 211, loss: 0.017 \n",
      "epoch: 007, batch: 212, loss: 0.049 \n",
      "epoch: 007, batch: 213, loss: 0.452 \n",
      "epoch: 007, batch: 214, loss: 0.003 \n",
      "epoch: 007, batch: 215, loss: 0.004 \n",
      "epoch: 007, batch: 216, loss: 0.018 \n",
      "epoch: 007, batch: 217, loss: 3.068 \n",
      "epoch: 007, batch: 218, loss: 0.161 \n",
      "epoch: 007, batch: 219, loss: 0.001 \n",
      "epoch: 007, batch: 220, loss: 0.493 \n",
      "epoch: 007, batch: 221, loss: 0.023 \n",
      "epoch: 007, batch: 222, loss: 0.040 \n",
      "epoch: 007, batch: 223, loss: 0.045 \n",
      "epoch: 007, batch: 224, loss: 0.008 \n",
      "epoch: 007, batch: 225, loss: 0.039 \n",
      "epoch: 007, batch: 226, loss: 0.124 \n",
      "epoch: 007, batch: 227, loss: 0.473 \n",
      "epoch: 007 ------------------------------------------------\n",
      "\n",
      "[train] loss: 28.201\n",
      "\n",
      "[validation] bulls_recall: 98.036%\n",
      "\n",
      "[validation] no_bulls_recall: 30.956%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.6449639153313753\n",
      "\n",
      "epoch: 008, batch: 001, loss: 0.017 \n",
      "epoch: 008, batch: 002, loss: 0.034 \n",
      "epoch: 008, batch: 003, loss: 0.006 \n",
      "epoch: 008, batch: 004, loss: 0.017 \n",
      "epoch: 008, batch: 005, loss: 0.726 \n",
      "epoch: 008, batch: 006, loss: 0.013 \n",
      "epoch: 008, batch: 007, loss: 0.013 \n",
      "epoch: 008, batch: 008, loss: 0.088 \n",
      "epoch: 008, batch: 009, loss: 0.014 \n",
      "epoch: 008, batch: 010, loss: 0.003 \n",
      "epoch: 008, batch: 011, loss: 0.278 \n",
      "epoch: 008, batch: 012, loss: 0.016 \n",
      "epoch: 008, batch: 013, loss: 0.005 \n",
      "epoch: 008, batch: 014, loss: 0.029 \n",
      "epoch: 008, batch: 015, loss: 0.016 \n",
      "epoch: 008, batch: 016, loss: 0.007 \n",
      "epoch: 008, batch: 017, loss: 0.750 \n",
      "epoch: 008, batch: 018, loss: 3.699 \n",
      "epoch: 008, batch: 019, loss: 0.014 \n",
      "epoch: 008, batch: 020, loss: 0.195 \n",
      "epoch: 008, batch: 021, loss: 0.009 \n",
      "epoch: 008, batch: 022, loss: 0.016 \n",
      "epoch: 008, batch: 023, loss: 0.069 \n",
      "epoch: 008, batch: 024, loss: 0.066 \n",
      "epoch: 008, batch: 025, loss: 0.042 \n",
      "epoch: 008, batch: 026, loss: 0.036 \n",
      "epoch: 008, batch: 027, loss: 0.106 \n",
      "epoch: 008, batch: 028, loss: 0.195 \n",
      "epoch: 008, batch: 029, loss: 0.011 \n",
      "epoch: 008, batch: 030, loss: 0.074 \n",
      "epoch: 008, batch: 031, loss: 0.032 \n",
      "epoch: 008, batch: 032, loss: 0.134 \n",
      "epoch: 008, batch: 033, loss: 0.066 \n",
      "epoch: 008, batch: 034, loss: 0.016 \n",
      "epoch: 008, batch: 035, loss: 0.039 \n",
      "epoch: 008, batch: 036, loss: 0.028 \n",
      "epoch: 008, batch: 037, loss: 0.078 \n",
      "epoch: 008, batch: 038, loss: 0.020 \n",
      "epoch: 008, batch: 039, loss: 0.011 \n",
      "epoch: 008, batch: 040, loss: 0.567 \n",
      "epoch: 008, batch: 041, loss: 0.029 \n",
      "epoch: 008, batch: 042, loss: 0.026 \n",
      "epoch: 008, batch: 043, loss: 0.014 \n",
      "epoch: 008, batch: 044, loss: 0.009 \n",
      "epoch: 008, batch: 045, loss: 0.025 \n",
      "epoch: 008, batch: 046, loss: 0.168 \n",
      "epoch: 008, batch: 047, loss: 0.204 \n",
      "epoch: 008, batch: 048, loss: 0.004 \n",
      "epoch: 008, batch: 049, loss: 0.829 \n",
      "epoch: 008, batch: 050, loss: 0.033 \n",
      "epoch: 008, batch: 051, loss: 0.054 \n",
      "epoch: 008, batch: 052, loss: 0.235 \n",
      "epoch: 008, batch: 053, loss: 0.058 \n",
      "epoch: 008, batch: 054, loss: 0.185 \n",
      "epoch: 008, batch: 055, loss: 0.099 \n",
      "epoch: 008, batch: 056, loss: 0.012 \n",
      "epoch: 008, batch: 057, loss: 0.043 \n",
      "epoch: 008, batch: 058, loss: 0.023 \n",
      "epoch: 008, batch: 059, loss: 0.085 \n",
      "epoch: 008, batch: 060, loss: 0.006 \n",
      "epoch: 008, batch: 061, loss: 0.008 \n",
      "epoch: 008, batch: 062, loss: 0.005 \n",
      "epoch: 008, batch: 063, loss: 0.002 \n",
      "epoch: 008, batch: 064, loss: 0.037 \n",
      "epoch: 008, batch: 065, loss: 0.003 \n",
      "epoch: 008, batch: 066, loss: 0.013 \n",
      "epoch: 008, batch: 067, loss: 0.041 \n",
      "epoch: 008, batch: 068, loss: 0.019 \n",
      "epoch: 008, batch: 069, loss: 0.021 \n",
      "epoch: 008, batch: 070, loss: 0.001 \n",
      "epoch: 008, batch: 071, loss: 0.002 \n",
      "epoch: 008, batch: 072, loss: 0.003 \n",
      "epoch: 008, batch: 073, loss: 0.015 \n",
      "epoch: 008, batch: 074, loss: 0.057 \n",
      "epoch: 008, batch: 075, loss: 0.098 \n",
      "epoch: 008, batch: 076, loss: 0.107 \n",
      "epoch: 008, batch: 077, loss: 0.006 \n",
      "epoch: 008, batch: 078, loss: 0.061 \n",
      "epoch: 008, batch: 079, loss: 0.007 \n",
      "epoch: 008, batch: 080, loss: 0.016 \n",
      "epoch: 008, batch: 081, loss: 0.005 \n",
      "epoch: 008, batch: 082, loss: 0.007 \n",
      "epoch: 008, batch: 083, loss: 0.011 \n",
      "epoch: 008, batch: 084, loss: 0.021 \n",
      "epoch: 008, batch: 085, loss: 0.009 \n",
      "epoch: 008, batch: 086, loss: 0.005 \n",
      "epoch: 008, batch: 087, loss: 0.017 \n",
      "epoch: 008, batch: 088, loss: 0.013 \n",
      "epoch: 008, batch: 089, loss: 0.020 \n",
      "epoch: 008, batch: 090, loss: 0.199 \n",
      "epoch: 008, batch: 091, loss: 0.019 \n",
      "epoch: 008, batch: 092, loss: 0.188 \n",
      "epoch: 008, batch: 093, loss: 0.011 \n",
      "epoch: 008, batch: 094, loss: 0.718 \n",
      "epoch: 008, batch: 095, loss: 0.127 \n",
      "epoch: 008, batch: 096, loss: 0.002 \n",
      "epoch: 008, batch: 097, loss: 0.136 \n",
      "epoch: 008, batch: 098, loss: 0.155 \n",
      "epoch: 008, batch: 099, loss: 0.053 \n",
      "epoch: 008, batch: 100, loss: 0.029 \n",
      "epoch: 008, batch: 101, loss: 0.003 \n",
      "epoch: 008, batch: 102, loss: 0.002 \n",
      "epoch: 008, batch: 103, loss: 0.002 \n",
      "epoch: 008, batch: 104, loss: 0.001 \n",
      "epoch: 008, batch: 105, loss: 0.028 \n",
      "epoch: 008, batch: 106, loss: 0.013 \n",
      "epoch: 008, batch: 107, loss: 0.001 \n",
      "epoch: 008, batch: 108, loss: 0.002 \n",
      "epoch: 008, batch: 109, loss: 0.001 \n",
      "epoch: 008, batch: 110, loss: 0.004 \n",
      "epoch: 008, batch: 111, loss: 0.212 \n",
      "epoch: 008, batch: 112, loss: 0.065 \n",
      "epoch: 008, batch: 113, loss: 0.129 \n",
      "epoch: 008, batch: 114, loss: 0.259 \n",
      "epoch: 008, batch: 115, loss: 0.003 \n",
      "epoch: 008, batch: 116, loss: 0.003 \n",
      "epoch: 008, batch: 117, loss: 0.018 \n",
      "epoch: 008, batch: 118, loss: 0.011 \n",
      "epoch: 008, batch: 119, loss: 0.011 \n",
      "epoch: 008, batch: 120, loss: 0.005 \n",
      "epoch: 008, batch: 121, loss: 0.067 \n",
      "epoch: 008, batch: 122, loss: 0.098 \n",
      "epoch: 008, batch: 123, loss: 0.019 \n",
      "epoch: 008, batch: 124, loss: 0.021 \n",
      "epoch: 008, batch: 125, loss: 0.052 \n",
      "epoch: 008, batch: 126, loss: 0.191 \n",
      "epoch: 008, batch: 127, loss: 0.019 \n",
      "epoch: 008, batch: 128, loss: 0.016 \n",
      "epoch: 008, batch: 129, loss: 0.035 \n",
      "epoch: 008, batch: 130, loss: 0.027 \n",
      "epoch: 008, batch: 131, loss: 0.138 \n",
      "epoch: 008, batch: 132, loss: 0.004 \n",
      "epoch: 008, batch: 133, loss: 0.033 \n",
      "epoch: 008, batch: 134, loss: 0.027 \n",
      "epoch: 008, batch: 135, loss: 0.010 \n",
      "epoch: 008, batch: 136, loss: 0.013 \n",
      "epoch: 008, batch: 137, loss: 0.108 \n",
      "epoch: 008, batch: 138, loss: 0.487 \n",
      "epoch: 008, batch: 139, loss: 0.356 \n",
      "epoch: 008, batch: 140, loss: 0.029 \n",
      "epoch: 008, batch: 141, loss: 0.004 \n",
      "epoch: 008, batch: 142, loss: 0.004 \n",
      "epoch: 008, batch: 143, loss: 0.479 \n",
      "epoch: 008, batch: 144, loss: 0.002 \n",
      "epoch: 008, batch: 145, loss: 0.015 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008, batch: 146, loss: 0.037 \n",
      "epoch: 008, batch: 147, loss: 0.002 \n",
      "epoch: 008, batch: 148, loss: 0.107 \n",
      "epoch: 008, batch: 149, loss: 0.002 \n",
      "epoch: 008, batch: 150, loss: 0.005 \n",
      "epoch: 008, batch: 151, loss: 0.077 \n",
      "epoch: 008, batch: 152, loss: 0.215 \n",
      "epoch: 008, batch: 153, loss: 0.038 \n",
      "epoch: 008, batch: 154, loss: 0.083 \n",
      "epoch: 008, batch: 155, loss: 0.034 \n",
      "epoch: 008, batch: 156, loss: 0.040 \n",
      "epoch: 008, batch: 157, loss: 0.029 \n",
      "epoch: 008, batch: 158, loss: 0.077 \n",
      "epoch: 008, batch: 159, loss: 0.085 \n",
      "epoch: 008, batch: 160, loss: 0.158 \n",
      "epoch: 008, batch: 161, loss: 0.044 \n",
      "epoch: 008, batch: 162, loss: 0.044 \n",
      "epoch: 008, batch: 163, loss: 0.036 \n",
      "epoch: 008, batch: 164, loss: 0.020 \n",
      "epoch: 008, batch: 165, loss: 0.017 \n",
      "epoch: 008, batch: 166, loss: 0.012 \n",
      "epoch: 008, batch: 167, loss: 0.088 \n",
      "epoch: 008, batch: 168, loss: 0.014 \n",
      "epoch: 008, batch: 169, loss: 0.023 \n",
      "epoch: 008, batch: 170, loss: 0.019 \n",
      "epoch: 008, batch: 171, loss: 0.028 \n",
      "epoch: 008, batch: 172, loss: 0.135 \n",
      "epoch: 008, batch: 173, loss: 0.012 \n",
      "epoch: 008, batch: 174, loss: 0.009 \n",
      "epoch: 008, batch: 175, loss: 0.039 \n",
      "epoch: 008, batch: 176, loss: 0.646 \n",
      "epoch: 008, batch: 177, loss: 0.012 \n",
      "epoch: 008, batch: 178, loss: 0.021 \n",
      "epoch: 008, batch: 179, loss: 0.013 \n",
      "epoch: 008, batch: 180, loss: 0.057 \n",
      "epoch: 008, batch: 181, loss: 0.002 \n",
      "epoch: 008, batch: 182, loss: 0.009 \n",
      "epoch: 008, batch: 183, loss: 0.006 \n",
      "epoch: 008, batch: 184, loss: 0.027 \n",
      "epoch: 008, batch: 185, loss: 0.077 \n",
      "epoch: 008, batch: 186, loss: 0.318 \n",
      "epoch: 008, batch: 187, loss: 0.000 \n",
      "epoch: 008, batch: 188, loss: 0.005 \n",
      "epoch: 008, batch: 189, loss: 0.001 \n",
      "epoch: 008, batch: 190, loss: 0.006 \n",
      "epoch: 008, batch: 191, loss: 0.004 \n",
      "epoch: 008, batch: 192, loss: 0.002 \n",
      "epoch: 008, batch: 193, loss: 0.005 \n",
      "epoch: 008, batch: 194, loss: 0.003 \n",
      "epoch: 008, batch: 195, loss: 0.003 \n",
      "epoch: 008, batch: 196, loss: 0.002 \n",
      "epoch: 008, batch: 197, loss: 0.001 \n",
      "epoch: 008, batch: 198, loss: 0.287 \n",
      "epoch: 008, batch: 199, loss: 0.210 \n",
      "epoch: 008, batch: 200, loss: 0.007 \n",
      "epoch: 008, batch: 201, loss: 0.081 \n",
      "epoch: 008, batch: 202, loss: 0.208 \n",
      "epoch: 008, batch: 203, loss: 0.003 \n",
      "epoch: 008, batch: 204, loss: 0.058 \n",
      "epoch: 008, batch: 205, loss: 0.064 \n",
      "epoch: 008, batch: 206, loss: 0.380 \n",
      "epoch: 008, batch: 207, loss: 0.263 \n",
      "epoch: 008, batch: 208, loss: 0.393 \n",
      "epoch: 008, batch: 209, loss: 0.010 \n",
      "epoch: 008, batch: 210, loss: 0.086 \n",
      "epoch: 008, batch: 211, loss: 0.001 \n",
      "epoch: 008, batch: 212, loss: 0.001 \n",
      "epoch: 008, batch: 213, loss: 0.003 \n",
      "epoch: 008, batch: 214, loss: 0.005 \n",
      "epoch: 008, batch: 215, loss: 0.236 \n",
      "epoch: 008, batch: 216, loss: 0.001 \n",
      "epoch: 008, batch: 217, loss: 0.001 \n",
      "epoch: 008, batch: 218, loss: 0.000 \n",
      "epoch: 008, batch: 219, loss: 0.006 \n",
      "epoch: 008, batch: 220, loss: 0.001 \n",
      "epoch: 008, batch: 221, loss: 0.001 \n",
      "epoch: 008, batch: 222, loss: 0.066 \n",
      "epoch: 008, batch: 223, loss: 0.002 \n",
      "epoch: 008, batch: 224, loss: 0.001 \n",
      "epoch: 008, batch: 225, loss: 0.007 \n",
      "epoch: 008, batch: 226, loss: 0.008 \n",
      "epoch: 008, batch: 227, loss: 0.004 \n",
      "epoch: 008 ------------------------------------------------\n",
      "\n",
      "[train] loss: 24.051\n",
      "\n",
      "[validation] bulls_recall: 98.597%\n",
      "\n",
      "[validation] no_bulls_recall: 54.882%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.7673916155144204\n",
      "\n",
      "epoch: 009, batch: 001, loss: 0.113 \n",
      "epoch: 009, batch: 002, loss: 0.009 \n",
      "epoch: 009, batch: 003, loss: 0.004 \n",
      "epoch: 009, batch: 004, loss: 0.253 \n",
      "epoch: 009, batch: 005, loss: 0.014 \n",
      "epoch: 009, batch: 006, loss: 0.021 \n",
      "epoch: 009, batch: 007, loss: 0.043 \n",
      "epoch: 009, batch: 008, loss: 0.126 \n",
      "epoch: 009, batch: 009, loss: 0.327 \n",
      "epoch: 009, batch: 010, loss: 0.209 \n",
      "epoch: 009, batch: 011, loss: 0.046 \n",
      "epoch: 009, batch: 012, loss: 0.027 \n",
      "epoch: 009, batch: 013, loss: 0.019 \n",
      "epoch: 009, batch: 014, loss: 0.050 \n",
      "epoch: 009, batch: 015, loss: 0.035 \n",
      "epoch: 009, batch: 016, loss: 0.054 \n",
      "epoch: 009, batch: 017, loss: 0.004 \n",
      "epoch: 009, batch: 018, loss: 0.028 \n",
      "epoch: 009, batch: 019, loss: 0.002 \n",
      "epoch: 009, batch: 020, loss: 0.019 \n",
      "epoch: 009, batch: 021, loss: 0.011 \n",
      "epoch: 009, batch: 022, loss: 0.015 \n",
      "epoch: 009, batch: 023, loss: 0.003 \n",
      "epoch: 009, batch: 024, loss: 0.101 \n",
      "epoch: 009, batch: 025, loss: 0.006 \n",
      "epoch: 009, batch: 026, loss: 0.003 \n",
      "epoch: 009, batch: 027, loss: 0.221 \n",
      "epoch: 009, batch: 028, loss: 0.007 \n",
      "epoch: 009, batch: 029, loss: 0.003 \n",
      "epoch: 009, batch: 030, loss: 0.002 \n",
      "epoch: 009, batch: 031, loss: 0.005 \n",
      "epoch: 009, batch: 032, loss: 0.006 \n",
      "epoch: 009, batch: 033, loss: 0.002 \n",
      "epoch: 009, batch: 034, loss: 0.004 \n",
      "epoch: 009, batch: 035, loss: 0.028 \n",
      "epoch: 009, batch: 036, loss: 0.018 \n",
      "epoch: 009, batch: 037, loss: 0.001 \n",
      "epoch: 009, batch: 038, loss: 0.020 \n",
      "epoch: 009, batch: 039, loss: 0.001 \n",
      "epoch: 009, batch: 040, loss: 0.040 \n",
      "epoch: 009, batch: 041, loss: 0.003 \n",
      "epoch: 009, batch: 042, loss: 0.001 \n",
      "epoch: 009, batch: 043, loss: 0.001 \n",
      "epoch: 009, batch: 044, loss: 0.005 \n",
      "epoch: 009, batch: 045, loss: 0.007 \n",
      "epoch: 009, batch: 046, loss: 0.010 \n",
      "epoch: 009, batch: 047, loss: 0.010 \n",
      "epoch: 009, batch: 048, loss: 0.187 \n",
      "epoch: 009, batch: 049, loss: 0.119 \n",
      "epoch: 009, batch: 050, loss: 0.017 \n",
      "epoch: 009, batch: 051, loss: 0.027 \n",
      "epoch: 009, batch: 052, loss: 0.045 \n",
      "epoch: 009, batch: 053, loss: 0.018 \n",
      "epoch: 009, batch: 054, loss: 0.097 \n",
      "epoch: 009, batch: 055, loss: 0.014 \n",
      "epoch: 009, batch: 056, loss: 0.047 \n",
      "epoch: 009, batch: 057, loss: 0.026 \n",
      "epoch: 009, batch: 058, loss: 0.371 \n",
      "epoch: 009, batch: 059, loss: 0.007 \n",
      "epoch: 009, batch: 060, loss: 0.080 \n",
      "epoch: 009, batch: 061, loss: 0.013 \n",
      "epoch: 009, batch: 062, loss: 0.010 \n",
      "epoch: 009, batch: 063, loss: 0.437 \n",
      "epoch: 009, batch: 064, loss: 0.009 \n",
      "epoch: 009, batch: 065, loss: 0.005 \n",
      "epoch: 009, batch: 066, loss: 0.077 \n",
      "epoch: 009, batch: 067, loss: 0.014 \n",
      "epoch: 009, batch: 068, loss: 0.017 \n",
      "epoch: 009, batch: 069, loss: 0.008 \n",
      "epoch: 009, batch: 070, loss: 0.006 \n",
      "epoch: 009, batch: 071, loss: 0.004 \n",
      "epoch: 009, batch: 072, loss: 0.006 \n",
      "epoch: 009, batch: 073, loss: 0.338 \n",
      "epoch: 009, batch: 074, loss: 0.014 \n",
      "epoch: 009, batch: 075, loss: 0.191 \n",
      "epoch: 009, batch: 076, loss: 0.354 \n",
      "epoch: 009, batch: 077, loss: 0.002 \n",
      "epoch: 009, batch: 078, loss: 0.023 \n",
      "epoch: 009, batch: 079, loss: 0.331 \n",
      "epoch: 009, batch: 080, loss: 0.202 \n",
      "epoch: 009, batch: 081, loss: 0.002 \n",
      "epoch: 009, batch: 082, loss: 0.129 \n",
      "epoch: 009, batch: 083, loss: 0.009 \n",
      "epoch: 009, batch: 084, loss: 0.002 \n",
      "epoch: 009, batch: 085, loss: 0.003 \n",
      "epoch: 009, batch: 086, loss: 0.002 \n",
      "epoch: 009, batch: 087, loss: 0.054 \n",
      "epoch: 009, batch: 088, loss: 0.001 \n",
      "epoch: 009, batch: 089, loss: 0.003 \n",
      "epoch: 009, batch: 090, loss: 0.000 \n",
      "epoch: 009, batch: 091, loss: 0.000 \n",
      "epoch: 009, batch: 092, loss: 0.030 \n",
      "epoch: 009, batch: 093, loss: 0.003 \n",
      "epoch: 009, batch: 094, loss: 0.003 \n",
      "epoch: 009, batch: 095, loss: 0.004 \n",
      "epoch: 009, batch: 096, loss: 0.005 \n",
      "epoch: 009, batch: 097, loss: 0.042 \n",
      "epoch: 009, batch: 098, loss: 0.011 \n",
      "epoch: 009, batch: 099, loss: 0.078 \n",
      "epoch: 009, batch: 100, loss: 0.091 \n",
      "epoch: 009, batch: 101, loss: 0.010 \n",
      "epoch: 009, batch: 102, loss: 0.367 \n",
      "epoch: 009, batch: 103, loss: 0.015 \n",
      "epoch: 009, batch: 104, loss: 0.044 \n",
      "epoch: 009, batch: 105, loss: 0.070 \n",
      "epoch: 009, batch: 106, loss: 0.012 \n",
      "epoch: 009, batch: 107, loss: 0.019 \n",
      "epoch: 009, batch: 108, loss: 0.013 \n",
      "epoch: 009, batch: 109, loss: 0.086 \n",
      "epoch: 009, batch: 110, loss: 0.023 \n",
      "epoch: 009, batch: 111, loss: 0.041 \n",
      "epoch: 009, batch: 112, loss: 0.099 \n",
      "epoch: 009, batch: 113, loss: 0.044 \n",
      "epoch: 009, batch: 114, loss: 0.112 \n",
      "epoch: 009, batch: 115, loss: 0.595 \n",
      "epoch: 009, batch: 116, loss: 0.124 \n",
      "epoch: 009, batch: 117, loss: 0.305 \n",
      "epoch: 009, batch: 118, loss: 0.015 \n",
      "epoch: 009, batch: 119, loss: 0.078 \n",
      "epoch: 009, batch: 120, loss: 0.003 \n",
      "epoch: 009, batch: 121, loss: 0.015 \n",
      "epoch: 009, batch: 122, loss: 0.005 \n",
      "epoch: 009, batch: 123, loss: 0.020 \n",
      "epoch: 009, batch: 124, loss: 0.012 \n",
      "epoch: 009, batch: 125, loss: 0.005 \n",
      "epoch: 009, batch: 126, loss: 0.003 \n",
      "epoch: 009, batch: 127, loss: 0.000 \n",
      "epoch: 009, batch: 128, loss: 0.003 \n",
      "epoch: 009, batch: 129, loss: 0.006 \n",
      "epoch: 009, batch: 130, loss: 0.002 \n",
      "epoch: 009, batch: 131, loss: 0.058 \n",
      "epoch: 009, batch: 132, loss: 0.014 \n",
      "epoch: 009, batch: 133, loss: 0.002 \n",
      "epoch: 009, batch: 134, loss: 0.232 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009, batch: 135, loss: 0.003 \n",
      "epoch: 009, batch: 136, loss: 0.042 \n",
      "epoch: 009, batch: 137, loss: 0.001 \n",
      "epoch: 009, batch: 138, loss: 0.002 \n",
      "epoch: 009, batch: 139, loss: 0.006 \n",
      "epoch: 009, batch: 140, loss: 0.007 \n",
      "epoch: 009, batch: 141, loss: 0.156 \n",
      "epoch: 009, batch: 142, loss: 1.540 \n",
      "epoch: 009, batch: 143, loss: 0.430 \n",
      "epoch: 009, batch: 144, loss: 0.356 \n",
      "epoch: 009, batch: 145, loss: 0.012 \n",
      "epoch: 009, batch: 146, loss: 0.032 \n",
      "epoch: 009, batch: 147, loss: 0.039 \n",
      "epoch: 009, batch: 148, loss: 0.024 \n",
      "epoch: 009, batch: 149, loss: 0.003 \n",
      "epoch: 009, batch: 150, loss: 0.179 \n",
      "epoch: 009, batch: 151, loss: 0.035 \n",
      "epoch: 009, batch: 152, loss: 0.008 \n",
      "epoch: 009, batch: 153, loss: 0.142 \n",
      "epoch: 009, batch: 154, loss: 0.005 \n",
      "epoch: 009, batch: 155, loss: 0.087 \n",
      "epoch: 009, batch: 156, loss: 0.009 \n",
      "epoch: 009, batch: 157, loss: 0.084 \n",
      "epoch: 009, batch: 158, loss: 0.013 \n",
      "epoch: 009, batch: 159, loss: 0.009 \n",
      "epoch: 009, batch: 160, loss: 0.009 \n",
      "epoch: 009, batch: 161, loss: 0.106 \n",
      "epoch: 009, batch: 162, loss: 0.012 \n",
      "epoch: 009, batch: 163, loss: 0.025 \n",
      "epoch: 009, batch: 164, loss: 0.021 \n",
      "epoch: 009, batch: 165, loss: 0.034 \n",
      "epoch: 009, batch: 166, loss: 0.002 \n",
      "epoch: 009, batch: 167, loss: 0.008 \n",
      "epoch: 009, batch: 168, loss: 0.372 \n",
      "epoch: 009, batch: 169, loss: 0.008 \n",
      "epoch: 009, batch: 170, loss: 0.003 \n",
      "epoch: 009, batch: 171, loss: 0.006 \n",
      "epoch: 009, batch: 172, loss: 0.009 \n",
      "epoch: 009, batch: 173, loss: 0.041 \n",
      "epoch: 009, batch: 174, loss: 0.007 \n",
      "epoch: 009, batch: 175, loss: 0.010 \n",
      "epoch: 009, batch: 176, loss: 0.008 \n",
      "epoch: 009, batch: 177, loss: 0.013 \n",
      "epoch: 009, batch: 178, loss: 0.005 \n",
      "epoch: 009, batch: 179, loss: 0.008 \n",
      "epoch: 009, batch: 180, loss: 0.011 \n",
      "epoch: 009, batch: 181, loss: 0.060 \n",
      "epoch: 009, batch: 182, loss: 0.093 \n",
      "epoch: 009, batch: 183, loss: 0.005 \n",
      "epoch: 009, batch: 184, loss: 0.007 \n",
      "epoch: 009, batch: 185, loss: 0.049 \n",
      "epoch: 009, batch: 186, loss: 0.123 \n",
      "epoch: 009, batch: 187, loss: 0.008 \n",
      "epoch: 009, batch: 188, loss: 0.009 \n",
      "epoch: 009, batch: 189, loss: 0.241 \n",
      "epoch: 009, batch: 190, loss: 3.171 \n",
      "epoch: 009, batch: 191, loss: 0.036 \n",
      "epoch: 009, batch: 192, loss: 0.003 \n",
      "epoch: 009, batch: 193, loss: 0.010 \n",
      "epoch: 009, batch: 194, loss: 0.006 \n",
      "epoch: 009, batch: 195, loss: 0.008 \n",
      "epoch: 009, batch: 196, loss: 0.007 \n",
      "epoch: 009, batch: 197, loss: 0.069 \n",
      "epoch: 009, batch: 198, loss: 0.001 \n",
      "epoch: 009, batch: 199, loss: 0.007 \n",
      "epoch: 009, batch: 200, loss: 0.001 \n",
      "epoch: 009, batch: 201, loss: 0.016 \n",
      "epoch: 009, batch: 202, loss: 0.039 \n",
      "epoch: 009, batch: 203, loss: 0.002 \n",
      "epoch: 009, batch: 204, loss: 0.048 \n",
      "epoch: 009, batch: 205, loss: 0.006 \n",
      "epoch: 009, batch: 206, loss: 0.076 \n",
      "epoch: 009, batch: 207, loss: 0.002 \n",
      "epoch: 009, batch: 208, loss: 0.004 \n",
      "epoch: 009, batch: 209, loss: 0.002 \n",
      "epoch: 009, batch: 210, loss: 0.196 \n",
      "epoch: 009, batch: 211, loss: 0.075 \n",
      "epoch: 009, batch: 212, loss: 0.882 \n",
      "epoch: 009, batch: 213, loss: 0.020 \n",
      "epoch: 009, batch: 214, loss: 0.004 \n",
      "epoch: 009, batch: 215, loss: 0.003 \n",
      "epoch: 009, batch: 216, loss: 0.287 \n",
      "epoch: 009, batch: 217, loss: 0.004 \n",
      "epoch: 009, batch: 218, loss: 0.017 \n",
      "epoch: 009, batch: 219, loss: 0.003 \n",
      "epoch: 009, batch: 220, loss: 0.002 \n",
      "epoch: 009, batch: 221, loss: 0.057 \n",
      "epoch: 009, batch: 222, loss: 0.003 \n",
      "epoch: 009, batch: 223, loss: 0.015 \n",
      "epoch: 009, batch: 224, loss: 0.008 \n",
      "epoch: 009, batch: 225, loss: 0.008 \n",
      "epoch: 009, batch: 226, loss: 0.003 \n",
      "epoch: 009, batch: 227, loss: 0.003 \n",
      "epoch: 009 ------------------------------------------------\n",
      "\n",
      "[train] loss: 19.327\n",
      "\n",
      "[validation] bulls_recall: 99.437%\n",
      "\n",
      "[validation] no_bulls_recall: 15.073%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5725486367259304\n",
      "\n",
      "epoch: 010, batch: 001, loss: 0.020 \n",
      "epoch: 010, batch: 002, loss: 0.003 \n",
      "epoch: 010, batch: 003, loss: 0.069 \n",
      "epoch: 010, batch: 004, loss: 0.031 \n",
      "epoch: 010, batch: 005, loss: 0.007 \n",
      "epoch: 010, batch: 006, loss: 0.007 \n",
      "epoch: 010, batch: 007, loss: 0.179 \n",
      "epoch: 010, batch: 008, loss: 0.003 \n",
      "epoch: 010, batch: 009, loss: 3.831 \n",
      "epoch: 010, batch: 010, loss: 0.002 \n",
      "epoch: 010, batch: 011, loss: 0.003 \n",
      "epoch: 010, batch: 012, loss: 0.004 \n",
      "epoch: 010, batch: 013, loss: 0.002 \n",
      "epoch: 010, batch: 014, loss: 0.004 \n",
      "epoch: 010, batch: 015, loss: 0.011 \n",
      "epoch: 010, batch: 016, loss: 3.992 \n",
      "epoch: 010, batch: 017, loss: 0.004 \n",
      "epoch: 010, batch: 018, loss: 0.005 \n",
      "epoch: 010, batch: 019, loss: 1.061 \n",
      "epoch: 010, batch: 020, loss: 0.015 \n",
      "epoch: 010, batch: 021, loss: 0.075 \n",
      "epoch: 010, batch: 022, loss: 0.004 \n",
      "epoch: 010, batch: 023, loss: 0.164 \n",
      "epoch: 010, batch: 024, loss: 0.003 \n",
      "epoch: 010, batch: 025, loss: 0.020 \n",
      "epoch: 010, batch: 026, loss: 0.020 \n",
      "epoch: 010, batch: 027, loss: 0.147 \n",
      "epoch: 010, batch: 028, loss: 0.074 \n",
      "epoch: 010, batch: 029, loss: 0.008 \n",
      "epoch: 010, batch: 030, loss: 0.035 \n",
      "epoch: 010, batch: 031, loss: 0.012 \n",
      "epoch: 010, batch: 032, loss: 0.086 \n",
      "epoch: 010, batch: 033, loss: 0.097 \n",
      "epoch: 010, batch: 034, loss: 0.039 \n",
      "epoch: 010, batch: 035, loss: 0.202 \n",
      "epoch: 010, batch: 036, loss: 0.139 \n",
      "epoch: 010, batch: 037, loss: 1.166 \n",
      "epoch: 010, batch: 038, loss: 0.010 \n",
      "epoch: 010, batch: 039, loss: 0.041 \n",
      "epoch: 010, batch: 040, loss: 0.012 \n",
      "epoch: 010, batch: 041, loss: 0.018 \n",
      "epoch: 010, batch: 042, loss: 0.152 \n",
      "epoch: 010, batch: 043, loss: 0.025 \n",
      "epoch: 010, batch: 044, loss: 0.005 \n",
      "epoch: 010, batch: 045, loss: 0.010 \n",
      "epoch: 010, batch: 046, loss: 0.058 \n",
      "epoch: 010, batch: 047, loss: 0.024 \n",
      "epoch: 010, batch: 048, loss: 0.004 \n",
      "epoch: 010, batch: 049, loss: 0.018 \n",
      "epoch: 010, batch: 050, loss: 0.013 \n",
      "epoch: 010, batch: 051, loss: 0.062 \n",
      "epoch: 010, batch: 052, loss: 0.010 \n",
      "epoch: 010, batch: 053, loss: 0.052 \n",
      "epoch: 010, batch: 054, loss: 0.048 \n",
      "epoch: 010, batch: 055, loss: 0.077 \n",
      "epoch: 010, batch: 056, loss: 0.005 \n",
      "epoch: 010, batch: 057, loss: 0.015 \n",
      "epoch: 010, batch: 058, loss: 0.017 \n",
      "epoch: 010, batch: 059, loss: 0.486 \n",
      "epoch: 010, batch: 060, loss: 0.007 \n",
      "epoch: 010, batch: 061, loss: 0.020 \n",
      "epoch: 010, batch: 062, loss: 0.012 \n",
      "epoch: 010, batch: 063, loss: 0.218 \n",
      "epoch: 010, batch: 064, loss: 0.004 \n",
      "epoch: 010, batch: 065, loss: 0.009 \n",
      "epoch: 010, batch: 066, loss: 0.003 \n",
      "epoch: 010, batch: 067, loss: 0.004 \n",
      "epoch: 010, batch: 068, loss: 0.001 \n",
      "epoch: 010, batch: 069, loss: 0.001 \n",
      "epoch: 010, batch: 070, loss: 0.004 \n",
      "epoch: 010, batch: 071, loss: 0.002 \n",
      "epoch: 010, batch: 072, loss: 0.006 \n",
      "epoch: 010, batch: 073, loss: 0.004 \n",
      "epoch: 010, batch: 074, loss: 0.026 \n",
      "epoch: 010, batch: 075, loss: 0.003 \n",
      "epoch: 010, batch: 076, loss: 0.075 \n",
      "epoch: 010, batch: 077, loss: 0.004 \n",
      "epoch: 010, batch: 078, loss: 0.002 \n",
      "epoch: 010, batch: 079, loss: 0.032 \n",
      "epoch: 010, batch: 080, loss: 0.034 \n",
      "epoch: 010, batch: 081, loss: 0.076 \n",
      "epoch: 010, batch: 082, loss: 0.002 \n",
      "epoch: 010, batch: 083, loss: 0.001 \n",
      "epoch: 010, batch: 084, loss: 0.001 \n",
      "epoch: 010, batch: 085, loss: 0.002 \n",
      "epoch: 010, batch: 086, loss: 0.001 \n",
      "epoch: 010, batch: 087, loss: 0.002 \n",
      "epoch: 010, batch: 088, loss: 0.016 \n",
      "epoch: 010, batch: 089, loss: 3.634 \n",
      "epoch: 010, batch: 090, loss: 0.005 \n",
      "epoch: 010, batch: 091, loss: 0.024 \n",
      "epoch: 010, batch: 092, loss: 0.009 \n",
      "epoch: 010, batch: 093, loss: 0.004 \n",
      "epoch: 010, batch: 094, loss: 0.011 \n",
      "epoch: 010, batch: 095, loss: 0.060 \n",
      "epoch: 010, batch: 096, loss: 0.907 \n",
      "epoch: 010, batch: 097, loss: 0.009 \n",
      "epoch: 010, batch: 098, loss: 0.275 \n",
      "epoch: 010, batch: 099, loss: 0.002 \n",
      "epoch: 010, batch: 100, loss: 0.002 \n",
      "epoch: 010, batch: 101, loss: 0.023 \n",
      "epoch: 010, batch: 102, loss: 0.015 \n",
      "epoch: 010, batch: 103, loss: 0.956 \n",
      "epoch: 010, batch: 104, loss: 0.003 \n",
      "epoch: 010, batch: 105, loss: 0.521 \n",
      "epoch: 010, batch: 106, loss: 0.061 \n",
      "epoch: 010, batch: 107, loss: 0.007 \n",
      "epoch: 010, batch: 108, loss: 0.006 \n",
      "epoch: 010, batch: 109, loss: 0.215 \n",
      "epoch: 010, batch: 110, loss: 0.025 \n",
      "epoch: 010, batch: 111, loss: 0.048 \n",
      "epoch: 010, batch: 112, loss: 0.281 \n",
      "epoch: 010, batch: 113, loss: 0.211 \n",
      "epoch: 010, batch: 114, loss: 0.013 \n",
      "epoch: 010, batch: 115, loss: 0.006 \n",
      "epoch: 010, batch: 116, loss: 0.001 \n",
      "epoch: 010, batch: 117, loss: 0.205 \n",
      "epoch: 010, batch: 118, loss: 0.014 \n",
      "epoch: 010, batch: 119, loss: 0.008 \n",
      "epoch: 010, batch: 120, loss: 0.020 \n",
      "epoch: 010, batch: 121, loss: 0.103 \n",
      "epoch: 010, batch: 122, loss: 0.013 \n",
      "epoch: 010, batch: 123, loss: 1.091 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010, batch: 124, loss: 0.034 \n",
      "epoch: 010, batch: 125, loss: 0.079 \n",
      "epoch: 010, batch: 126, loss: 0.106 \n",
      "epoch: 010, batch: 127, loss: 0.036 \n",
      "epoch: 010, batch: 128, loss: 0.024 \n",
      "epoch: 010, batch: 129, loss: 0.063 \n",
      "epoch: 010, batch: 130, loss: 0.083 \n",
      "epoch: 010, batch: 131, loss: 0.040 \n",
      "epoch: 010, batch: 132, loss: 0.025 \n",
      "epoch: 010, batch: 133, loss: 0.008 \n",
      "epoch: 010, batch: 134, loss: 0.018 \n",
      "epoch: 010, batch: 135, loss: 0.244 \n",
      "epoch: 010, batch: 136, loss: 0.026 \n",
      "epoch: 010, batch: 137, loss: 0.014 \n",
      "epoch: 010, batch: 138, loss: 0.003 \n",
      "epoch: 010, batch: 139, loss: 0.804 \n",
      "epoch: 010, batch: 140, loss: 0.008 \n",
      "epoch: 010, batch: 141, loss: 0.038 \n",
      "epoch: 010, batch: 142, loss: 0.055 \n",
      "epoch: 010, batch: 143, loss: 0.053 \n",
      "epoch: 010, batch: 144, loss: 0.531 \n",
      "epoch: 010, batch: 145, loss: 0.007 \n",
      "epoch: 010, batch: 146, loss: 0.016 \n",
      "epoch: 010, batch: 147, loss: 0.024 \n",
      "epoch: 010, batch: 148, loss: 0.009 \n",
      "epoch: 010, batch: 149, loss: 0.071 \n",
      "epoch: 010, batch: 150, loss: 0.000 \n",
      "epoch: 010, batch: 151, loss: 0.024 \n",
      "epoch: 010, batch: 152, loss: 0.009 \n",
      "epoch: 010, batch: 153, loss: 0.001 \n",
      "epoch: 010, batch: 154, loss: 0.004 \n",
      "epoch: 010, batch: 155, loss: 0.005 \n",
      "epoch: 010, batch: 156, loss: 0.502 \n",
      "epoch: 010, batch: 157, loss: 0.001 \n",
      "epoch: 010, batch: 158, loss: 0.009 \n",
      "epoch: 010, batch: 159, loss: 0.348 \n",
      "epoch: 010, batch: 160, loss: 0.002 \n",
      "epoch: 010, batch: 161, loss: 0.003 \n",
      "epoch: 010, batch: 162, loss: 0.007 \n",
      "epoch: 010, batch: 163, loss: 0.006 \n",
      "epoch: 010, batch: 164, loss: 0.006 \n",
      "epoch: 010, batch: 165, loss: 0.003 \n",
      "epoch: 010, batch: 166, loss: 0.011 \n",
      "epoch: 010, batch: 167, loss: 0.339 \n",
      "epoch: 010, batch: 168, loss: 0.047 \n",
      "epoch: 010, batch: 169, loss: 0.024 \n",
      "epoch: 010, batch: 170, loss: 0.076 \n",
      "epoch: 010, batch: 171, loss: 0.054 \n",
      "epoch: 010, batch: 172, loss: 0.006 \n",
      "epoch: 010, batch: 173, loss: 0.416 \n",
      "epoch: 010, batch: 174, loss: 0.004 \n",
      "epoch: 010, batch: 175, loss: 0.047 \n",
      "epoch: 010, batch: 176, loss: 0.011 \n",
      "epoch: 010, batch: 177, loss: 0.002 \n",
      "epoch: 010, batch: 178, loss: 0.004 \n",
      "epoch: 010, batch: 179, loss: 0.017 \n",
      "epoch: 010, batch: 180, loss: 0.009 \n",
      "epoch: 010, batch: 181, loss: 0.165 \n",
      "epoch: 010, batch: 182, loss: 0.045 \n",
      "epoch: 010, batch: 183, loss: 0.009 \n",
      "epoch: 010, batch: 184, loss: 0.009 \n",
      "epoch: 010, batch: 185, loss: 0.011 \n",
      "epoch: 010, batch: 186, loss: 0.002 \n",
      "epoch: 010, batch: 187, loss: 0.144 \n",
      "epoch: 010, batch: 188, loss: 0.197 \n",
      "epoch: 010, batch: 189, loss: 0.006 \n",
      "epoch: 010, batch: 190, loss: 0.000 \n",
      "epoch: 010, batch: 191, loss: 0.030 \n",
      "epoch: 010, batch: 192, loss: 0.004 \n",
      "epoch: 010, batch: 193, loss: 0.007 \n",
      "epoch: 010, batch: 194, loss: 0.033 \n",
      "epoch: 010, batch: 195, loss: 0.075 \n",
      "epoch: 010, batch: 196, loss: 0.026 \n",
      "epoch: 010, batch: 197, loss: 0.015 \n",
      "epoch: 010, batch: 198, loss: 0.077 \n",
      "epoch: 010, batch: 199, loss: 0.006 \n",
      "epoch: 010, batch: 200, loss: 0.005 \n",
      "epoch: 010, batch: 201, loss: 0.108 \n",
      "epoch: 010, batch: 202, loss: 0.003 \n",
      "epoch: 010, batch: 203, loss: 0.003 \n",
      "epoch: 010, batch: 204, loss: 0.007 \n",
      "epoch: 010, batch: 205, loss: 0.054 \n",
      "epoch: 010, batch: 206, loss: 0.199 \n",
      "epoch: 010, batch: 207, loss: 0.001 \n",
      "epoch: 010, batch: 208, loss: 0.145 \n",
      "epoch: 010, batch: 209, loss: 0.007 \n",
      "epoch: 010, batch: 210, loss: 0.009 \n",
      "epoch: 010, batch: 211, loss: 0.016 \n",
      "epoch: 010, batch: 212, loss: 0.036 \n",
      "epoch: 010, batch: 213, loss: 0.409 \n",
      "epoch: 010, batch: 214, loss: 0.005 \n",
      "epoch: 010, batch: 215, loss: 0.013 \n",
      "epoch: 010, batch: 216, loss: 0.004 \n",
      "epoch: 010, batch: 217, loss: 0.006 \n",
      "epoch: 010, batch: 218, loss: 0.007 \n",
      "epoch: 010, batch: 219, loss: 0.005 \n",
      "epoch: 010, batch: 220, loss: 0.289 \n",
      "epoch: 010, batch: 221, loss: 0.004 \n",
      "epoch: 010, batch: 222, loss: 0.116 \n",
      "epoch: 010, batch: 223, loss: 0.020 \n",
      "epoch: 010, batch: 224, loss: 0.093 \n",
      "epoch: 010, batch: 225, loss: 0.007 \n",
      "epoch: 010, batch: 226, loss: 0.005 \n",
      "epoch: 010, batch: 227, loss: 0.001 \n",
      "epoch: 010 ------------------------------------------------\n",
      "\n",
      "[train] loss: 20.228\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 8.275%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5413610460229273\n",
      "\n",
      "epoch: 011, batch: 001, loss: 3.444 \n",
      "epoch: 011, batch: 002, loss: 0.061 \n",
      "epoch: 011, batch: 003, loss: 0.097 \n",
      "epoch: 011, batch: 004, loss: 0.003 \n",
      "epoch: 011, batch: 005, loss: 0.011 \n",
      "epoch: 011, batch: 006, loss: 0.215 \n",
      "epoch: 011, batch: 007, loss: 0.035 \n",
      "epoch: 011, batch: 008, loss: 0.267 \n",
      "epoch: 011, batch: 009, loss: 0.255 \n",
      "epoch: 011, batch: 010, loss: 0.012 \n",
      "epoch: 011, batch: 011, loss: 0.009 \n",
      "epoch: 011, batch: 012, loss: 0.005 \n",
      "epoch: 011, batch: 013, loss: 0.083 \n",
      "epoch: 011, batch: 014, loss: 0.014 \n",
      "epoch: 011, batch: 015, loss: 0.003 \n",
      "epoch: 011, batch: 016, loss: 0.004 \n",
      "epoch: 011, batch: 017, loss: 0.012 \n",
      "epoch: 011, batch: 018, loss: 0.004 \n",
      "epoch: 011, batch: 019, loss: 0.003 \n",
      "epoch: 011, batch: 020, loss: 0.122 \n",
      "epoch: 011, batch: 021, loss: 0.001 \n",
      "epoch: 011, batch: 022, loss: 0.003 \n",
      "epoch: 011, batch: 023, loss: 0.003 \n",
      "epoch: 011, batch: 024, loss: 0.003 \n",
      "epoch: 011, batch: 025, loss: 0.008 \n",
      "epoch: 011, batch: 026, loss: 0.012 \n",
      "epoch: 011, batch: 027, loss: 0.004 \n",
      "epoch: 011, batch: 028, loss: 0.007 \n",
      "epoch: 011, batch: 029, loss: 0.007 \n",
      "epoch: 011, batch: 030, loss: 0.011 \n",
      "epoch: 011, batch: 031, loss: 0.044 \n",
      "epoch: 011, batch: 032, loss: 0.005 \n",
      "epoch: 011, batch: 033, loss: 0.077 \n",
      "epoch: 011, batch: 034, loss: 0.004 \n",
      "epoch: 011, batch: 035, loss: 0.013 \n",
      "epoch: 011, batch: 036, loss: 0.002 \n",
      "epoch: 011, batch: 037, loss: 0.004 \n",
      "epoch: 011, batch: 038, loss: 0.007 \n",
      "epoch: 011, batch: 039, loss: 0.008 \n",
      "epoch: 011, batch: 040, loss: 0.003 \n",
      "epoch: 011, batch: 041, loss: 0.003 \n",
      "epoch: 011, batch: 042, loss: 0.002 \n",
      "epoch: 011, batch: 043, loss: 0.004 \n",
      "epoch: 011, batch: 044, loss: 0.725 \n",
      "epoch: 011, batch: 045, loss: 0.478 \n",
      "epoch: 011, batch: 046, loss: 0.030 \n",
      "epoch: 011, batch: 047, loss: 0.079 \n",
      "epoch: 011, batch: 048, loss: 0.010 \n",
      "epoch: 011, batch: 049, loss: 0.019 \n",
      "epoch: 011, batch: 050, loss: 0.015 \n",
      "epoch: 011, batch: 051, loss: 0.010 \n",
      "epoch: 011, batch: 052, loss: 0.092 \n",
      "epoch: 011, batch: 053, loss: 0.148 \n",
      "epoch: 011, batch: 054, loss: 0.096 \n",
      "epoch: 011, batch: 055, loss: 0.015 \n",
      "epoch: 011, batch: 056, loss: 0.018 \n",
      "epoch: 011, batch: 057, loss: 0.030 \n",
      "epoch: 011, batch: 058, loss: 0.019 \n",
      "epoch: 011, batch: 059, loss: 0.004 \n",
      "epoch: 011, batch: 060, loss: 0.047 \n",
      "epoch: 011, batch: 061, loss: 0.014 \n",
      "epoch: 011, batch: 062, loss: 0.003 \n",
      "epoch: 011, batch: 063, loss: 0.007 \n",
      "epoch: 011, batch: 064, loss: 0.008 \n",
      "epoch: 011, batch: 065, loss: 0.100 \n",
      "epoch: 011, batch: 066, loss: 0.005 \n",
      "epoch: 011, batch: 067, loss: 0.014 \n",
      "epoch: 011, batch: 068, loss: 0.007 \n",
      "epoch: 011, batch: 069, loss: 0.010 \n",
      "epoch: 011, batch: 070, loss: 0.015 \n",
      "epoch: 011, batch: 071, loss: 0.133 \n",
      "epoch: 011, batch: 072, loss: 0.002 \n",
      "epoch: 011, batch: 073, loss: 0.001 \n",
      "epoch: 011, batch: 074, loss: 0.514 \n",
      "epoch: 011, batch: 075, loss: 0.001 \n",
      "epoch: 011, batch: 076, loss: 0.015 \n",
      "epoch: 011, batch: 077, loss: 0.004 \n",
      "epoch: 011, batch: 078, loss: 0.052 \n",
      "epoch: 011, batch: 079, loss: 0.004 \n",
      "epoch: 011, batch: 080, loss: 0.001 \n",
      "epoch: 011, batch: 081, loss: 0.074 \n",
      "epoch: 011, batch: 082, loss: 0.001 \n",
      "epoch: 011, batch: 083, loss: 0.001 \n",
      "epoch: 011, batch: 084, loss: 0.085 \n",
      "epoch: 011, batch: 085, loss: 0.002 \n",
      "epoch: 011, batch: 086, loss: 0.001 \n",
      "epoch: 011, batch: 087, loss: 0.000 \n",
      "epoch: 011, batch: 088, loss: 0.020 \n",
      "epoch: 011, batch: 089, loss: 0.060 \n",
      "epoch: 011, batch: 090, loss: 0.005 \n",
      "epoch: 011, batch: 091, loss: 0.004 \n",
      "epoch: 011, batch: 092, loss: 0.010 \n",
      "epoch: 011, batch: 093, loss: 0.077 \n",
      "epoch: 011, batch: 094, loss: 0.034 \n",
      "epoch: 011, batch: 095, loss: 0.009 \n",
      "epoch: 011, batch: 096, loss: 0.019 \n",
      "epoch: 011, batch: 097, loss: 0.001 \n",
      "epoch: 011, batch: 098, loss: 0.001 \n",
      "epoch: 011, batch: 099, loss: 0.020 \n",
      "epoch: 011, batch: 100, loss: 0.098 \n",
      "epoch: 011, batch: 101, loss: 0.111 \n",
      "epoch: 011, batch: 102, loss: 0.018 \n",
      "epoch: 011, batch: 103, loss: 0.010 \n",
      "epoch: 011, batch: 104, loss: 0.063 \n",
      "epoch: 011, batch: 105, loss: 0.004 \n",
      "epoch: 011, batch: 106, loss: 0.059 \n",
      "epoch: 011, batch: 107, loss: 0.022 \n",
      "epoch: 011, batch: 108, loss: 0.009 \n",
      "epoch: 011, batch: 109, loss: 0.004 \n",
      "epoch: 011, batch: 110, loss: 0.009 \n",
      "epoch: 011, batch: 111, loss: 0.004 \n",
      "epoch: 011, batch: 112, loss: 0.048 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011, batch: 113, loss: 0.627 \n",
      "epoch: 011, batch: 114, loss: 0.004 \n",
      "epoch: 011, batch: 115, loss: 0.501 \n",
      "epoch: 011, batch: 116, loss: 0.005 \n",
      "epoch: 011, batch: 117, loss: 0.150 \n",
      "epoch: 011, batch: 118, loss: 0.225 \n",
      "epoch: 011, batch: 119, loss: 0.003 \n",
      "epoch: 011, batch: 120, loss: 1.169 \n",
      "epoch: 011, batch: 121, loss: 0.002 \n",
      "epoch: 011, batch: 122, loss: 0.006 \n",
      "epoch: 011, batch: 123, loss: 0.054 \n",
      "epoch: 011, batch: 124, loss: 0.012 \n",
      "epoch: 011, batch: 125, loss: 0.004 \n",
      "epoch: 011, batch: 126, loss: 0.157 \n",
      "epoch: 011, batch: 127, loss: 0.120 \n",
      "epoch: 011, batch: 128, loss: 0.006 \n",
      "epoch: 011, batch: 129, loss: 0.004 \n",
      "epoch: 011, batch: 130, loss: 0.017 \n",
      "epoch: 011, batch: 131, loss: 0.006 \n",
      "epoch: 011, batch: 132, loss: 0.001 \n",
      "epoch: 011, batch: 133, loss: 0.006 \n",
      "epoch: 011, batch: 134, loss: 0.003 \n",
      "epoch: 011, batch: 135, loss: 0.001 \n",
      "epoch: 011, batch: 136, loss: 0.000 \n",
      "epoch: 011, batch: 137, loss: 0.019 \n",
      "epoch: 011, batch: 138, loss: 0.003 \n",
      "epoch: 011, batch: 139, loss: 0.006 \n",
      "epoch: 011, batch: 140, loss: 0.015 \n",
      "epoch: 011, batch: 141, loss: 0.022 \n",
      "epoch: 011, batch: 142, loss: 0.022 \n",
      "epoch: 011, batch: 143, loss: 0.007 \n",
      "epoch: 011, batch: 144, loss: 0.005 \n",
      "epoch: 011, batch: 145, loss: 0.237 \n",
      "epoch: 011, batch: 146, loss: 0.005 \n",
      "epoch: 011, batch: 147, loss: 0.007 \n",
      "epoch: 011, batch: 148, loss: 0.110 \n",
      "epoch: 011, batch: 149, loss: 0.110 \n",
      "epoch: 011, batch: 150, loss: 0.007 \n",
      "epoch: 011, batch: 151, loss: 0.020 \n",
      "epoch: 011, batch: 152, loss: 0.018 \n",
      "epoch: 011, batch: 153, loss: 0.008 \n",
      "epoch: 011, batch: 154, loss: 0.009 \n",
      "epoch: 011, batch: 155, loss: 0.017 \n",
      "epoch: 011, batch: 156, loss: 0.003 \n",
      "epoch: 011, batch: 157, loss: 0.005 \n",
      "epoch: 011, batch: 158, loss: 0.010 \n",
      "epoch: 011, batch: 159, loss: 3.468 \n",
      "epoch: 011, batch: 160, loss: 0.001 \n",
      "epoch: 011, batch: 161, loss: 0.005 \n",
      "epoch: 011, batch: 162, loss: 0.031 \n",
      "epoch: 011, batch: 163, loss: 0.026 \n",
      "epoch: 011, batch: 164, loss: 0.007 \n",
      "epoch: 011, batch: 165, loss: 0.440 \n",
      "epoch: 011, batch: 166, loss: 0.101 \n",
      "epoch: 011, batch: 167, loss: 0.015 \n",
      "epoch: 011, batch: 168, loss: 0.005 \n",
      "epoch: 011, batch: 169, loss: 0.015 \n",
      "epoch: 011, batch: 170, loss: 0.017 \n",
      "epoch: 011, batch: 171, loss: 0.014 \n",
      "epoch: 011, batch: 172, loss: 0.009 \n",
      "epoch: 011, batch: 173, loss: 0.010 \n",
      "epoch: 011, batch: 174, loss: 0.013 \n",
      "epoch: 011, batch: 175, loss: 0.079 \n",
      "epoch: 011, batch: 176, loss: 0.431 \n",
      "epoch: 011, batch: 177, loss: 0.082 \n",
      "epoch: 011, batch: 178, loss: 0.011 \n",
      "epoch: 011, batch: 179, loss: 0.021 \n",
      "epoch: 011, batch: 180, loss: 0.002 \n",
      "epoch: 011, batch: 181, loss: 0.004 \n",
      "epoch: 011, batch: 182, loss: 0.021 \n",
      "epoch: 011, batch: 183, loss: 0.007 \n",
      "epoch: 011, batch: 184, loss: 0.027 \n",
      "epoch: 011, batch: 185, loss: 0.006 \n",
      "epoch: 011, batch: 186, loss: 0.004 \n",
      "epoch: 011, batch: 187, loss: 0.001 \n",
      "epoch: 011, batch: 188, loss: 0.027 \n",
      "epoch: 011, batch: 189, loss: 0.373 \n",
      "epoch: 011, batch: 190, loss: 0.059 \n",
      "epoch: 011, batch: 191, loss: 0.040 \n",
      "epoch: 011, batch: 192, loss: 0.004 \n",
      "epoch: 011, batch: 193, loss: 0.114 \n",
      "epoch: 011, batch: 194, loss: 0.009 \n",
      "epoch: 011, batch: 195, loss: 0.002 \n",
      "epoch: 011, batch: 196, loss: 0.087 \n",
      "epoch: 011, batch: 197, loss: 0.003 \n",
      "epoch: 011, batch: 198, loss: 0.099 \n",
      "epoch: 011, batch: 199, loss: 0.023 \n",
      "epoch: 011, batch: 200, loss: 0.020 \n",
      "epoch: 011, batch: 201, loss: 0.044 \n",
      "epoch: 011, batch: 202, loss: 0.392 \n",
      "epoch: 011, batch: 203, loss: 0.006 \n",
      "epoch: 011, batch: 204, loss: 0.018 \n",
      "epoch: 011, batch: 205, loss: 0.010 \n",
      "epoch: 011, batch: 206, loss: 0.017 \n",
      "epoch: 011, batch: 207, loss: 0.021 \n",
      "epoch: 011, batch: 208, loss: 0.026 \n",
      "epoch: 011, batch: 209, loss: 0.024 \n",
      "epoch: 011, batch: 210, loss: 0.011 \n",
      "epoch: 011, batch: 211, loss: 0.011 \n",
      "epoch: 011, batch: 212, loss: 0.009 \n",
      "epoch: 011, batch: 213, loss: 0.172 \n",
      "epoch: 011, batch: 214, loss: 0.013 \n",
      "epoch: 011, batch: 215, loss: 0.066 \n",
      "epoch: 011, batch: 216, loss: 0.008 \n",
      "epoch: 011, batch: 217, loss: 0.013 \n",
      "epoch: 011, batch: 218, loss: 0.008 \n",
      "epoch: 011, batch: 219, loss: 0.002 \n",
      "epoch: 011, batch: 220, loss: 0.008 \n",
      "epoch: 011, batch: 221, loss: 0.002 \n",
      "epoch: 011, batch: 222, loss: 0.186 \n",
      "epoch: 011, batch: 223, loss: 0.002 \n",
      "epoch: 011, batch: 224, loss: 4.772 \n",
      "epoch: 011, batch: 225, loss: 0.003 \n",
      "epoch: 011, batch: 226, loss: 0.011 \n",
      "epoch: 011, batch: 227, loss: 0.009 \n",
      "epoch: 011 ------------------------------------------------\n",
      "\n",
      "[train] loss: 18.946\n",
      "\n",
      "[validation] bulls_recall: 91.034%\n",
      "\n",
      "[validation] no_bulls_recall: 77.807%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.8442058785401281\n",
      "\n",
      "epoch: 012, batch: 001, loss: 0.009 \n",
      "epoch: 012, batch: 002, loss: 0.008 \n",
      "epoch: 012, batch: 003, loss: 0.008 \n",
      "epoch: 012, batch: 004, loss: 0.010 \n",
      "epoch: 012, batch: 005, loss: 0.009 \n",
      "epoch: 012, batch: 006, loss: 0.013 \n",
      "epoch: 012, batch: 007, loss: 0.048 \n",
      "epoch: 012, batch: 008, loss: 0.023 \n",
      "epoch: 012, batch: 009, loss: 0.010 \n",
      "epoch: 012, batch: 010, loss: 0.040 \n",
      "epoch: 012, batch: 011, loss: 0.012 \n",
      "epoch: 012, batch: 012, loss: 0.016 \n",
      "epoch: 012, batch: 013, loss: 0.008 \n",
      "epoch: 012, batch: 014, loss: 0.025 \n",
      "epoch: 012, batch: 015, loss: 0.049 \n",
      "epoch: 012, batch: 016, loss: 0.014 \n",
      "epoch: 012, batch: 017, loss: 0.022 \n",
      "epoch: 012, batch: 018, loss: 0.206 \n",
      "epoch: 012, batch: 019, loss: 0.013 \n",
      "epoch: 012, batch: 020, loss: 0.073 \n",
      "epoch: 012, batch: 021, loss: 0.009 \n",
      "epoch: 012, batch: 022, loss: 0.011 \n",
      "epoch: 012, batch: 023, loss: 0.010 \n",
      "epoch: 012, batch: 024, loss: 0.023 \n",
      "epoch: 012, batch: 025, loss: 0.022 \n",
      "epoch: 012, batch: 026, loss: 0.011 \n",
      "epoch: 012, batch: 027, loss: 0.001 \n",
      "epoch: 012, batch: 028, loss: 0.042 \n",
      "epoch: 012, batch: 029, loss: 0.239 \n",
      "epoch: 012, batch: 030, loss: 0.053 \n",
      "epoch: 012, batch: 031, loss: 0.002 \n",
      "epoch: 012, batch: 032, loss: 0.041 \n",
      "epoch: 012, batch: 033, loss: 0.006 \n",
      "epoch: 012, batch: 034, loss: 0.004 \n",
      "epoch: 012, batch: 035, loss: 0.119 \n",
      "epoch: 012, batch: 036, loss: 0.001 \n",
      "epoch: 012, batch: 037, loss: 0.001 \n",
      "epoch: 012, batch: 038, loss: 0.002 \n",
      "epoch: 012, batch: 039, loss: 0.059 \n",
      "epoch: 012, batch: 040, loss: 0.000 \n",
      "epoch: 012, batch: 041, loss: 0.003 \n",
      "epoch: 012, batch: 042, loss: 0.000 \n",
      "epoch: 012, batch: 043, loss: 0.001 \n",
      "epoch: 012, batch: 044, loss: 0.002 \n",
      "epoch: 012, batch: 045, loss: 0.016 \n",
      "epoch: 012, batch: 046, loss: 0.000 \n",
      "epoch: 012, batch: 047, loss: 0.000 \n",
      "epoch: 012, batch: 048, loss: 0.053 \n",
      "epoch: 012, batch: 049, loss: 0.007 \n",
      "epoch: 012, batch: 050, loss: 0.001 \n",
      "epoch: 012, batch: 051, loss: 0.114 \n",
      "epoch: 012, batch: 052, loss: 0.016 \n",
      "epoch: 012, batch: 053, loss: 0.005 \n",
      "epoch: 012, batch: 054, loss: 0.047 \n",
      "epoch: 012, batch: 055, loss: 0.265 \n",
      "epoch: 012, batch: 056, loss: 0.008 \n",
      "epoch: 012, batch: 057, loss: 0.042 \n",
      "epoch: 012, batch: 058, loss: 0.407 \n",
      "epoch: 012, batch: 059, loss: 0.008 \n",
      "epoch: 012, batch: 060, loss: 0.165 \n",
      "epoch: 012, batch: 061, loss: 0.018 \n",
      "epoch: 012, batch: 062, loss: 0.179 \n",
      "epoch: 012, batch: 063, loss: 0.002 \n",
      "epoch: 012, batch: 064, loss: 0.080 \n",
      "epoch: 012, batch: 065, loss: 0.721 \n",
      "epoch: 012, batch: 066, loss: 0.018 \n",
      "epoch: 012, batch: 067, loss: 0.439 \n",
      "epoch: 012, batch: 068, loss: 0.025 \n",
      "epoch: 012, batch: 069, loss: 0.003 \n",
      "epoch: 012, batch: 070, loss: 0.010 \n",
      "epoch: 012, batch: 071, loss: 0.005 \n",
      "epoch: 012, batch: 072, loss: 0.013 \n",
      "epoch: 012, batch: 073, loss: 0.208 \n",
      "epoch: 012, batch: 074, loss: 0.010 \n",
      "epoch: 012, batch: 075, loss: 0.010 \n",
      "epoch: 012, batch: 076, loss: 0.066 \n",
      "epoch: 012, batch: 077, loss: 0.060 \n",
      "epoch: 012, batch: 078, loss: 0.001 \n",
      "epoch: 012, batch: 079, loss: 0.015 \n",
      "epoch: 012, batch: 080, loss: 0.003 \n",
      "epoch: 012, batch: 081, loss: 0.076 \n",
      "epoch: 012, batch: 082, loss: 0.001 \n",
      "epoch: 012, batch: 083, loss: 0.054 \n",
      "epoch: 012, batch: 084, loss: 0.116 \n",
      "epoch: 012, batch: 085, loss: 0.005 \n",
      "epoch: 012, batch: 086, loss: 0.005 \n",
      "epoch: 012, batch: 087, loss: 0.034 \n",
      "epoch: 012, batch: 088, loss: 0.001 \n",
      "epoch: 012, batch: 089, loss: 0.000 \n",
      "epoch: 012, batch: 090, loss: 0.000 \n",
      "epoch: 012, batch: 091, loss: 0.043 \n",
      "epoch: 012, batch: 092, loss: 0.023 \n",
      "epoch: 012, batch: 093, loss: 0.001 \n",
      "epoch: 012, batch: 094, loss: 0.001 \n",
      "epoch: 012, batch: 095, loss: 0.000 \n",
      "epoch: 012, batch: 096, loss: 0.000 \n",
      "epoch: 012, batch: 097, loss: 0.000 \n",
      "epoch: 012, batch: 098, loss: 0.003 \n",
      "epoch: 012, batch: 099, loss: 0.005 \n",
      "epoch: 012, batch: 100, loss: 0.008 \n",
      "epoch: 012, batch: 101, loss: 0.073 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012, batch: 102, loss: 0.040 \n",
      "epoch: 012, batch: 103, loss: 0.010 \n",
      "epoch: 012, batch: 104, loss: 0.015 \n",
      "epoch: 012, batch: 105, loss: 0.013 \n",
      "epoch: 012, batch: 106, loss: 0.012 \n",
      "epoch: 012, batch: 107, loss: 0.083 \n",
      "epoch: 012, batch: 108, loss: 0.006 \n",
      "epoch: 012, batch: 109, loss: 0.054 \n",
      "epoch: 012, batch: 110, loss: 0.005 \n",
      "epoch: 012, batch: 111, loss: 0.007 \n",
      "epoch: 012, batch: 112, loss: 0.396 \n",
      "epoch: 012, batch: 113, loss: 0.004 \n",
      "epoch: 012, batch: 114, loss: 0.006 \n",
      "epoch: 012, batch: 115, loss: 0.011 \n",
      "epoch: 012, batch: 116, loss: 0.007 \n",
      "epoch: 012, batch: 117, loss: 0.011 \n",
      "epoch: 012, batch: 118, loss: 0.047 \n",
      "epoch: 012, batch: 119, loss: 0.036 \n",
      "epoch: 012, batch: 120, loss: 0.073 \n",
      "epoch: 012, batch: 121, loss: 0.002 \n",
      "epoch: 012, batch: 122, loss: 0.003 \n",
      "epoch: 012, batch: 123, loss: 0.041 \n",
      "epoch: 012, batch: 124, loss: 0.002 \n",
      "epoch: 012, batch: 125, loss: 0.342 \n",
      "epoch: 012, batch: 126, loss: 0.001 \n",
      "epoch: 012, batch: 127, loss: 0.022 \n",
      "epoch: 012, batch: 128, loss: 0.001 \n",
      "epoch: 012, batch: 129, loss: 0.142 \n",
      "epoch: 012, batch: 130, loss: 0.001 \n",
      "epoch: 012, batch: 131, loss: 0.003 \n",
      "epoch: 012, batch: 132, loss: 0.110 \n",
      "epoch: 012, batch: 133, loss: 0.193 \n",
      "epoch: 012, batch: 134, loss: 0.063 \n",
      "epoch: 012, batch: 135, loss: 0.004 \n",
      "epoch: 012, batch: 136, loss: 0.176 \n",
      "epoch: 012, batch: 137, loss: 0.014 \n",
      "epoch: 012, batch: 138, loss: 0.004 \n",
      "epoch: 012, batch: 139, loss: 0.006 \n",
      "epoch: 012, batch: 140, loss: 0.004 \n",
      "epoch: 012, batch: 141, loss: 0.034 \n",
      "epoch: 012, batch: 142, loss: 0.009 \n",
      "epoch: 012, batch: 143, loss: 0.041 \n",
      "epoch: 012, batch: 144, loss: 0.045 \n",
      "epoch: 012, batch: 145, loss: 0.147 \n",
      "epoch: 012, batch: 146, loss: 0.027 \n",
      "epoch: 012, batch: 147, loss: 0.006 \n",
      "epoch: 012, batch: 148, loss: 0.008 \n",
      "epoch: 012, batch: 149, loss: 0.008 \n",
      "epoch: 012, batch: 150, loss: 0.130 \n",
      "epoch: 012, batch: 151, loss: 0.032 \n",
      "epoch: 012, batch: 152, loss: 0.005 \n",
      "epoch: 012, batch: 153, loss: 0.001 \n",
      "epoch: 012, batch: 154, loss: 0.018 \n",
      "epoch: 012, batch: 155, loss: 0.003 \n",
      "epoch: 012, batch: 156, loss: 0.030 \n",
      "epoch: 012, batch: 157, loss: 0.004 \n",
      "epoch: 012, batch: 158, loss: 0.150 \n",
      "epoch: 012, batch: 159, loss: 0.010 \n",
      "epoch: 012, batch: 160, loss: 0.010 \n",
      "epoch: 012, batch: 161, loss: 0.004 \n",
      "epoch: 012, batch: 162, loss: 0.003 \n",
      "epoch: 012, batch: 163, loss: 0.001 \n",
      "epoch: 012, batch: 164, loss: 0.001 \n",
      "epoch: 012, batch: 165, loss: 0.026 \n",
      "epoch: 012, batch: 166, loss: 0.117 \n",
      "epoch: 012, batch: 167, loss: 0.006 \n",
      "epoch: 012, batch: 168, loss: 0.004 \n",
      "epoch: 012, batch: 169, loss: 0.050 \n",
      "epoch: 012, batch: 170, loss: 0.001 \n",
      "epoch: 012, batch: 171, loss: 0.075 \n",
      "epoch: 012, batch: 172, loss: 0.068 \n",
      "epoch: 012, batch: 173, loss: 0.215 \n",
      "epoch: 012, batch: 174, loss: 0.023 \n",
      "epoch: 012, batch: 175, loss: 0.632 \n",
      "epoch: 012, batch: 176, loss: 0.004 \n",
      "epoch: 012, batch: 177, loss: 3.733 \n",
      "epoch: 012, batch: 178, loss: 0.033 \n",
      "epoch: 012, batch: 179, loss: 0.017 \n",
      "epoch: 012, batch: 180, loss: 0.026 \n",
      "epoch: 012, batch: 181, loss: 0.065 \n",
      "epoch: 012, batch: 182, loss: 0.006 \n",
      "epoch: 012, batch: 183, loss: 0.095 \n",
      "epoch: 012, batch: 184, loss: 0.220 \n",
      "epoch: 012, batch: 185, loss: 0.015 \n",
      "epoch: 012, batch: 186, loss: 0.025 \n",
      "epoch: 012, batch: 187, loss: 0.029 \n",
      "epoch: 012, batch: 188, loss: 0.008 \n",
      "epoch: 012, batch: 189, loss: 0.093 \n",
      "epoch: 012, batch: 190, loss: 0.099 \n",
      "epoch: 012, batch: 191, loss: 0.008 \n",
      "epoch: 012, batch: 192, loss: 0.040 \n",
      "epoch: 012, batch: 193, loss: 0.016 \n",
      "epoch: 012, batch: 194, loss: 0.013 \n",
      "epoch: 012, batch: 195, loss: 0.096 \n",
      "epoch: 012, batch: 196, loss: 0.076 \n",
      "epoch: 012, batch: 197, loss: 0.170 \n",
      "epoch: 012, batch: 198, loss: 0.011 \n",
      "epoch: 012, batch: 199, loss: 0.006 \n",
      "epoch: 012, batch: 200, loss: 0.001 \n",
      "epoch: 012, batch: 201, loss: 0.005 \n",
      "epoch: 012, batch: 202, loss: 0.002 \n",
      "epoch: 012, batch: 203, loss: 0.001 \n",
      "epoch: 012, batch: 204, loss: 0.004 \n",
      "epoch: 012, batch: 205, loss: 0.050 \n",
      "epoch: 012, batch: 206, loss: 0.014 \n",
      "epoch: 012, batch: 207, loss: 0.015 \n",
      "epoch: 012, batch: 208, loss: 0.011 \n",
      "epoch: 012, batch: 209, loss: 0.134 \n",
      "epoch: 012, batch: 210, loss: 0.134 \n",
      "epoch: 012, batch: 211, loss: 0.045 \n",
      "epoch: 012, batch: 212, loss: 0.048 \n",
      "epoch: 012, batch: 213, loss: 0.031 \n",
      "epoch: 012, batch: 214, loss: 0.022 \n",
      "epoch: 012, batch: 215, loss: 0.021 \n",
      "epoch: 012, batch: 216, loss: 0.014 \n",
      "epoch: 012, batch: 217, loss: 0.019 \n",
      "epoch: 012, batch: 218, loss: 0.011 \n",
      "epoch: 012, batch: 219, loss: 0.077 \n",
      "epoch: 012, batch: 220, loss: 0.006 \n",
      "epoch: 012, batch: 221, loss: 0.003 \n",
      "epoch: 012, batch: 222, loss: 0.047 \n",
      "epoch: 012, batch: 223, loss: 0.005 \n",
      "epoch: 012, batch: 224, loss: 0.001 \n",
      "epoch: 012, batch: 225, loss: 0.005 \n",
      "epoch: 012, batch: 226, loss: 0.017 \n",
      "epoch: 012, batch: 227, loss: 0.006 \n",
      "epoch: 012 ------------------------------------------------\n",
      "\n",
      "[train] loss: 17.695\n",
      "\n",
      "[validation] bulls_recall: 90.194%\n",
      "\n",
      "[validation] no_bulls_recall: 31.245%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.60719328902424\n",
      "\n",
      "epoch: 013, batch: 001, loss: 0.010 \n",
      "epoch: 013, batch: 002, loss: 0.114 \n",
      "epoch: 013, batch: 003, loss: 0.021 \n",
      "epoch: 013, batch: 004, loss: 0.006 \n",
      "epoch: 013, batch: 005, loss: 0.004 \n",
      "epoch: 013, batch: 006, loss: 0.158 \n",
      "epoch: 013, batch: 007, loss: 0.002 \n",
      "epoch: 013, batch: 008, loss: 0.000 \n",
      "epoch: 013, batch: 009, loss: 0.006 \n",
      "epoch: 013, batch: 010, loss: 0.008 \n",
      "epoch: 013, batch: 011, loss: 0.005 \n",
      "epoch: 013, batch: 012, loss: 0.032 \n",
      "epoch: 013, batch: 013, loss: 0.003 \n",
      "epoch: 013, batch: 014, loss: 0.007 \n",
      "epoch: 013, batch: 015, loss: 0.002 \n",
      "epoch: 013, batch: 016, loss: 0.018 \n",
      "epoch: 013, batch: 017, loss: 0.005 \n",
      "epoch: 013, batch: 018, loss: 0.009 \n",
      "epoch: 013, batch: 019, loss: 0.012 \n",
      "epoch: 013, batch: 020, loss: 0.022 \n",
      "epoch: 013, batch: 021, loss: 0.006 \n",
      "epoch: 013, batch: 022, loss: 0.367 \n",
      "epoch: 013, batch: 023, loss: 0.006 \n",
      "epoch: 013, batch: 024, loss: 0.005 \n",
      "epoch: 013, batch: 025, loss: 0.005 \n",
      "epoch: 013, batch: 026, loss: 0.005 \n",
      "epoch: 013, batch: 027, loss: 0.051 \n",
      "epoch: 013, batch: 028, loss: 0.099 \n",
      "epoch: 013, batch: 029, loss: 0.094 \n",
      "epoch: 013, batch: 030, loss: 0.041 \n",
      "epoch: 013, batch: 031, loss: 0.000 \n",
      "epoch: 013, batch: 032, loss: 0.012 \n",
      "epoch: 013, batch: 033, loss: 0.009 \n",
      "epoch: 013, batch: 034, loss: 0.002 \n",
      "epoch: 013, batch: 035, loss: 0.003 \n",
      "epoch: 013, batch: 036, loss: 0.010 \n",
      "epoch: 013, batch: 037, loss: 0.002 \n",
      "epoch: 013, batch: 038, loss: 0.001 \n",
      "epoch: 013, batch: 039, loss: 0.002 \n",
      "epoch: 013, batch: 040, loss: 0.003 \n",
      "epoch: 013, batch: 041, loss: 0.002 \n",
      "epoch: 013, batch: 042, loss: 0.002 \n",
      "epoch: 013, batch: 043, loss: 0.024 \n",
      "epoch: 013, batch: 044, loss: 0.011 \n",
      "epoch: 013, batch: 045, loss: 0.006 \n",
      "epoch: 013, batch: 046, loss: 0.004 \n",
      "epoch: 013, batch: 047, loss: 0.006 \n",
      "epoch: 013, batch: 048, loss: 0.039 \n",
      "epoch: 013, batch: 049, loss: 0.020 \n",
      "epoch: 013, batch: 050, loss: 0.126 \n",
      "epoch: 013, batch: 051, loss: 0.029 \n",
      "epoch: 013, batch: 052, loss: 0.057 \n",
      "epoch: 013, batch: 053, loss: 0.003 \n",
      "epoch: 013, batch: 054, loss: 0.011 \n",
      "epoch: 013, batch: 055, loss: 0.698 \n",
      "epoch: 013, batch: 056, loss: 0.008 \n",
      "epoch: 013, batch: 057, loss: 0.019 \n",
      "epoch: 013, batch: 058, loss: 0.066 \n",
      "epoch: 013, batch: 059, loss: 0.014 \n",
      "epoch: 013, batch: 060, loss: 0.011 \n",
      "epoch: 013, batch: 061, loss: 0.218 \n",
      "epoch: 013, batch: 062, loss: 0.017 \n",
      "epoch: 013, batch: 063, loss: 0.014 \n",
      "epoch: 013, batch: 064, loss: 0.012 \n",
      "epoch: 013, batch: 065, loss: 0.029 \n",
      "epoch: 013, batch: 066, loss: 0.002 \n",
      "epoch: 013, batch: 067, loss: 0.004 \n",
      "epoch: 013, batch: 068, loss: 0.002 \n",
      "epoch: 013, batch: 069, loss: 0.026 \n",
      "epoch: 013, batch: 070, loss: 0.041 \n",
      "epoch: 013, batch: 071, loss: 0.004 \n",
      "epoch: 013, batch: 072, loss: 0.009 \n",
      "epoch: 013, batch: 073, loss: 0.006 \n",
      "epoch: 013, batch: 074, loss: 0.119 \n",
      "epoch: 013, batch: 075, loss: 0.003 \n",
      "epoch: 013, batch: 076, loss: 0.006 \n",
      "epoch: 013, batch: 077, loss: 0.001 \n",
      "epoch: 013, batch: 078, loss: 0.001 \n",
      "epoch: 013, batch: 079, loss: 0.711 \n",
      "epoch: 013, batch: 080, loss: 0.037 \n",
      "epoch: 013, batch: 081, loss: 0.003 \n",
      "epoch: 013, batch: 082, loss: 0.009 \n",
      "epoch: 013, batch: 083, loss: 0.008 \n",
      "epoch: 013, batch: 084, loss: 0.042 \n",
      "epoch: 013, batch: 085, loss: 0.013 \n",
      "epoch: 013, batch: 086, loss: 0.008 \n",
      "epoch: 013, batch: 087, loss: 0.021 \n",
      "epoch: 013, batch: 088, loss: 0.017 \n",
      "epoch: 013, batch: 089, loss: 0.012 \n",
      "epoch: 013, batch: 090, loss: 0.024 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013, batch: 091, loss: 0.322 \n",
      "epoch: 013, batch: 092, loss: 0.070 \n",
      "epoch: 013, batch: 093, loss: 0.026 \n",
      "epoch: 013, batch: 094, loss: 0.007 \n",
      "epoch: 013, batch: 095, loss: 0.007 \n",
      "epoch: 013, batch: 096, loss: 0.067 \n",
      "epoch: 013, batch: 097, loss: 0.006 \n",
      "epoch: 013, batch: 098, loss: 0.013 \n",
      "epoch: 013, batch: 099, loss: 0.030 \n",
      "epoch: 013, batch: 100, loss: 0.115 \n",
      "epoch: 013, batch: 101, loss: 0.000 \n",
      "epoch: 013, batch: 102, loss: 0.053 \n",
      "epoch: 013, batch: 103, loss: 0.004 \n",
      "epoch: 013, batch: 104, loss: 0.121 \n",
      "epoch: 013, batch: 105, loss: 0.002 \n",
      "epoch: 013, batch: 106, loss: 0.171 \n",
      "epoch: 013, batch: 107, loss: 0.020 \n",
      "epoch: 013, batch: 108, loss: 0.008 \n",
      "epoch: 013, batch: 109, loss: 0.005 \n",
      "epoch: 013, batch: 110, loss: 0.004 \n",
      "epoch: 013, batch: 111, loss: 0.009 \n",
      "epoch: 013, batch: 112, loss: 0.010 \n",
      "epoch: 013, batch: 113, loss: 0.009 \n",
      "epoch: 013, batch: 114, loss: 0.019 \n",
      "epoch: 013, batch: 115, loss: 0.284 \n",
      "epoch: 013, batch: 116, loss: 0.006 \n",
      "epoch: 013, batch: 117, loss: 0.121 \n",
      "epoch: 013, batch: 118, loss: 0.003 \n",
      "epoch: 013, batch: 119, loss: 0.008 \n",
      "epoch: 013, batch: 120, loss: 0.031 \n",
      "epoch: 013, batch: 121, loss: 0.078 \n",
      "epoch: 013, batch: 122, loss: 0.012 \n",
      "epoch: 013, batch: 123, loss: 0.269 \n",
      "epoch: 013, batch: 124, loss: 0.010 \n",
      "epoch: 013, batch: 125, loss: 0.040 \n",
      "epoch: 013, batch: 126, loss: 0.025 \n",
      "epoch: 013, batch: 127, loss: 0.013 \n",
      "epoch: 013, batch: 128, loss: 0.398 \n",
      "epoch: 013, batch: 129, loss: 0.007 \n",
      "epoch: 013, batch: 130, loss: 0.001 \n",
      "epoch: 013, batch: 131, loss: 0.013 \n",
      "epoch: 013, batch: 132, loss: 0.006 \n",
      "epoch: 013, batch: 133, loss: 0.009 \n",
      "epoch: 013, batch: 134, loss: 0.339 \n",
      "epoch: 013, batch: 135, loss: 0.011 \n",
      "epoch: 013, batch: 136, loss: 0.013 \n",
      "epoch: 013, batch: 137, loss: 0.009 \n",
      "epoch: 013, batch: 138, loss: 0.014 \n",
      "epoch: 013, batch: 139, loss: 0.054 \n",
      "epoch: 013, batch: 140, loss: 0.108 \n",
      "epoch: 013, batch: 141, loss: 0.032 \n",
      "epoch: 013, batch: 142, loss: 0.057 \n",
      "epoch: 013, batch: 143, loss: 0.152 \n",
      "epoch: 013, batch: 144, loss: 0.011 \n",
      "epoch: 013, batch: 145, loss: 0.003 \n",
      "epoch: 013, batch: 146, loss: 0.023 \n",
      "epoch: 013, batch: 147, loss: 0.005 \n",
      "epoch: 013, batch: 148, loss: 0.005 \n",
      "epoch: 013, batch: 149, loss: 0.006 \n",
      "epoch: 013, batch: 150, loss: 0.001 \n",
      "epoch: 013, batch: 151, loss: 0.003 \n",
      "epoch: 013, batch: 152, loss: 0.008 \n",
      "epoch: 013, batch: 153, loss: 0.004 \n",
      "epoch: 013, batch: 154, loss: 0.014 \n",
      "epoch: 013, batch: 155, loss: 0.017 \n",
      "epoch: 013, batch: 156, loss: 0.025 \n",
      "epoch: 013, batch: 157, loss: 0.001 \n",
      "epoch: 013, batch: 158, loss: 0.112 \n",
      "epoch: 013, batch: 159, loss: 0.328 \n",
      "epoch: 013, batch: 160, loss: 0.369 \n",
      "epoch: 013, batch: 161, loss: 0.010 \n",
      "epoch: 013, batch: 162, loss: 0.032 \n",
      "epoch: 013, batch: 163, loss: 0.012 \n",
      "epoch: 013, batch: 164, loss: 0.004 \n",
      "epoch: 013, batch: 165, loss: 0.002 \n",
      "epoch: 013, batch: 166, loss: 0.023 \n",
      "epoch: 013, batch: 167, loss: 0.034 \n",
      "epoch: 013, batch: 168, loss: 0.006 \n",
      "epoch: 013, batch: 169, loss: 0.438 \n",
      "epoch: 013, batch: 170, loss: 0.008 \n",
      "epoch: 013, batch: 171, loss: 0.004 \n",
      "epoch: 013, batch: 172, loss: 0.004 \n",
      "epoch: 013, batch: 173, loss: 0.010 \n",
      "epoch: 013, batch: 174, loss: 0.013 \n",
      "epoch: 013, batch: 175, loss: 0.008 \n",
      "epoch: 013, batch: 176, loss: 0.008 \n",
      "epoch: 013, batch: 177, loss: 0.254 \n",
      "epoch: 013, batch: 178, loss: 0.022 \n",
      "epoch: 013, batch: 179, loss: 0.003 \n",
      "epoch: 013, batch: 180, loss: 0.002 \n",
      "epoch: 013, batch: 181, loss: 0.019 \n",
      "epoch: 013, batch: 182, loss: 0.005 \n",
      "epoch: 013, batch: 183, loss: 0.013 \n",
      "epoch: 013, batch: 184, loss: 0.017 \n",
      "epoch: 013, batch: 185, loss: 0.038 \n",
      "epoch: 013, batch: 186, loss: 0.037 \n",
      "epoch: 013, batch: 187, loss: 0.008 \n",
      "epoch: 013, batch: 188, loss: 0.014 \n",
      "epoch: 013, batch: 189, loss: 0.015 \n",
      "epoch: 013, batch: 190, loss: 0.009 \n",
      "epoch: 013, batch: 191, loss: 0.008 \n",
      "epoch: 013, batch: 192, loss: 0.284 \n",
      "epoch: 013, batch: 193, loss: 0.034 \n",
      "epoch: 013, batch: 194, loss: 0.003 \n",
      "epoch: 013, batch: 195, loss: 0.283 \n",
      "epoch: 013, batch: 196, loss: 0.014 \n",
      "epoch: 013, batch: 197, loss: 0.102 \n",
      "epoch: 013, batch: 198, loss: 0.028 \n",
      "epoch: 013, batch: 199, loss: 0.010 \n",
      "epoch: 013, batch: 200, loss: 0.196 \n",
      "epoch: 013, batch: 201, loss: 0.102 \n",
      "epoch: 013, batch: 202, loss: 0.662 \n",
      "epoch: 013, batch: 203, loss: 0.035 \n",
      "epoch: 013, batch: 204, loss: 0.022 \n",
      "epoch: 013, batch: 205, loss: 0.003 \n",
      "epoch: 013, batch: 206, loss: 0.004 \n",
      "epoch: 013, batch: 207, loss: 0.020 \n",
      "epoch: 013, batch: 208, loss: 0.003 \n",
      "epoch: 013, batch: 209, loss: 0.488 \n",
      "epoch: 013, batch: 210, loss: 0.007 \n",
      "epoch: 013, batch: 211, loss: 0.114 \n",
      "epoch: 013, batch: 212, loss: 0.009 \n",
      "epoch: 013, batch: 213, loss: 0.010 \n",
      "epoch: 013, batch: 214, loss: 0.003 \n",
      "epoch: 013, batch: 215, loss: 0.007 \n",
      "epoch: 013, batch: 216, loss: 0.005 \n",
      "epoch: 013, batch: 217, loss: 0.015 \n",
      "epoch: 013, batch: 218, loss: 0.012 \n",
      "epoch: 013, batch: 219, loss: 0.049 \n",
      "epoch: 013, batch: 220, loss: 0.086 \n",
      "epoch: 013, batch: 221, loss: 0.022 \n",
      "epoch: 013, batch: 222, loss: 0.103 \n",
      "epoch: 013, batch: 223, loss: 0.008 \n",
      "epoch: 013, batch: 224, loss: 0.009 \n",
      "epoch: 013, batch: 225, loss: 0.079 \n",
      "epoch: 013, batch: 226, loss: 0.007 \n",
      "epoch: 013, batch: 227, loss: 0.000 \n",
      "epoch: 013 ------------------------------------------------\n",
      "\n",
      "[train] loss: 16.804\n",
      "\n",
      "[validation] bulls_recall: 97.756%\n",
      "\n",
      "[validation] no_bulls_recall: 63.457%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.8060646022669136\n",
      "\n",
      "epoch: 014, batch: 001, loss: 3.165 \n",
      "epoch: 014, batch: 002, loss: 0.014 \n",
      "epoch: 014, batch: 003, loss: 0.038 \n",
      "epoch: 014, batch: 004, loss: 0.190 \n",
      "epoch: 014, batch: 005, loss: 0.020 \n",
      "epoch: 014, batch: 006, loss: 0.003 \n",
      "epoch: 014, batch: 007, loss: 0.011 \n",
      "epoch: 014, batch: 008, loss: 0.002 \n",
      "epoch: 014, batch: 009, loss: 0.002 \n",
      "epoch: 014, batch: 010, loss: 0.010 \n",
      "epoch: 014, batch: 011, loss: 0.392 \n",
      "epoch: 014, batch: 012, loss: 0.106 \n",
      "epoch: 014, batch: 013, loss: 0.011 \n",
      "epoch: 014, batch: 014, loss: 0.501 \n",
      "epoch: 014, batch: 015, loss: 0.078 \n",
      "epoch: 014, batch: 016, loss: 0.004 \n",
      "epoch: 014, batch: 017, loss: 0.008 \n",
      "epoch: 014, batch: 018, loss: 0.027 \n",
      "epoch: 014, batch: 019, loss: 0.008 \n",
      "epoch: 014, batch: 020, loss: 0.082 \n",
      "epoch: 014, batch: 021, loss: 0.003 \n",
      "epoch: 014, batch: 022, loss: 0.007 \n",
      "epoch: 014, batch: 023, loss: 0.209 \n",
      "epoch: 014, batch: 024, loss: 0.010 \n",
      "epoch: 014, batch: 025, loss: 0.001 \n",
      "epoch: 014, batch: 026, loss: 0.041 \n",
      "epoch: 014, batch: 027, loss: 0.007 \n",
      "epoch: 014, batch: 028, loss: 0.393 \n",
      "epoch: 014, batch: 029, loss: 0.003 \n",
      "epoch: 014, batch: 030, loss: 0.010 \n",
      "epoch: 014, batch: 031, loss: 0.238 \n",
      "epoch: 014, batch: 032, loss: 0.003 \n",
      "epoch: 014, batch: 033, loss: 0.002 \n",
      "epoch: 014, batch: 034, loss: 0.135 \n",
      "epoch: 014, batch: 035, loss: 0.089 \n",
      "epoch: 014, batch: 036, loss: 0.002 \n",
      "epoch: 014, batch: 037, loss: 0.002 \n",
      "epoch: 014, batch: 038, loss: 0.003 \n",
      "epoch: 014, batch: 039, loss: 0.009 \n",
      "epoch: 014, batch: 040, loss: 0.001 \n",
      "epoch: 014, batch: 041, loss: 0.000 \n",
      "epoch: 014, batch: 042, loss: 0.003 \n",
      "epoch: 014, batch: 043, loss: 0.015 \n",
      "epoch: 014, batch: 044, loss: 0.006 \n",
      "epoch: 014, batch: 045, loss: 0.005 \n",
      "epoch: 014, batch: 046, loss: 0.037 \n",
      "epoch: 014, batch: 047, loss: 0.006 \n",
      "epoch: 014, batch: 048, loss: 0.014 \n",
      "epoch: 014, batch: 049, loss: 0.035 \n",
      "epoch: 014, batch: 050, loss: 0.002 \n",
      "epoch: 014, batch: 051, loss: 0.008 \n",
      "epoch: 014, batch: 052, loss: 0.001 \n",
      "epoch: 014, batch: 053, loss: 0.245 \n",
      "epoch: 014, batch: 054, loss: 0.953 \n",
      "epoch: 014, batch: 055, loss: 0.010 \n",
      "epoch: 014, batch: 056, loss: 0.013 \n",
      "epoch: 014, batch: 057, loss: 0.103 \n",
      "epoch: 014, batch: 058, loss: 0.014 \n",
      "epoch: 014, batch: 059, loss: 0.002 \n",
      "epoch: 014, batch: 060, loss: 0.313 \n",
      "epoch: 014, batch: 061, loss: 0.004 \n",
      "epoch: 014, batch: 062, loss: 0.009 \n",
      "epoch: 014, batch: 063, loss: 0.001 \n",
      "epoch: 014, batch: 064, loss: 0.003 \n",
      "epoch: 014, batch: 065, loss: 0.002 \n",
      "epoch: 014, batch: 066, loss: 0.001 \n",
      "epoch: 014, batch: 067, loss: 0.002 \n",
      "epoch: 014, batch: 068, loss: 0.001 \n",
      "epoch: 014, batch: 069, loss: 0.118 \n",
      "epoch: 014, batch: 070, loss: 0.004 \n",
      "epoch: 014, batch: 071, loss: 0.001 \n",
      "epoch: 014, batch: 072, loss: 0.004 \n",
      "epoch: 014, batch: 073, loss: 0.002 \n",
      "epoch: 014, batch: 074, loss: 0.011 \n",
      "epoch: 014, batch: 075, loss: 0.005 \n",
      "epoch: 014, batch: 076, loss: 0.044 \n",
      "epoch: 014, batch: 077, loss: 0.008 \n",
      "epoch: 014, batch: 078, loss: 0.120 \n",
      "epoch: 014, batch: 079, loss: 0.039 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014, batch: 080, loss: 0.208 \n",
      "epoch: 014, batch: 081, loss: 0.063 \n",
      "epoch: 014, batch: 082, loss: 0.001 \n",
      "epoch: 014, batch: 083, loss: 0.003 \n",
      "epoch: 014, batch: 084, loss: 0.005 \n",
      "epoch: 014, batch: 085, loss: 0.025 \n",
      "epoch: 014, batch: 086, loss: 0.016 \n",
      "epoch: 014, batch: 087, loss: 0.011 \n",
      "epoch: 014, batch: 088, loss: 0.132 \n",
      "epoch: 014, batch: 089, loss: 0.058 \n",
      "epoch: 014, batch: 090, loss: 0.063 \n",
      "epoch: 014, batch: 091, loss: 0.005 \n",
      "epoch: 014, batch: 092, loss: 0.015 \n",
      "epoch: 014, batch: 093, loss: 0.001 \n",
      "epoch: 014, batch: 094, loss: 0.021 \n",
      "epoch: 014, batch: 095, loss: 0.113 \n",
      "epoch: 014, batch: 096, loss: 0.099 \n",
      "epoch: 014, batch: 097, loss: 0.006 \n",
      "epoch: 014, batch: 098, loss: 0.245 \n",
      "epoch: 014, batch: 099, loss: 0.001 \n",
      "epoch: 014, batch: 100, loss: 0.000 \n",
      "epoch: 014, batch: 101, loss: 0.012 \n",
      "epoch: 014, batch: 102, loss: 0.001 \n",
      "epoch: 014, batch: 103, loss: 1.237 \n",
      "epoch: 014, batch: 104, loss: 0.001 \n",
      "epoch: 014, batch: 105, loss: 0.002 \n",
      "epoch: 014, batch: 106, loss: 0.012 \n",
      "epoch: 014, batch: 107, loss: 0.006 \n",
      "epoch: 014, batch: 108, loss: 0.008 \n",
      "epoch: 014, batch: 109, loss: 0.012 \n",
      "epoch: 014, batch: 110, loss: 0.010 \n",
      "epoch: 014, batch: 111, loss: 0.060 \n",
      "epoch: 014, batch: 112, loss: 0.118 \n",
      "epoch: 014, batch: 113, loss: 0.061 \n",
      "epoch: 014, batch: 114, loss: 0.104 \n",
      "epoch: 014, batch: 115, loss: 0.014 \n",
      "epoch: 014, batch: 116, loss: 0.044 \n",
      "epoch: 014, batch: 117, loss: 0.017 \n",
      "epoch: 014, batch: 118, loss: 0.009 \n",
      "epoch: 014, batch: 119, loss: 0.011 \n",
      "epoch: 014, batch: 120, loss: 0.012 \n",
      "epoch: 014, batch: 121, loss: 0.002 \n",
      "epoch: 014, batch: 122, loss: 0.035 \n",
      "epoch: 014, batch: 123, loss: 0.125 \n",
      "epoch: 014, batch: 124, loss: 0.003 \n",
      "epoch: 014, batch: 125, loss: 0.009 \n",
      "epoch: 014, batch: 126, loss: 0.012 \n",
      "epoch: 014, batch: 127, loss: 0.003 \n",
      "epoch: 014, batch: 128, loss: 0.016 \n",
      "epoch: 014, batch: 129, loss: 0.003 \n",
      "epoch: 014, batch: 130, loss: 0.003 \n",
      "epoch: 014, batch: 131, loss: 0.032 \n",
      "epoch: 014, batch: 132, loss: 0.003 \n",
      "epoch: 014, batch: 133, loss: 0.114 \n",
      "epoch: 014, batch: 134, loss: 0.005 \n",
      "epoch: 014, batch: 135, loss: 0.034 \n",
      "epoch: 014, batch: 136, loss: 0.016 \n",
      "epoch: 014, batch: 137, loss: 0.044 \n",
      "epoch: 014, batch: 138, loss: 0.004 \n",
      "epoch: 014, batch: 139, loss: 0.001 \n",
      "epoch: 014, batch: 140, loss: 0.002 \n",
      "epoch: 014, batch: 141, loss: 0.009 \n",
      "epoch: 014, batch: 142, loss: 0.003 \n",
      "epoch: 014, batch: 143, loss: 0.000 \n",
      "epoch: 014, batch: 144, loss: 0.006 \n",
      "epoch: 014, batch: 145, loss: 0.054 \n",
      "epoch: 014, batch: 146, loss: 0.002 \n",
      "epoch: 014, batch: 147, loss: 0.006 \n",
      "epoch: 014, batch: 148, loss: 0.005 \n",
      "epoch: 014, batch: 149, loss: 0.004 \n",
      "epoch: 014, batch: 150, loss: 0.187 \n",
      "epoch: 014, batch: 151, loss: 0.007 \n",
      "epoch: 014, batch: 152, loss: 0.172 \n",
      "epoch: 014, batch: 153, loss: 0.012 \n",
      "epoch: 014, batch: 154, loss: 0.045 \n",
      "epoch: 014, batch: 155, loss: 0.008 \n",
      "epoch: 014, batch: 156, loss: 0.029 \n",
      "epoch: 014, batch: 157, loss: 0.005 \n",
      "epoch: 014, batch: 158, loss: 0.016 \n",
      "epoch: 014, batch: 159, loss: 0.528 \n",
      "epoch: 014, batch: 160, loss: 0.019 \n",
      "epoch: 014, batch: 161, loss: 0.228 \n",
      "epoch: 014, batch: 162, loss: 0.014 \n",
      "epoch: 014, batch: 163, loss: 0.094 \n",
      "epoch: 014, batch: 164, loss: 0.633 \n",
      "epoch: 014, batch: 165, loss: 0.221 \n",
      "epoch: 014, batch: 166, loss: 0.077 \n",
      "epoch: 014, batch: 167, loss: 0.006 \n",
      "epoch: 014, batch: 168, loss: 1.716 \n",
      "epoch: 014, batch: 169, loss: 0.541 \n",
      "epoch: 014, batch: 170, loss: 0.046 \n",
      "epoch: 014, batch: 171, loss: 0.232 \n",
      "epoch: 014, batch: 172, loss: 0.573 \n",
      "epoch: 014, batch: 173, loss: 0.148 \n",
      "epoch: 014, batch: 174, loss: 0.015 \n",
      "epoch: 014, batch: 175, loss: 0.075 \n",
      "epoch: 014, batch: 176, loss: 0.004 \n",
      "epoch: 014, batch: 177, loss: 0.000 \n",
      "epoch: 014, batch: 178, loss: 0.006 \n",
      "epoch: 014, batch: 179, loss: 0.151 \n",
      "epoch: 014, batch: 180, loss: 0.003 \n",
      "epoch: 014, batch: 181, loss: 0.142 \n",
      "epoch: 014, batch: 182, loss: 0.003 \n",
      "epoch: 014, batch: 183, loss: 0.001 \n",
      "epoch: 014, batch: 184, loss: 0.104 \n",
      "epoch: 014, batch: 185, loss: 0.000 \n",
      "epoch: 014, batch: 186, loss: 0.002 \n",
      "epoch: 014, batch: 187, loss: 0.073 \n",
      "epoch: 014, batch: 188, loss: 0.037 \n",
      "epoch: 014, batch: 189, loss: 0.000 \n",
      "epoch: 014, batch: 190, loss: 0.024 \n",
      "epoch: 014, batch: 191, loss: 0.067 \n",
      "epoch: 014, batch: 192, loss: 0.000 \n",
      "epoch: 014, batch: 193, loss: 0.318 \n",
      "epoch: 014, batch: 194, loss: 0.096 \n",
      "epoch: 014, batch: 195, loss: 0.045 \n",
      "epoch: 014, batch: 196, loss: 0.041 \n",
      "epoch: 014, batch: 197, loss: 0.123 \n",
      "epoch: 014, batch: 198, loss: 0.004 \n",
      "epoch: 014, batch: 199, loss: 0.064 \n",
      "epoch: 014, batch: 200, loss: 0.013 \n",
      "epoch: 014, batch: 201, loss: 0.004 \n",
      "epoch: 014, batch: 202, loss: 0.010 \n",
      "epoch: 014, batch: 203, loss: 0.007 \n",
      "epoch: 014, batch: 204, loss: 0.081 \n",
      "epoch: 014, batch: 205, loss: 0.153 \n",
      "epoch: 014, batch: 206, loss: 0.110 \n",
      "epoch: 014, batch: 207, loss: 0.003 \n",
      "epoch: 014, batch: 208, loss: 0.004 \n",
      "epoch: 014, batch: 209, loss: 0.005 \n",
      "epoch: 014, batch: 210, loss: 0.005 \n",
      "epoch: 014, batch: 211, loss: 0.116 \n",
      "epoch: 014, batch: 212, loss: 0.000 \n",
      "epoch: 014, batch: 213, loss: 0.002 \n",
      "epoch: 014, batch: 214, loss: 0.012 \n",
      "epoch: 014, batch: 215, loss: 0.102 \n",
      "epoch: 014, batch: 216, loss: 0.047 \n",
      "epoch: 014, batch: 217, loss: 0.013 \n",
      "epoch: 014, batch: 218, loss: 0.025 \n",
      "epoch: 014, batch: 219, loss: 0.016 \n",
      "epoch: 014, batch: 220, loss: 0.005 \n",
      "epoch: 014, batch: 221, loss: 0.016 \n",
      "epoch: 014, batch: 222, loss: 0.012 \n",
      "epoch: 014, batch: 223, loss: 0.018 \n",
      "epoch: 014, batch: 224, loss: 0.005 \n",
      "epoch: 014, batch: 225, loss: 0.033 \n",
      "epoch: 014, batch: 226, loss: 0.031 \n",
      "epoch: 014, batch: 227, loss: 0.000 \n",
      "epoch: 014 ------------------------------------------------\n",
      "\n",
      "[train] loss: 17.869\n",
      "\n",
      "[validation] bulls_recall: 86.552%\n",
      "\n",
      "[validation] no_bulls_recall: 84.116%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.8533425481428878\n",
      "\n",
      "epoch: 015, batch: 001, loss: 0.011 \n",
      "epoch: 015, batch: 002, loss: 0.013 \n",
      "epoch: 015, batch: 003, loss: 0.002 \n",
      "epoch: 015, batch: 004, loss: 0.015 \n",
      "epoch: 015, batch: 005, loss: 0.128 \n",
      "epoch: 015, batch: 006, loss: 0.002 \n",
      "epoch: 015, batch: 007, loss: 0.038 \n",
      "epoch: 015, batch: 008, loss: 0.182 \n",
      "epoch: 015, batch: 009, loss: 0.032 \n",
      "epoch: 015, batch: 010, loss: 0.007 \n",
      "epoch: 015, batch: 011, loss: 0.006 \n",
      "epoch: 015, batch: 012, loss: 0.009 \n",
      "epoch: 015, batch: 013, loss: 0.013 \n",
      "epoch: 015, batch: 014, loss: 0.004 \n",
      "epoch: 015, batch: 015, loss: 0.007 \n",
      "epoch: 015, batch: 016, loss: 0.013 \n",
      "epoch: 015, batch: 017, loss: 0.009 \n",
      "epoch: 015, batch: 018, loss: 0.008 \n",
      "epoch: 015, batch: 019, loss: 0.010 \n",
      "epoch: 015, batch: 020, loss: 0.006 \n",
      "epoch: 015, batch: 021, loss: 0.044 \n",
      "epoch: 015, batch: 022, loss: 0.060 \n",
      "epoch: 015, batch: 023, loss: 0.146 \n",
      "epoch: 015, batch: 024, loss: 0.003 \n",
      "epoch: 015, batch: 025, loss: 0.060 \n",
      "epoch: 015, batch: 026, loss: 0.022 \n",
      "epoch: 015, batch: 027, loss: 0.020 \n",
      "epoch: 015, batch: 028, loss: 0.192 \n",
      "epoch: 015, batch: 029, loss: 0.047 \n",
      "epoch: 015, batch: 030, loss: 0.087 \n",
      "epoch: 015, batch: 031, loss: 0.122 \n",
      "epoch: 015, batch: 032, loss: 0.058 \n",
      "epoch: 015, batch: 033, loss: 0.026 \n",
      "epoch: 015, batch: 034, loss: 0.045 \n",
      "epoch: 015, batch: 035, loss: 0.014 \n",
      "epoch: 015, batch: 036, loss: 0.057 \n",
      "epoch: 015, batch: 037, loss: 0.047 \n",
      "epoch: 015, batch: 038, loss: 0.038 \n",
      "epoch: 015, batch: 039, loss: 0.019 \n",
      "epoch: 015, batch: 040, loss: 0.011 \n",
      "epoch: 015, batch: 041, loss: 0.027 \n",
      "epoch: 015, batch: 042, loss: 0.035 \n",
      "epoch: 015, batch: 043, loss: 0.014 \n",
      "epoch: 015, batch: 044, loss: 0.016 \n",
      "epoch: 015, batch: 045, loss: 0.002 \n",
      "epoch: 015, batch: 046, loss: 0.009 \n",
      "epoch: 015, batch: 047, loss: 0.008 \n",
      "epoch: 015, batch: 048, loss: 0.036 \n",
      "epoch: 015, batch: 049, loss: 0.002 \n",
      "epoch: 015, batch: 050, loss: 0.001 \n",
      "epoch: 015, batch: 051, loss: 0.007 \n",
      "epoch: 015, batch: 052, loss: 0.027 \n",
      "epoch: 015, batch: 053, loss: 0.007 \n",
      "epoch: 015, batch: 054, loss: 0.001 \n",
      "epoch: 015, batch: 055, loss: 0.001 \n",
      "epoch: 015, batch: 056, loss: 0.134 \n",
      "epoch: 015, batch: 057, loss: 0.021 \n",
      "epoch: 015, batch: 058, loss: 0.000 \n",
      "epoch: 015, batch: 059, loss: 0.209 \n",
      "epoch: 015, batch: 060, loss: 0.221 \n",
      "epoch: 015, batch: 061, loss: 0.031 \n",
      "epoch: 015, batch: 062, loss: 0.063 \n",
      "epoch: 015, batch: 063, loss: 0.004 \n",
      "epoch: 015, batch: 064, loss: 1.745 \n",
      "epoch: 015, batch: 065, loss: 0.052 \n",
      "epoch: 015, batch: 066, loss: 0.001 \n",
      "epoch: 015, batch: 067, loss: 0.001 \n",
      "epoch: 015, batch: 068, loss: 0.033 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015, batch: 069, loss: 0.000 \n",
      "epoch: 015, batch: 070, loss: 0.022 \n",
      "epoch: 015, batch: 071, loss: 0.041 \n",
      "epoch: 015, batch: 072, loss: 0.067 \n",
      "epoch: 015, batch: 073, loss: 0.006 \n",
      "epoch: 015, batch: 074, loss: 0.281 \n",
      "epoch: 015, batch: 075, loss: 0.014 \n",
      "epoch: 015, batch: 076, loss: 0.088 \n",
      "epoch: 015, batch: 077, loss: 0.007 \n",
      "epoch: 015, batch: 078, loss: 0.033 \n",
      "epoch: 015, batch: 079, loss: 0.036 \n",
      "epoch: 015, batch: 080, loss: 0.003 \n",
      "epoch: 015, batch: 081, loss: 0.003 \n",
      "epoch: 015, batch: 082, loss: 0.017 \n",
      "epoch: 015, batch: 083, loss: 0.062 \n",
      "epoch: 015, batch: 084, loss: 0.002 \n",
      "epoch: 015, batch: 085, loss: 0.003 \n",
      "epoch: 015, batch: 086, loss: 0.092 \n",
      "epoch: 015, batch: 087, loss: 0.006 \n",
      "epoch: 015, batch: 088, loss: 0.003 \n",
      "epoch: 015, batch: 089, loss: 0.000 \n",
      "epoch: 015, batch: 090, loss: 0.005 \n",
      "epoch: 015, batch: 091, loss: 2.799 \n",
      "epoch: 015, batch: 092, loss: 0.005 \n",
      "epoch: 015, batch: 093, loss: 0.078 \n",
      "epoch: 015, batch: 094, loss: 0.004 \n",
      "epoch: 015, batch: 095, loss: 0.016 \n",
      "epoch: 015, batch: 096, loss: 0.100 \n",
      "epoch: 015, batch: 097, loss: 0.016 \n",
      "epoch: 015, batch: 098, loss: 0.054 \n",
      "epoch: 015, batch: 099, loss: 0.011 \n",
      "epoch: 015, batch: 100, loss: 0.014 \n",
      "epoch: 015, batch: 101, loss: 0.018 \n",
      "epoch: 015, batch: 102, loss: 0.005 \n",
      "epoch: 015, batch: 103, loss: 0.098 \n",
      "epoch: 015, batch: 104, loss: 0.055 \n",
      "epoch: 015, batch: 105, loss: 0.009 \n",
      "epoch: 015, batch: 106, loss: 0.961 \n",
      "epoch: 015, batch: 107, loss: 0.009 \n",
      "epoch: 015, batch: 108, loss: 0.007 \n",
      "epoch: 015, batch: 109, loss: 0.005 \n",
      "epoch: 015, batch: 110, loss: 0.003 \n",
      "epoch: 015, batch: 111, loss: 0.025 \n",
      "epoch: 015, batch: 112, loss: 0.038 \n",
      "epoch: 015, batch: 113, loss: 0.006 \n",
      "epoch: 015, batch: 114, loss: 0.005 \n",
      "epoch: 015, batch: 115, loss: 0.399 \n",
      "epoch: 015, batch: 116, loss: 0.252 \n",
      "epoch: 015, batch: 117, loss: 0.011 \n",
      "epoch: 015, batch: 118, loss: 0.028 \n",
      "epoch: 015, batch: 119, loss: 0.001 \n",
      "epoch: 015, batch: 120, loss: 0.001 \n",
      "epoch: 015, batch: 121, loss: 0.006 \n",
      "epoch: 015, batch: 122, loss: 0.000 \n",
      "epoch: 015, batch: 123, loss: 0.115 \n",
      "epoch: 015, batch: 124, loss: 0.047 \n",
      "epoch: 015, batch: 125, loss: 0.002 \n",
      "epoch: 015, batch: 126, loss: 0.005 \n",
      "epoch: 015, batch: 127, loss: 0.012 \n",
      "epoch: 015, batch: 128, loss: 0.001 \n",
      "epoch: 015, batch: 129, loss: 0.001 \n",
      "epoch: 015, batch: 130, loss: 0.001 \n",
      "epoch: 015, batch: 131, loss: 0.010 \n",
      "epoch: 015, batch: 132, loss: 0.001 \n",
      "epoch: 015, batch: 133, loss: 0.087 \n",
      "epoch: 015, batch: 134, loss: 0.105 \n",
      "epoch: 015, batch: 135, loss: 0.005 \n",
      "epoch: 015, batch: 136, loss: 0.048 \n",
      "epoch: 015, batch: 137, loss: 0.025 \n",
      "epoch: 015, batch: 138, loss: 0.007 \n",
      "epoch: 015, batch: 139, loss: 0.004 \n",
      "epoch: 015, batch: 140, loss: 0.059 \n",
      "epoch: 015, batch: 141, loss: 0.039 \n",
      "epoch: 015, batch: 142, loss: 0.065 \n",
      "epoch: 015, batch: 143, loss: 0.269 \n",
      "epoch: 015, batch: 144, loss: 0.007 \n",
      "epoch: 015, batch: 145, loss: 0.096 \n",
      "epoch: 015, batch: 146, loss: 0.046 \n",
      "epoch: 015, batch: 147, loss: 0.050 \n",
      "epoch: 015, batch: 148, loss: 0.082 \n",
      "epoch: 015, batch: 149, loss: 0.017 \n",
      "epoch: 015, batch: 150, loss: 0.106 \n",
      "epoch: 015, batch: 151, loss: 0.007 \n",
      "epoch: 015, batch: 152, loss: 0.019 \n",
      "epoch: 015, batch: 153, loss: 0.153 \n",
      "epoch: 015, batch: 154, loss: 0.005 \n",
      "epoch: 015, batch: 155, loss: 0.030 \n",
      "epoch: 015, batch: 156, loss: 0.072 \n",
      "epoch: 015, batch: 157, loss: 0.005 \n",
      "epoch: 015, batch: 158, loss: 0.004 \n",
      "epoch: 015, batch: 159, loss: 1.647 \n",
      "epoch: 015, batch: 160, loss: 0.002 \n",
      "epoch: 015, batch: 161, loss: 0.010 \n",
      "epoch: 015, batch: 162, loss: 0.038 \n",
      "epoch: 015, batch: 163, loss: 0.163 \n",
      "epoch: 015, batch: 164, loss: 0.002 \n",
      "epoch: 015, batch: 165, loss: 0.002 \n",
      "epoch: 015, batch: 166, loss: 0.011 \n",
      "epoch: 015, batch: 167, loss: 0.011 \n",
      "epoch: 015, batch: 168, loss: 0.026 \n",
      "epoch: 015, batch: 169, loss: 0.049 \n",
      "epoch: 015, batch: 170, loss: 0.060 \n",
      "epoch: 015, batch: 171, loss: 0.001 \n",
      "epoch: 015, batch: 172, loss: 0.007 \n",
      "epoch: 015, batch: 173, loss: 0.027 \n",
      "epoch: 015, batch: 174, loss: 0.022 \n",
      "epoch: 015, batch: 175, loss: 0.052 \n",
      "epoch: 015, batch: 176, loss: 0.052 \n",
      "epoch: 015, batch: 177, loss: 0.061 \n",
      "epoch: 015, batch: 178, loss: 0.146 \n",
      "epoch: 015, batch: 179, loss: 0.001 \n",
      "epoch: 015, batch: 180, loss: 0.582 \n",
      "epoch: 015, batch: 181, loss: 0.006 \n",
      "epoch: 015, batch: 182, loss: 0.002 \n",
      "epoch: 015, batch: 183, loss: 0.001 \n",
      "epoch: 015, batch: 184, loss: 0.011 \n",
      "epoch: 015, batch: 185, loss: 0.109 \n",
      "epoch: 015, batch: 186, loss: 0.007 \n",
      "epoch: 015, batch: 187, loss: 0.030 \n",
      "epoch: 015, batch: 188, loss: 0.044 \n",
      "epoch: 015, batch: 189, loss: 0.006 \n",
      "epoch: 015, batch: 190, loss: 0.006 \n",
      "epoch: 015, batch: 191, loss: 0.005 \n",
      "epoch: 015, batch: 192, loss: 0.004 \n",
      "epoch: 015, batch: 193, loss: 0.012 \n",
      "epoch: 015, batch: 194, loss: 0.006 \n",
      "epoch: 015, batch: 195, loss: 0.006 \n",
      "epoch: 015, batch: 196, loss: 0.051 \n",
      "epoch: 015, batch: 197, loss: 0.002 \n",
      "epoch: 015, batch: 198, loss: 0.007 \n",
      "epoch: 015, batch: 199, loss: 0.143 \n",
      "epoch: 015, batch: 200, loss: 0.002 \n",
      "epoch: 015, batch: 201, loss: 0.003 \n",
      "epoch: 015, batch: 202, loss: 0.006 \n",
      "epoch: 015, batch: 203, loss: 0.001 \n",
      "epoch: 015, batch: 204, loss: 0.001 \n",
      "epoch: 015, batch: 205, loss: 0.135 \n",
      "epoch: 015, batch: 206, loss: 0.008 \n",
      "epoch: 015, batch: 207, loss: 0.009 \n",
      "epoch: 015, batch: 208, loss: 0.013 \n",
      "epoch: 015, batch: 209, loss: 0.020 \n",
      "epoch: 015, batch: 210, loss: 0.019 \n",
      "epoch: 015, batch: 211, loss: 0.053 \n",
      "epoch: 015, batch: 212, loss: 0.002 \n",
      "epoch: 015, batch: 213, loss: 0.288 \n",
      "epoch: 015, batch: 214, loss: 0.030 \n",
      "epoch: 015, batch: 215, loss: 0.006 \n",
      "epoch: 015, batch: 216, loss: 0.002 \n",
      "epoch: 015, batch: 217, loss: 0.010 \n",
      "epoch: 015, batch: 218, loss: 0.121 \n",
      "epoch: 015, batch: 219, loss: 0.445 \n",
      "epoch: 015, batch: 220, loss: 0.020 \n",
      "epoch: 015, batch: 221, loss: 0.038 \n",
      "epoch: 015, batch: 222, loss: 0.096 \n",
      "epoch: 015, batch: 223, loss: 0.088 \n",
      "epoch: 015, batch: 224, loss: 0.010 \n",
      "epoch: 015, batch: 225, loss: 0.058 \n",
      "epoch: 015, batch: 226, loss: 0.005 \n",
      "epoch: 015, batch: 227, loss: 0.000 \n",
      "epoch: 015 ------------------------------------------------\n",
      "\n",
      "[train] loss: 18.460\n",
      "\n",
      "[validation] bulls_recall: 93.275%\n",
      "\n",
      "[validation] no_bulls_recall: 54.282%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.7377827196299225\n",
      "\n",
      "epoch: 016, batch: 001, loss: 0.041 \n",
      "epoch: 016, batch: 002, loss: 0.012 \n",
      "epoch: 016, batch: 003, loss: 0.008 \n",
      "epoch: 016, batch: 004, loss: 0.381 \n",
      "epoch: 016, batch: 005, loss: 0.006 \n",
      "epoch: 016, batch: 006, loss: 0.159 \n",
      "epoch: 016, batch: 007, loss: 0.018 \n",
      "epoch: 016, batch: 008, loss: 0.728 \n",
      "epoch: 016, batch: 009, loss: 0.119 \n",
      "epoch: 016, batch: 010, loss: 0.020 \n",
      "epoch: 016, batch: 011, loss: 0.024 \n",
      "epoch: 016, batch: 012, loss: 0.044 \n",
      "epoch: 016, batch: 013, loss: 0.000 \n",
      "epoch: 016, batch: 014, loss: 0.002 \n",
      "epoch: 016, batch: 015, loss: 0.001 \n",
      "epoch: 016, batch: 016, loss: 0.012 \n",
      "epoch: 016, batch: 017, loss: 0.001 \n",
      "epoch: 016, batch: 018, loss: 4.513 \n",
      "epoch: 016, batch: 019, loss: 0.002 \n",
      "epoch: 016, batch: 020, loss: 0.001 \n",
      "epoch: 016, batch: 021, loss: 0.005 \n",
      "epoch: 016, batch: 022, loss: 0.005 \n",
      "epoch: 016, batch: 023, loss: 0.033 \n",
      "epoch: 016, batch: 024, loss: 0.006 \n",
      "epoch: 016, batch: 025, loss: 0.250 \n",
      "epoch: 016, batch: 026, loss: 0.120 \n",
      "epoch: 016, batch: 027, loss: 0.160 \n",
      "epoch: 016, batch: 028, loss: 0.036 \n",
      "epoch: 016, batch: 029, loss: 0.203 \n",
      "epoch: 016, batch: 030, loss: 0.005 \n",
      "epoch: 016, batch: 031, loss: 0.009 \n",
      "epoch: 016, batch: 032, loss: 0.006 \n",
      "epoch: 016, batch: 033, loss: 0.023 \n",
      "epoch: 016, batch: 034, loss: 0.014 \n",
      "epoch: 016, batch: 035, loss: 0.014 \n",
      "epoch: 016, batch: 036, loss: 0.190 \n",
      "epoch: 016, batch: 037, loss: 0.053 \n",
      "epoch: 016, batch: 038, loss: 0.010 \n",
      "epoch: 016, batch: 039, loss: 0.015 \n",
      "epoch: 016, batch: 040, loss: 0.005 \n",
      "epoch: 016, batch: 041, loss: 0.073 \n",
      "epoch: 016, batch: 042, loss: 0.047 \n",
      "epoch: 016, batch: 043, loss: 0.007 \n",
      "epoch: 016, batch: 044, loss: 0.029 \n",
      "epoch: 016, batch: 045, loss: 0.003 \n",
      "epoch: 016, batch: 046, loss: 0.016 \n",
      "epoch: 016, batch: 047, loss: 0.050 \n",
      "epoch: 016, batch: 048, loss: 0.008 \n",
      "epoch: 016, batch: 049, loss: 0.008 \n",
      "epoch: 016, batch: 050, loss: 0.087 \n",
      "epoch: 016, batch: 051, loss: 0.002 \n",
      "epoch: 016, batch: 052, loss: 0.005 \n",
      "epoch: 016, batch: 053, loss: 0.009 \n",
      "epoch: 016, batch: 054, loss: 0.047 \n",
      "epoch: 016, batch: 055, loss: 0.340 \n",
      "epoch: 016, batch: 056, loss: 0.002 \n",
      "epoch: 016, batch: 057, loss: 0.003 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016, batch: 058, loss: 0.011 \n",
      "epoch: 016, batch: 059, loss: 0.016 \n",
      "epoch: 016, batch: 060, loss: 0.001 \n",
      "epoch: 016, batch: 061, loss: 0.002 \n",
      "epoch: 016, batch: 062, loss: 0.002 \n",
      "epoch: 016, batch: 063, loss: 0.245 \n",
      "epoch: 016, batch: 064, loss: 0.036 \n",
      "epoch: 016, batch: 065, loss: 0.169 \n",
      "epoch: 016, batch: 066, loss: 0.006 \n",
      "epoch: 016, batch: 067, loss: 0.028 \n",
      "epoch: 016, batch: 068, loss: 0.014 \n",
      "epoch: 016, batch: 069, loss: 0.068 \n",
      "epoch: 016, batch: 070, loss: 0.019 \n",
      "epoch: 016, batch: 071, loss: 0.046 \n",
      "epoch: 016, batch: 072, loss: 0.006 \n",
      "epoch: 016, batch: 073, loss: 0.009 \n",
      "epoch: 016, batch: 074, loss: 0.018 \n",
      "epoch: 016, batch: 075, loss: 0.013 \n",
      "epoch: 016, batch: 076, loss: 0.010 \n",
      "epoch: 016, batch: 077, loss: 0.016 \n",
      "epoch: 016, batch: 078, loss: 0.038 \n",
      "epoch: 016, batch: 079, loss: 0.009 \n",
      "epoch: 016, batch: 080, loss: 0.008 \n",
      "epoch: 016, batch: 081, loss: 0.027 \n",
      "epoch: 016, batch: 082, loss: 0.008 \n",
      "epoch: 016, batch: 083, loss: 0.004 \n",
      "epoch: 016, batch: 084, loss: 0.005 \n",
      "epoch: 016, batch: 085, loss: 0.038 \n",
      "epoch: 016, batch: 086, loss: 6.230 \n",
      "epoch: 016, batch: 087, loss: 0.022 \n",
      "epoch: 016, batch: 088, loss: 0.009 \n",
      "epoch: 016, batch: 089, loss: 0.248 \n",
      "epoch: 016, batch: 090, loss: 0.019 \n",
      "epoch: 016, batch: 091, loss: 0.029 \n",
      "epoch: 016, batch: 092, loss: 0.005 \n",
      "epoch: 016, batch: 093, loss: 0.026 \n",
      "epoch: 016, batch: 094, loss: 0.013 \n",
      "epoch: 016, batch: 095, loss: 0.316 \n",
      "epoch: 016, batch: 096, loss: 0.016 \n",
      "epoch: 016, batch: 097, loss: 0.008 \n",
      "epoch: 016, batch: 098, loss: 0.005 \n",
      "epoch: 016, batch: 099, loss: 0.005 \n",
      "epoch: 016, batch: 100, loss: 0.003 \n",
      "epoch: 016, batch: 101, loss: 0.003 \n",
      "epoch: 016, batch: 102, loss: 0.014 \n",
      "epoch: 016, batch: 103, loss: 0.080 \n",
      "epoch: 016, batch: 104, loss: 0.022 \n",
      "epoch: 016, batch: 105, loss: 0.006 \n",
      "epoch: 016, batch: 106, loss: 0.086 \n",
      "epoch: 016, batch: 107, loss: 0.013 \n",
      "epoch: 016, batch: 108, loss: 0.012 \n",
      "epoch: 016, batch: 109, loss: 0.005 \n",
      "epoch: 016, batch: 110, loss: 0.002 \n",
      "epoch: 016, batch: 111, loss: 0.095 \n",
      "epoch: 016, batch: 112, loss: 0.006 \n",
      "epoch: 016, batch: 113, loss: 0.007 \n",
      "epoch: 016, batch: 114, loss: 0.113 \n",
      "epoch: 016, batch: 115, loss: 0.001 \n",
      "epoch: 016, batch: 116, loss: 0.002 \n",
      "epoch: 016, batch: 117, loss: 0.001 \n",
      "epoch: 016, batch: 118, loss: 0.006 \n",
      "epoch: 016, batch: 119, loss: 0.023 \n",
      "epoch: 016, batch: 120, loss: 0.002 \n",
      "epoch: 016, batch: 121, loss: 0.007 \n",
      "epoch: 016, batch: 122, loss: 0.005 \n",
      "epoch: 016, batch: 123, loss: 0.001 \n",
      "epoch: 016, batch: 124, loss: 0.004 \n",
      "epoch: 016, batch: 125, loss: 0.003 \n",
      "epoch: 016, batch: 126, loss: 0.189 \n",
      "epoch: 016, batch: 127, loss: 0.003 \n",
      "epoch: 016, batch: 128, loss: 0.001 \n",
      "epoch: 016, batch: 129, loss: 0.001 \n",
      "epoch: 016, batch: 130, loss: 0.002 \n",
      "epoch: 016, batch: 131, loss: 0.049 \n",
      "epoch: 016, batch: 132, loss: 0.003 \n",
      "epoch: 016, batch: 133, loss: 0.003 \n",
      "epoch: 016, batch: 134, loss: 0.015 \n",
      "epoch: 016, batch: 135, loss: 0.626 \n",
      "epoch: 016, batch: 136, loss: 0.004 \n",
      "epoch: 016, batch: 137, loss: 0.040 \n",
      "epoch: 016, batch: 138, loss: 0.002 \n",
      "epoch: 016, batch: 139, loss: 0.088 \n",
      "epoch: 016, batch: 140, loss: 0.148 \n",
      "epoch: 016, batch: 141, loss: 0.010 \n",
      "epoch: 016, batch: 142, loss: 0.003 \n",
      "epoch: 016, batch: 143, loss: 0.002 \n",
      "epoch: 016, batch: 144, loss: 0.006 \n",
      "epoch: 016, batch: 145, loss: 0.077 \n",
      "epoch: 016, batch: 146, loss: 0.000 \n",
      "epoch: 016, batch: 147, loss: 0.030 \n",
      "epoch: 016, batch: 148, loss: 0.006 \n",
      "epoch: 016, batch: 149, loss: 0.001 \n",
      "epoch: 016, batch: 150, loss: 0.001 \n",
      "epoch: 016, batch: 151, loss: 0.001 \n",
      "epoch: 016, batch: 152, loss: 0.010 \n",
      "epoch: 016, batch: 153, loss: 0.001 \n",
      "epoch: 016, batch: 154, loss: 0.001 \n",
      "epoch: 016, batch: 155, loss: 0.021 \n",
      "epoch: 016, batch: 156, loss: 0.237 \n",
      "epoch: 016, batch: 157, loss: 0.009 \n",
      "epoch: 016, batch: 158, loss: 0.009 \n",
      "epoch: 016, batch: 159, loss: 0.001 \n",
      "epoch: 016, batch: 160, loss: 0.006 \n",
      "epoch: 016, batch: 161, loss: 0.178 \n",
      "epoch: 016, batch: 162, loss: 0.019 \n",
      "epoch: 016, batch: 163, loss: 0.001 \n",
      "epoch: 016, batch: 164, loss: 0.004 \n",
      "epoch: 016, batch: 165, loss: 0.173 \n",
      "epoch: 016, batch: 166, loss: 0.000 \n",
      "epoch: 016, batch: 167, loss: 0.010 \n",
      "epoch: 016, batch: 168, loss: 0.025 \n",
      "epoch: 016, batch: 169, loss: 0.310 \n",
      "epoch: 016, batch: 170, loss: 0.004 \n",
      "epoch: 016, batch: 171, loss: 0.004 \n",
      "epoch: 016, batch: 172, loss: 0.049 \n",
      "epoch: 016, batch: 173, loss: 0.005 \n",
      "epoch: 016, batch: 174, loss: 0.005 \n",
      "epoch: 016, batch: 175, loss: 0.009 \n",
      "epoch: 016, batch: 176, loss: 0.005 \n",
      "epoch: 016, batch: 177, loss: 0.071 \n",
      "epoch: 016, batch: 178, loss: 0.009 \n",
      "epoch: 016, batch: 179, loss: 0.013 \n",
      "epoch: 016, batch: 180, loss: 0.113 \n",
      "epoch: 016, batch: 181, loss: 0.016 \n",
      "epoch: 016, batch: 182, loss: 0.009 \n",
      "epoch: 016, batch: 183, loss: 0.072 \n",
      "epoch: 016, batch: 184, loss: 0.029 \n",
      "epoch: 016, batch: 185, loss: 0.005 \n",
      "epoch: 016, batch: 186, loss: 0.022 \n",
      "epoch: 016, batch: 187, loss: 0.131 \n",
      "epoch: 016, batch: 188, loss: 0.007 \n",
      "epoch: 016, batch: 189, loss: 0.092 \n",
      "epoch: 016, batch: 190, loss: 0.004 \n",
      "epoch: 016, batch: 191, loss: 0.003 \n",
      "epoch: 016, batch: 192, loss: 0.001 \n",
      "epoch: 016, batch: 193, loss: 0.683 \n",
      "epoch: 016, batch: 194, loss: 0.002 \n",
      "epoch: 016, batch: 195, loss: 0.005 \n",
      "epoch: 016, batch: 196, loss: 0.015 \n",
      "epoch: 016, batch: 197, loss: 0.001 \n",
      "epoch: 016, batch: 198, loss: 0.001 \n",
      "epoch: 016, batch: 199, loss: 0.005 \n",
      "epoch: 016, batch: 200, loss: 0.001 \n",
      "epoch: 016, batch: 201, loss: 0.058 \n",
      "epoch: 016, batch: 202, loss: 0.003 \n",
      "epoch: 016, batch: 203, loss: 0.001 \n",
      "epoch: 016, batch: 204, loss: 0.023 \n",
      "epoch: 016, batch: 205, loss: 0.001 \n",
      "epoch: 016, batch: 206, loss: 0.001 \n",
      "epoch: 016, batch: 207, loss: 0.512 \n",
      "epoch: 016, batch: 208, loss: 0.000 \n",
      "epoch: 016, batch: 209, loss: 0.098 \n",
      "epoch: 016, batch: 210, loss: 0.001 \n",
      "epoch: 016, batch: 211, loss: 0.000 \n",
      "epoch: 016, batch: 212, loss: 0.017 \n",
      "epoch: 016, batch: 213, loss: 0.004 \n",
      "epoch: 016, batch: 214, loss: 0.001 \n",
      "epoch: 016, batch: 215, loss: 0.119 \n",
      "epoch: 016, batch: 216, loss: 0.003 \n",
      "epoch: 016, batch: 217, loss: 0.017 \n",
      "epoch: 016, batch: 218, loss: 0.000 \n",
      "epoch: 016, batch: 219, loss: 0.008 \n",
      "epoch: 016, batch: 220, loss: 6.200 \n",
      "epoch: 016, batch: 221, loss: 0.028 \n",
      "epoch: 016, batch: 222, loss: 0.087 \n",
      "epoch: 016, batch: 223, loss: 0.046 \n",
      "epoch: 016, batch: 224, loss: 0.037 \n",
      "epoch: 016, batch: 225, loss: 0.033 \n",
      "epoch: 016, batch: 226, loss: 0.045 \n",
      "epoch: 016, batch: 227, loss: 0.014 \n",
      "epoch: 016 ------------------------------------------------\n",
      "\n",
      "[train] loss: 16.245\n",
      "\n",
      "[validation] bulls_recall: 76.468%\n",
      "\n",
      "[validation] no_bulls_recall: 89.081%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.8277488231054579\n",
      "\n",
      "epoch: 017, batch: 001, loss: 0.041 \n",
      "epoch: 017, batch: 002, loss: 0.022 \n",
      "epoch: 017, batch: 003, loss: 0.020 \n",
      "epoch: 017, batch: 004, loss: 0.067 \n",
      "epoch: 017, batch: 005, loss: 0.016 \n",
      "epoch: 017, batch: 006, loss: 0.012 \n",
      "epoch: 017, batch: 007, loss: 0.004 \n",
      "epoch: 017, batch: 008, loss: 0.016 \n",
      "epoch: 017, batch: 009, loss: 0.004 \n",
      "epoch: 017, batch: 010, loss: 0.003 \n",
      "epoch: 017, batch: 011, loss: 0.008 \n",
      "epoch: 017, batch: 012, loss: 0.012 \n",
      "epoch: 017, batch: 013, loss: 0.003 \n",
      "epoch: 017, batch: 014, loss: 0.220 \n",
      "epoch: 017, batch: 015, loss: 0.016 \n",
      "epoch: 017, batch: 016, loss: 0.152 \n",
      "epoch: 017, batch: 017, loss: 0.022 \n",
      "epoch: 017, batch: 018, loss: 0.006 \n",
      "epoch: 017, batch: 019, loss: 0.009 \n",
      "epoch: 017, batch: 020, loss: 0.003 \n",
      "epoch: 017, batch: 021, loss: 0.005 \n",
      "epoch: 017, batch: 022, loss: 0.001 \n",
      "epoch: 017, batch: 023, loss: 0.002 \n",
      "epoch: 017, batch: 024, loss: 0.002 \n",
      "epoch: 017, batch: 025, loss: 0.001 \n",
      "epoch: 017, batch: 026, loss: 0.002 \n",
      "epoch: 017, batch: 027, loss: 0.001 \n",
      "epoch: 017, batch: 028, loss: 0.003 \n",
      "epoch: 017, batch: 029, loss: 0.004 \n",
      "epoch: 017, batch: 030, loss: 0.007 \n",
      "epoch: 017, batch: 031, loss: 0.009 \n",
      "epoch: 017, batch: 032, loss: 0.002 \n",
      "epoch: 017, batch: 033, loss: 0.204 \n",
      "epoch: 017, batch: 034, loss: 0.000 \n",
      "epoch: 017, batch: 035, loss: 0.001 \n",
      "epoch: 017, batch: 036, loss: 0.000 \n",
      "epoch: 017, batch: 037, loss: 0.066 \n",
      "epoch: 017, batch: 038, loss: 0.001 \n",
      "epoch: 017, batch: 039, loss: 0.005 \n",
      "epoch: 017, batch: 040, loss: 0.005 \n",
      "epoch: 017, batch: 041, loss: 0.013 \n",
      "epoch: 017, batch: 042, loss: 0.005 \n",
      "epoch: 017, batch: 043, loss: 0.004 \n",
      "epoch: 017, batch: 044, loss: 0.007 \n",
      "epoch: 017, batch: 045, loss: 0.037 \n",
      "epoch: 017, batch: 046, loss: 0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017, batch: 047, loss: 0.008 \n",
      "epoch: 017, batch: 048, loss: 0.024 \n",
      "epoch: 017, batch: 049, loss: 0.002 \n",
      "epoch: 017, batch: 050, loss: 0.007 \n",
      "epoch: 017, batch: 051, loss: 0.003 \n",
      "epoch: 017, batch: 052, loss: 0.126 \n",
      "epoch: 017, batch: 053, loss: 0.072 \n",
      "epoch: 017, batch: 054, loss: 0.006 \n",
      "epoch: 017, batch: 055, loss: 0.002 \n",
      "epoch: 017, batch: 056, loss: 0.151 \n",
      "epoch: 017, batch: 057, loss: 0.227 \n",
      "epoch: 017, batch: 058, loss: 0.001 \n",
      "epoch: 017, batch: 059, loss: 0.005 \n",
      "epoch: 017, batch: 060, loss: 0.004 \n",
      "epoch: 017, batch: 061, loss: 0.028 \n",
      "epoch: 017, batch: 062, loss: 0.013 \n",
      "epoch: 017, batch: 063, loss: 0.095 \n",
      "epoch: 017, batch: 064, loss: 0.015 \n",
      "epoch: 017, batch: 065, loss: 0.004 \n",
      "epoch: 017, batch: 066, loss: 0.004 \n",
      "epoch: 017, batch: 067, loss: 0.003 \n",
      "epoch: 017, batch: 068, loss: 0.109 \n",
      "epoch: 017, batch: 069, loss: 0.012 \n",
      "epoch: 017, batch: 070, loss: 0.003 \n",
      "epoch: 017, batch: 071, loss: 0.006 \n",
      "epoch: 017, batch: 072, loss: 0.004 \n",
      "epoch: 017, batch: 073, loss: 0.002 \n",
      "epoch: 017, batch: 074, loss: 0.003 \n",
      "epoch: 017, batch: 075, loss: 0.006 \n",
      "epoch: 017, batch: 076, loss: 0.034 \n",
      "epoch: 017, batch: 077, loss: 0.001 \n",
      "epoch: 017, batch: 078, loss: 0.041 \n",
      "epoch: 017, batch: 079, loss: 0.002 \n",
      "epoch: 017, batch: 080, loss: 0.014 \n",
      "epoch: 017, batch: 081, loss: 0.001 \n",
      "epoch: 017, batch: 082, loss: 0.083 \n",
      "epoch: 017, batch: 083, loss: 0.006 \n",
      "epoch: 017, batch: 084, loss: 0.041 \n",
      "epoch: 017, batch: 085, loss: 0.000 \n",
      "epoch: 017, batch: 086, loss: 0.045 \n",
      "epoch: 017, batch: 087, loss: 0.000 \n",
      "epoch: 017, batch: 088, loss: 0.002 \n",
      "epoch: 017, batch: 089, loss: 0.001 \n",
      "epoch: 017, batch: 090, loss: 0.000 \n",
      "epoch: 017, batch: 091, loss: 0.025 \n",
      "epoch: 017, batch: 092, loss: 0.000 \n",
      "epoch: 017, batch: 093, loss: 0.001 \n",
      "epoch: 017, batch: 094, loss: 0.000 \n",
      "epoch: 017, batch: 095, loss: 0.001 \n",
      "epoch: 017, batch: 096, loss: 0.009 \n",
      "epoch: 017, batch: 097, loss: 0.000 \n",
      "epoch: 017, batch: 098, loss: 0.152 \n",
      "epoch: 017, batch: 099, loss: 0.002 \n",
      "epoch: 017, batch: 100, loss: 4.321 \n",
      "epoch: 017, batch: 101, loss: 0.000 \n",
      "epoch: 017, batch: 102, loss: 0.000 \n",
      "epoch: 017, batch: 103, loss: 0.000 \n",
      "epoch: 017, batch: 104, loss: 0.001 \n",
      "epoch: 017, batch: 105, loss: 0.001 \n",
      "epoch: 017, batch: 106, loss: 0.192 \n",
      "epoch: 017, batch: 107, loss: 0.014 \n",
      "epoch: 017, batch: 108, loss: 0.001 \n",
      "epoch: 017, batch: 109, loss: 0.013 \n",
      "epoch: 017, batch: 110, loss: 0.041 \n",
      "epoch: 017, batch: 111, loss: 0.021 \n",
      "epoch: 017, batch: 112, loss: 0.151 \n",
      "epoch: 017, batch: 113, loss: 0.012 \n",
      "epoch: 017, batch: 114, loss: 0.053 \n",
      "epoch: 017, batch: 115, loss: 0.007 \n",
      "epoch: 017, batch: 116, loss: 0.011 \n",
      "epoch: 017, batch: 117, loss: 0.003 \n",
      "epoch: 017, batch: 118, loss: 0.024 \n",
      "epoch: 017, batch: 119, loss: 0.044 \n",
      "epoch: 017, batch: 120, loss: 0.045 \n",
      "epoch: 017, batch: 121, loss: 0.114 \n",
      "epoch: 017, batch: 122, loss: 0.003 \n",
      "epoch: 017, batch: 123, loss: 0.038 \n",
      "epoch: 017, batch: 124, loss: 0.014 \n",
      "epoch: 017, batch: 125, loss: 0.033 \n",
      "epoch: 017, batch: 126, loss: 0.021 \n",
      "epoch: 017, batch: 127, loss: 0.024 \n",
      "epoch: 017, batch: 128, loss: 0.020 \n",
      "epoch: 017, batch: 129, loss: 0.056 \n",
      "epoch: 017, batch: 130, loss: 0.308 \n",
      "epoch: 017, batch: 131, loss: 0.013 \n",
      "epoch: 017, batch: 132, loss: 0.052 \n",
      "epoch: 017, batch: 133, loss: 0.032 \n",
      "epoch: 017, batch: 134, loss: 0.010 \n",
      "epoch: 017, batch: 135, loss: 0.922 \n",
      "epoch: 017, batch: 136, loss: 0.016 \n",
      "epoch: 017, batch: 137, loss: 0.006 \n",
      "epoch: 017, batch: 138, loss: 0.012 \n",
      "epoch: 017, batch: 139, loss: 0.084 \n",
      "epoch: 017, batch: 140, loss: 0.050 \n",
      "epoch: 017, batch: 141, loss: 0.024 \n",
      "epoch: 017, batch: 142, loss: 0.009 \n",
      "epoch: 017, batch: 143, loss: 0.234 \n",
      "epoch: 017, batch: 144, loss: 0.313 \n",
      "epoch: 017, batch: 145, loss: 0.005 \n",
      "epoch: 017, batch: 146, loss: 0.008 \n",
      "epoch: 017, batch: 147, loss: 0.024 \n",
      "epoch: 017, batch: 148, loss: 0.002 \n",
      "epoch: 017, batch: 149, loss: 0.002 \n",
      "epoch: 017, batch: 150, loss: 0.005 \n",
      "epoch: 017, batch: 151, loss: 0.001 \n",
      "epoch: 017, batch: 152, loss: 0.140 \n",
      "epoch: 017, batch: 153, loss: 0.046 \n",
      "epoch: 017, batch: 154, loss: 0.012 \n",
      "epoch: 017, batch: 155, loss: 0.011 \n",
      "epoch: 017, batch: 156, loss: 0.004 \n",
      "epoch: 017, batch: 157, loss: 0.006 \n",
      "epoch: 017, batch: 158, loss: 0.008 \n",
      "epoch: 017, batch: 159, loss: 0.033 \n",
      "epoch: 017, batch: 160, loss: 0.017 \n",
      "epoch: 017, batch: 161, loss: 0.008 \n",
      "epoch: 017, batch: 162, loss: 0.009 \n",
      "epoch: 017, batch: 163, loss: 0.005 \n",
      "epoch: 017, batch: 164, loss: 0.011 \n",
      "epoch: 017, batch: 165, loss: 0.046 \n",
      "epoch: 017, batch: 166, loss: 0.002 \n",
      "epoch: 017, batch: 167, loss: 0.744 \n",
      "epoch: 017, batch: 168, loss: 0.003 \n",
      "epoch: 017, batch: 169, loss: 0.026 \n",
      "epoch: 017, batch: 170, loss: 0.053 \n",
      "epoch: 017, batch: 171, loss: 0.004 \n",
      "epoch: 017, batch: 172, loss: 0.003 \n",
      "epoch: 017, batch: 173, loss: 0.005 \n",
      "epoch: 017, batch: 174, loss: 0.151 \n",
      "epoch: 017, batch: 175, loss: 0.184 \n",
      "epoch: 017, batch: 176, loss: 0.033 \n",
      "epoch: 017, batch: 177, loss: 0.273 \n",
      "epoch: 017, batch: 178, loss: 0.058 \n",
      "epoch: 017, batch: 179, loss: 0.001 \n",
      "epoch: 017, batch: 180, loss: 0.122 \n",
      "epoch: 017, batch: 181, loss: 0.080 \n",
      "epoch: 017, batch: 182, loss: 0.001 \n",
      "epoch: 017, batch: 183, loss: 0.005 \n",
      "epoch: 017, batch: 184, loss: 0.016 \n",
      "epoch: 017, batch: 185, loss: 0.001 \n",
      "epoch: 017, batch: 186, loss: 0.006 \n",
      "epoch: 017, batch: 187, loss: 0.007 \n",
      "epoch: 017, batch: 188, loss: 0.154 \n",
      "epoch: 017, batch: 189, loss: 0.091 \n",
      "epoch: 017, batch: 190, loss: 0.107 \n",
      "epoch: 017, batch: 191, loss: 0.016 \n",
      "epoch: 017, batch: 192, loss: 0.130 \n",
      "epoch: 017, batch: 193, loss: 0.008 \n",
      "epoch: 017, batch: 194, loss: 0.142 \n",
      "epoch: 017, batch: 195, loss: 0.024 \n",
      "epoch: 017, batch: 196, loss: 0.026 \n",
      "epoch: 017, batch: 197, loss: 0.020 \n",
      "epoch: 017, batch: 198, loss: 0.002 \n",
      "epoch: 017, batch: 199, loss: 0.993 \n",
      "epoch: 017, batch: 200, loss: 0.001 \n",
      "epoch: 017, batch: 201, loss: 0.001 \n",
      "epoch: 017, batch: 202, loss: 0.000 \n",
      "epoch: 017, batch: 203, loss: 0.364 \n",
      "epoch: 017, batch: 204, loss: 0.001 \n",
      "epoch: 017, batch: 205, loss: 0.041 \n",
      "epoch: 017, batch: 206, loss: 0.019 \n",
      "epoch: 017, batch: 207, loss: 0.032 \n",
      "epoch: 017, batch: 208, loss: 0.007 \n",
      "epoch: 017, batch: 209, loss: 0.010 \n",
      "epoch: 017, batch: 210, loss: 0.174 \n",
      "epoch: 017, batch: 211, loss: 0.019 \n",
      "epoch: 017, batch: 212, loss: 0.021 \n",
      "epoch: 017, batch: 213, loss: 0.004 \n",
      "epoch: 017, batch: 214, loss: 0.011 \n",
      "epoch: 017, batch: 215, loss: 0.182 \n",
      "epoch: 017, batch: 216, loss: 0.011 \n",
      "epoch: 017, batch: 217, loss: 0.012 \n",
      "epoch: 017, batch: 218, loss: 0.592 \n",
      "epoch: 017, batch: 219, loss: 0.032 \n",
      "epoch: 017, batch: 220, loss: 0.004 \n",
      "epoch: 017, batch: 221, loss: 0.008 \n",
      "epoch: 017, batch: 222, loss: 0.006 \n",
      "epoch: 017, batch: 223, loss: 0.005 \n",
      "epoch: 017, batch: 224, loss: 0.083 \n",
      "epoch: 017, batch: 225, loss: 0.016 \n",
      "epoch: 017, batch: 226, loss: 0.003 \n",
      "epoch: 017, batch: 227, loss: 0.008 \n",
      "epoch: 017 ------------------------------------------------\n",
      "\n",
      "[train] loss: 16.347\n",
      "\n",
      "[validation] bulls_recall: 42.016%\n",
      "\n",
      "[validation] no_bulls_recall: 97.778%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.6989701973975144\n",
      "\n",
      "epoch: 018, batch: 001, loss: 0.004 \n",
      "epoch: 018, batch: 002, loss: 0.006 \n",
      "epoch: 018, batch: 003, loss: 0.005 \n",
      "epoch: 018, batch: 004, loss: 0.015 \n",
      "epoch: 018, batch: 005, loss: 0.037 \n",
      "epoch: 018, batch: 006, loss: 0.022 \n",
      "epoch: 018, batch: 007, loss: 0.004 \n",
      "epoch: 018, batch: 008, loss: 0.004 \n",
      "epoch: 018, batch: 009, loss: 0.037 \n",
      "epoch: 018, batch: 010, loss: 0.002 \n",
      "epoch: 018, batch: 011, loss: 0.001 \n",
      "epoch: 018, batch: 012, loss: 0.020 \n",
      "epoch: 018, batch: 013, loss: 0.007 \n",
      "epoch: 018, batch: 014, loss: 0.011 \n",
      "epoch: 018, batch: 015, loss: 0.713 \n",
      "epoch: 018, batch: 016, loss: 0.018 \n",
      "epoch: 018, batch: 017, loss: 0.015 \n",
      "epoch: 018, batch: 018, loss: 0.012 \n",
      "epoch: 018, batch: 019, loss: 0.003 \n",
      "epoch: 018, batch: 020, loss: 0.001 \n",
      "epoch: 018, batch: 021, loss: 0.004 \n",
      "epoch: 018, batch: 022, loss: 0.005 \n",
      "epoch: 018, batch: 023, loss: 0.009 \n",
      "epoch: 018, batch: 024, loss: 0.011 \n",
      "epoch: 018, batch: 025, loss: 0.003 \n",
      "epoch: 018, batch: 026, loss: 0.002 \n",
      "epoch: 018, batch: 027, loss: 0.002 \n",
      "epoch: 018, batch: 028, loss: 0.001 \n",
      "epoch: 018, batch: 029, loss: 0.010 \n",
      "epoch: 018, batch: 030, loss: 0.005 \n",
      "epoch: 018, batch: 031, loss: 0.012 \n",
      "epoch: 018, batch: 032, loss: 0.005 \n",
      "epoch: 018, batch: 033, loss: 0.005 \n",
      "epoch: 018, batch: 034, loss: 0.011 \n",
      "epoch: 018, batch: 035, loss: 0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018, batch: 036, loss: 0.028 \n",
      "epoch: 018, batch: 037, loss: 0.038 \n",
      "epoch: 018, batch: 038, loss: 0.000 \n",
      "epoch: 018, batch: 039, loss: 0.095 \n",
      "epoch: 018, batch: 040, loss: 0.194 \n",
      "epoch: 018, batch: 041, loss: 0.028 \n",
      "epoch: 018, batch: 042, loss: 0.002 \n",
      "epoch: 018, batch: 043, loss: 0.017 \n",
      "epoch: 018, batch: 044, loss: 0.018 \n",
      "epoch: 018, batch: 045, loss: 0.009 \n",
      "epoch: 018, batch: 046, loss: 0.008 \n",
      "epoch: 018, batch: 047, loss: 0.001 \n",
      "epoch: 018, batch: 048, loss: 0.001 \n",
      "epoch: 018, batch: 049, loss: 0.006 \n",
      "epoch: 018, batch: 050, loss: 0.106 \n",
      "epoch: 018, batch: 051, loss: 0.108 \n",
      "epoch: 018, batch: 052, loss: 0.005 \n",
      "epoch: 018, batch: 053, loss: 0.011 \n",
      "epoch: 018, batch: 054, loss: 0.015 \n",
      "epoch: 018, batch: 055, loss: 0.000 \n",
      "epoch: 018, batch: 056, loss: 0.015 \n",
      "epoch: 018, batch: 057, loss: 0.001 \n",
      "epoch: 018, batch: 058, loss: 0.025 \n",
      "epoch: 018, batch: 059, loss: 0.001 \n",
      "epoch: 018, batch: 060, loss: 0.001 \n",
      "epoch: 018, batch: 061, loss: 0.042 \n",
      "epoch: 018, batch: 062, loss: 0.000 \n",
      "epoch: 018, batch: 063, loss: 0.006 \n",
      "epoch: 018, batch: 064, loss: 0.000 \n",
      "epoch: 018, batch: 065, loss: 0.001 \n",
      "epoch: 018, batch: 066, loss: 0.001 \n",
      "epoch: 018, batch: 067, loss: 0.014 \n",
      "epoch: 018, batch: 068, loss: 0.010 \n",
      "epoch: 018, batch: 069, loss: 0.000 \n",
      "epoch: 018, batch: 070, loss: 0.000 \n",
      "epoch: 018, batch: 071, loss: 0.039 \n",
      "epoch: 018, batch: 072, loss: 0.001 \n",
      "epoch: 018, batch: 073, loss: 0.074 \n",
      "epoch: 018, batch: 074, loss: 0.000 \n",
      "epoch: 018, batch: 075, loss: 0.007 \n",
      "epoch: 018, batch: 076, loss: 0.002 \n",
      "epoch: 018, batch: 077, loss: 0.047 \n",
      "epoch: 018, batch: 078, loss: 0.001 \n",
      "epoch: 018, batch: 079, loss: 0.440 \n",
      "epoch: 018, batch: 080, loss: 0.008 \n",
      "epoch: 018, batch: 081, loss: 0.002 \n",
      "epoch: 018, batch: 082, loss: 0.030 \n",
      "epoch: 018, batch: 083, loss: 0.087 \n",
      "epoch: 018, batch: 084, loss: 0.025 \n",
      "epoch: 018, batch: 085, loss: 0.001 \n",
      "epoch: 018, batch: 086, loss: 0.001 \n",
      "epoch: 018, batch: 087, loss: 0.000 \n",
      "epoch: 018, batch: 088, loss: 0.003 \n",
      "epoch: 018, batch: 089, loss: 0.002 \n",
      "epoch: 018, batch: 090, loss: 0.001 \n",
      "epoch: 018, batch: 091, loss: 0.003 \n",
      "epoch: 018, batch: 092, loss: 0.006 \n",
      "epoch: 018, batch: 093, loss: 0.100 \n",
      "epoch: 018, batch: 094, loss: 0.005 \n",
      "epoch: 018, batch: 095, loss: 0.003 \n",
      "epoch: 018, batch: 096, loss: 0.033 \n",
      "epoch: 018, batch: 097, loss: 0.005 \n",
      "epoch: 018, batch: 098, loss: 0.087 \n",
      "epoch: 018, batch: 099, loss: 0.514 \n",
      "epoch: 018, batch: 100, loss: 0.004 \n",
      "epoch: 018, batch: 101, loss: 0.015 \n",
      "epoch: 018, batch: 102, loss: 0.008 \n",
      "epoch: 018, batch: 103, loss: 0.014 \n",
      "epoch: 018, batch: 104, loss: 0.033 \n",
      "epoch: 018, batch: 105, loss: 0.011 \n",
      "epoch: 018, batch: 106, loss: 0.003 \n",
      "epoch: 018, batch: 107, loss: 0.002 \n",
      "epoch: 018, batch: 108, loss: 0.004 \n",
      "epoch: 018, batch: 109, loss: 0.024 \n",
      "epoch: 018, batch: 110, loss: 0.048 \n",
      "epoch: 018, batch: 111, loss: 0.005 \n",
      "epoch: 018, batch: 112, loss: 0.043 \n",
      "epoch: 018, batch: 113, loss: 0.005 \n",
      "epoch: 018, batch: 114, loss: 0.066 \n",
      "epoch: 018, batch: 115, loss: 0.012 \n",
      "epoch: 018, batch: 116, loss: 0.010 \n",
      "epoch: 018, batch: 117, loss: 0.003 \n",
      "epoch: 018, batch: 118, loss: 0.026 \n",
      "epoch: 018, batch: 119, loss: 0.019 \n",
      "epoch: 018, batch: 120, loss: 0.005 \n",
      "epoch: 018, batch: 121, loss: 0.009 \n",
      "epoch: 018, batch: 122, loss: 0.011 \n",
      "epoch: 018, batch: 123, loss: 0.004 \n",
      "epoch: 018, batch: 124, loss: 0.203 \n",
      "epoch: 018, batch: 125, loss: 0.012 \n",
      "epoch: 018, batch: 126, loss: 0.022 \n",
      "epoch: 018, batch: 127, loss: 0.000 \n",
      "epoch: 018, batch: 128, loss: 0.156 \n",
      "epoch: 018, batch: 129, loss: 0.031 \n",
      "epoch: 018, batch: 130, loss: 0.004 \n",
      "epoch: 018, batch: 131, loss: 0.003 \n",
      "epoch: 018, batch: 132, loss: 0.116 \n",
      "epoch: 018, batch: 133, loss: 0.008 \n",
      "epoch: 018, batch: 134, loss: 0.334 \n",
      "epoch: 018, batch: 135, loss: 0.001 \n",
      "epoch: 018, batch: 136, loss: 0.008 \n",
      "epoch: 018, batch: 137, loss: 0.033 \n",
      "epoch: 018, batch: 138, loss: 0.009 \n",
      "epoch: 018, batch: 139, loss: 0.007 \n",
      "epoch: 018, batch: 140, loss: 0.204 \n",
      "epoch: 018, batch: 141, loss: 0.015 \n",
      "epoch: 018, batch: 142, loss: 0.002 \n",
      "epoch: 018, batch: 143, loss: 3.600 \n",
      "epoch: 018, batch: 144, loss: 0.003 \n",
      "epoch: 018, batch: 145, loss: 0.008 \n",
      "epoch: 018, batch: 146, loss: 0.004 \n",
      "epoch: 018, batch: 147, loss: 0.064 \n",
      "epoch: 018, batch: 148, loss: 0.078 \n",
      "epoch: 018, batch: 149, loss: 0.251 \n",
      "epoch: 018, batch: 150, loss: 0.010 \n",
      "epoch: 018, batch: 151, loss: 0.007 \n",
      "epoch: 018, batch: 152, loss: 0.011 \n",
      "epoch: 018, batch: 153, loss: 0.008 \n",
      "epoch: 018, batch: 154, loss: 0.010 \n",
      "epoch: 018, batch: 155, loss: 0.003 \n",
      "epoch: 018, batch: 156, loss: 0.048 \n",
      "epoch: 018, batch: 157, loss: 0.006 \n",
      "epoch: 018, batch: 158, loss: 0.012 \n",
      "epoch: 018, batch: 159, loss: 0.014 \n",
      "epoch: 018, batch: 160, loss: 0.065 \n",
      "epoch: 018, batch: 161, loss: 0.360 \n",
      "epoch: 018, batch: 162, loss: 0.001 \n",
      "epoch: 018, batch: 163, loss: 0.003 \n",
      "epoch: 018, batch: 164, loss: 0.003 \n",
      "epoch: 018, batch: 165, loss: 0.002 \n",
      "epoch: 018, batch: 166, loss: 0.068 \n",
      "epoch: 018, batch: 167, loss: 0.001 \n",
      "epoch: 018, batch: 168, loss: 0.008 \n",
      "epoch: 018, batch: 169, loss: 0.007 \n",
      "epoch: 018, batch: 170, loss: 0.002 \n",
      "epoch: 018, batch: 171, loss: 0.030 \n",
      "epoch: 018, batch: 172, loss: 0.010 \n",
      "epoch: 018, batch: 173, loss: 0.002 \n",
      "epoch: 018, batch: 174, loss: 0.017 \n",
      "epoch: 018, batch: 175, loss: 0.008 \n",
      "epoch: 018, batch: 176, loss: 0.004 \n",
      "epoch: 018, batch: 177, loss: 0.011 \n",
      "epoch: 018, batch: 178, loss: 0.016 \n",
      "epoch: 018, batch: 179, loss: 0.004 \n",
      "epoch: 018, batch: 180, loss: 0.001 \n",
      "epoch: 018, batch: 181, loss: 0.015 \n",
      "epoch: 018, batch: 182, loss: 0.071 \n",
      "epoch: 018, batch: 183, loss: 0.051 \n",
      "epoch: 018, batch: 184, loss: 0.078 \n",
      "epoch: 018, batch: 185, loss: 0.009 \n",
      "epoch: 018, batch: 186, loss: 0.008 \n",
      "epoch: 018, batch: 187, loss: 0.003 \n",
      "epoch: 018, batch: 188, loss: 0.713 \n",
      "epoch: 018, batch: 189, loss: 0.002 \n",
      "epoch: 018, batch: 190, loss: 0.003 \n",
      "epoch: 018, batch: 191, loss: 0.066 \n",
      "epoch: 018, batch: 192, loss: 0.003 \n",
      "epoch: 018, batch: 193, loss: 0.195 \n",
      "epoch: 018, batch: 194, loss: 0.010 \n",
      "epoch: 018, batch: 195, loss: 0.003 \n",
      "epoch: 018, batch: 196, loss: 0.007 \n",
      "epoch: 018, batch: 197, loss: 0.043 \n",
      "epoch: 018, batch: 198, loss: 0.002 \n",
      "epoch: 018, batch: 199, loss: 0.001 \n",
      "epoch: 018, batch: 200, loss: 0.002 \n",
      "epoch: 018, batch: 201, loss: 0.002 \n",
      "epoch: 018, batch: 202, loss: 0.030 \n",
      "epoch: 018, batch: 203, loss: 0.000 \n",
      "epoch: 018, batch: 204, loss: 0.000 \n",
      "epoch: 018, batch: 205, loss: 0.021 \n",
      "epoch: 018, batch: 206, loss: 0.005 \n",
      "epoch: 018, batch: 207, loss: 0.006 \n",
      "epoch: 018, batch: 208, loss: 0.007 \n",
      "epoch: 018, batch: 209, loss: 0.063 \n",
      "epoch: 018, batch: 210, loss: 0.013 \n",
      "epoch: 018, batch: 211, loss: 0.042 \n",
      "epoch: 018, batch: 212, loss: 0.018 \n",
      "epoch: 018, batch: 213, loss: 0.116 \n",
      "epoch: 018, batch: 214, loss: 0.047 \n",
      "epoch: 018, batch: 215, loss: 0.038 \n",
      "epoch: 018, batch: 216, loss: 0.014 \n",
      "epoch: 018, batch: 217, loss: 0.007 \n",
      "epoch: 018, batch: 218, loss: 0.002 \n",
      "epoch: 018, batch: 219, loss: 0.003 \n",
      "epoch: 018, batch: 220, loss: 0.004 \n",
      "epoch: 018, batch: 221, loss: 0.005 \n",
      "epoch: 018, batch: 222, loss: 0.021 \n",
      "epoch: 018, batch: 223, loss: 0.002 \n",
      "epoch: 018, batch: 224, loss: 0.002 \n",
      "epoch: 018, batch: 225, loss: 0.157 \n",
      "epoch: 018, batch: 226, loss: 0.005 \n",
      "epoch: 018, batch: 227, loss: 0.002 \n",
      "epoch: 018 ------------------------------------------------\n",
      "\n",
      "[train] loss: 13.691\n",
      "\n",
      "[validation] bulls_recall: 90.474%\n",
      "\n",
      "[validation] no_bulls_recall: 17.216%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5384506023575006\n",
      "\n",
      "epoch: 019, batch: 001, loss: 0.007 \n",
      "epoch: 019, batch: 002, loss: 0.002 \n",
      "epoch: 019, batch: 003, loss: 0.031 \n",
      "epoch: 019, batch: 004, loss: 0.017 \n",
      "epoch: 019, batch: 005, loss: 0.004 \n",
      "epoch: 019, batch: 006, loss: 0.106 \n",
      "epoch: 019, batch: 007, loss: 0.002 \n",
      "epoch: 019, batch: 008, loss: 0.001 \n",
      "epoch: 019, batch: 009, loss: 0.001 \n",
      "epoch: 019, batch: 010, loss: 0.020 \n",
      "epoch: 019, batch: 011, loss: 0.003 \n",
      "epoch: 019, batch: 012, loss: 0.002 \n",
      "epoch: 019, batch: 013, loss: 0.001 \n",
      "epoch: 019, batch: 014, loss: 0.001 \n",
      "epoch: 019, batch: 015, loss: 0.001 \n",
      "epoch: 019, batch: 016, loss: 0.001 \n",
      "epoch: 019, batch: 017, loss: 0.001 \n",
      "epoch: 019, batch: 018, loss: 0.003 \n",
      "epoch: 019, batch: 019, loss: 0.002 \n",
      "epoch: 019, batch: 020, loss: 0.001 \n",
      "epoch: 019, batch: 021, loss: 0.040 \n",
      "epoch: 019, batch: 022, loss: 0.155 \n",
      "epoch: 019, batch: 023, loss: 0.000 \n",
      "epoch: 019, batch: 024, loss: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019, batch: 025, loss: 0.000 \n",
      "epoch: 019, batch: 026, loss: 0.001 \n",
      "epoch: 019, batch: 027, loss: 0.001 \n",
      "epoch: 019, batch: 028, loss: 0.010 \n",
      "epoch: 019, batch: 029, loss: 0.025 \n",
      "epoch: 019, batch: 030, loss: 0.025 \n",
      "epoch: 019, batch: 031, loss: 0.112 \n",
      "epoch: 019, batch: 032, loss: 0.051 \n",
      "epoch: 019, batch: 033, loss: 0.087 \n",
      "epoch: 019, batch: 034, loss: 0.023 \n",
      "epoch: 019, batch: 035, loss: 0.013 \n",
      "epoch: 019, batch: 036, loss: 0.128 \n",
      "epoch: 019, batch: 037, loss: 0.016 \n",
      "epoch: 019, batch: 038, loss: 0.008 \n",
      "epoch: 019, batch: 039, loss: 0.036 \n",
      "epoch: 019, batch: 040, loss: 0.055 \n",
      "epoch: 019, batch: 041, loss: 0.004 \n",
      "epoch: 019, batch: 042, loss: 0.002 \n",
      "epoch: 019, batch: 043, loss: 0.016 \n",
      "epoch: 019, batch: 044, loss: 0.001 \n",
      "epoch: 019, batch: 045, loss: 0.019 \n",
      "epoch: 019, batch: 046, loss: 0.012 \n",
      "epoch: 019, batch: 047, loss: 0.014 \n",
      "epoch: 019, batch: 048, loss: 0.001 \n",
      "epoch: 019, batch: 049, loss: 0.002 \n",
      "epoch: 019, batch: 050, loss: 0.001 \n",
      "epoch: 019, batch: 051, loss: 0.002 \n",
      "epoch: 019, batch: 052, loss: 0.004 \n",
      "epoch: 019, batch: 053, loss: 0.003 \n",
      "epoch: 019, batch: 054, loss: 0.648 \n",
      "epoch: 019, batch: 055, loss: 0.002 \n",
      "epoch: 019, batch: 056, loss: 0.118 \n",
      "epoch: 019, batch: 057, loss: 0.020 \n",
      "epoch: 019, batch: 058, loss: 0.003 \n",
      "epoch: 019, batch: 059, loss: 0.009 \n",
      "epoch: 019, batch: 060, loss: 0.035 \n",
      "epoch: 019, batch: 061, loss: 0.003 \n",
      "epoch: 019, batch: 062, loss: 0.014 \n",
      "epoch: 019, batch: 063, loss: 0.015 \n",
      "epoch: 019, batch: 064, loss: 0.005 \n",
      "epoch: 019, batch: 065, loss: 0.012 \n",
      "epoch: 019, batch: 066, loss: 0.004 \n",
      "epoch: 019, batch: 067, loss: 0.022 \n",
      "epoch: 019, batch: 068, loss: 0.004 \n",
      "epoch: 019, batch: 069, loss: 0.002 \n",
      "epoch: 019, batch: 070, loss: 0.031 \n",
      "epoch: 019, batch: 071, loss: 0.001 \n",
      "epoch: 019, batch: 072, loss: 0.010 \n",
      "epoch: 019, batch: 073, loss: 0.097 \n",
      "epoch: 019, batch: 074, loss: 0.002 \n",
      "epoch: 019, batch: 075, loss: 0.003 \n",
      "epoch: 019, batch: 076, loss: 0.003 \n",
      "epoch: 019, batch: 077, loss: 0.005 \n",
      "epoch: 019, batch: 078, loss: 0.002 \n",
      "epoch: 019, batch: 079, loss: 0.001 \n",
      "epoch: 019, batch: 080, loss: 0.006 \n",
      "epoch: 019, batch: 081, loss: 0.009 \n",
      "epoch: 019, batch: 082, loss: 0.000 \n",
      "epoch: 019, batch: 083, loss: 0.085 \n",
      "epoch: 019, batch: 084, loss: 0.126 \n",
      "epoch: 019, batch: 085, loss: 0.011 \n",
      "epoch: 019, batch: 086, loss: 0.261 \n",
      "epoch: 019, batch: 087, loss: 0.015 \n",
      "epoch: 019, batch: 088, loss: 0.202 \n",
      "epoch: 019, batch: 089, loss: 2.028 \n",
      "epoch: 019, batch: 090, loss: 0.002 \n",
      "epoch: 019, batch: 091, loss: 0.013 \n",
      "epoch: 019, batch: 092, loss: 0.038 \n",
      "epoch: 019, batch: 093, loss: 0.016 \n",
      "epoch: 019, batch: 094, loss: 0.117 \n",
      "epoch: 019, batch: 095, loss: 0.013 \n",
      "epoch: 019, batch: 096, loss: 0.104 \n",
      "epoch: 019, batch: 097, loss: 0.016 \n",
      "epoch: 019, batch: 098, loss: 0.005 \n",
      "epoch: 019, batch: 099, loss: 0.152 \n",
      "epoch: 019, batch: 100, loss: 0.024 \n",
      "epoch: 019, batch: 101, loss: 0.060 \n",
      "epoch: 019, batch: 102, loss: 0.085 \n",
      "epoch: 019, batch: 103, loss: 0.059 \n",
      "epoch: 019, batch: 104, loss: 0.030 \n",
      "epoch: 019, batch: 105, loss: 0.002 \n",
      "epoch: 019, batch: 106, loss: 0.004 \n",
      "epoch: 019, batch: 107, loss: 0.002 \n",
      "epoch: 019, batch: 108, loss: 0.002 \n",
      "epoch: 019, batch: 109, loss: 0.007 \n",
      "epoch: 019, batch: 110, loss: 0.041 \n",
      "epoch: 019, batch: 111, loss: 0.026 \n",
      "epoch: 019, batch: 112, loss: 0.005 \n",
      "epoch: 019, batch: 113, loss: 0.001 \n",
      "epoch: 019, batch: 114, loss: 0.001 \n",
      "epoch: 019, batch: 115, loss: 0.001 \n",
      "epoch: 019, batch: 116, loss: 0.001 \n",
      "epoch: 019, batch: 117, loss: 0.290 \n",
      "epoch: 019, batch: 118, loss: 0.002 \n",
      "epoch: 019, batch: 119, loss: 0.002 \n",
      "epoch: 019, batch: 120, loss: 0.551 \n",
      "epoch: 019, batch: 121, loss: 0.009 \n",
      "epoch: 019, batch: 122, loss: 0.009 \n",
      "epoch: 019, batch: 123, loss: 0.017 \n",
      "epoch: 019, batch: 124, loss: 0.016 \n",
      "epoch: 019, batch: 125, loss: 0.056 \n",
      "epoch: 019, batch: 126, loss: 0.029 \n",
      "epoch: 019, batch: 127, loss: 0.083 \n",
      "epoch: 019, batch: 128, loss: 0.003 \n",
      "epoch: 019, batch: 129, loss: 0.064 \n",
      "epoch: 019, batch: 130, loss: 0.098 \n",
      "epoch: 019, batch: 131, loss: 0.016 \n",
      "epoch: 019, batch: 132, loss: 0.036 \n",
      "epoch: 019, batch: 133, loss: 0.027 \n",
      "epoch: 019, batch: 134, loss: 0.015 \n",
      "epoch: 019, batch: 135, loss: 0.010 \n",
      "epoch: 019, batch: 136, loss: 0.033 \n",
      "epoch: 019, batch: 137, loss: 0.029 \n",
      "epoch: 019, batch: 138, loss: 0.009 \n",
      "epoch: 019, batch: 139, loss: 0.006 \n",
      "epoch: 019, batch: 140, loss: 0.055 \n",
      "epoch: 019, batch: 141, loss: 0.010 \n",
      "epoch: 019, batch: 142, loss: 0.010 \n",
      "epoch: 019, batch: 143, loss: 0.006 \n",
      "epoch: 019, batch: 144, loss: 0.001 \n",
      "epoch: 019, batch: 145, loss: 0.005 \n",
      "epoch: 019, batch: 146, loss: 0.541 \n",
      "epoch: 019, batch: 147, loss: 0.003 \n",
      "epoch: 019, batch: 148, loss: 0.310 \n",
      "epoch: 019, batch: 149, loss: 0.233 \n",
      "epoch: 019, batch: 150, loss: 0.004 \n",
      "epoch: 019, batch: 151, loss: 0.003 \n",
      "epoch: 019, batch: 152, loss: 0.004 \n",
      "epoch: 019, batch: 153, loss: 0.004 \n",
      "epoch: 019, batch: 154, loss: 0.002 \n",
      "epoch: 019, batch: 155, loss: 0.001 \n",
      "epoch: 019, batch: 156, loss: 0.008 \n",
      "epoch: 019, batch: 157, loss: 0.000 \n",
      "epoch: 019, batch: 158, loss: 0.118 \n",
      "epoch: 019, batch: 159, loss: 0.006 \n",
      "epoch: 019, batch: 160, loss: 0.003 \n",
      "epoch: 019, batch: 161, loss: 0.001 \n",
      "epoch: 019, batch: 162, loss: 0.008 \n",
      "epoch: 019, batch: 163, loss: 0.009 \n",
      "epoch: 019, batch: 164, loss: 0.003 \n",
      "epoch: 019, batch: 165, loss: 0.004 \n",
      "epoch: 019, batch: 166, loss: 0.009 \n",
      "epoch: 019, batch: 167, loss: 0.001 \n",
      "epoch: 019, batch: 168, loss: 0.014 \n",
      "epoch: 019, batch: 169, loss: 0.057 \n",
      "epoch: 019, batch: 170, loss: 0.002 \n",
      "epoch: 019, batch: 171, loss: 0.003 \n",
      "epoch: 019, batch: 172, loss: 0.005 \n",
      "epoch: 019, batch: 173, loss: 0.097 \n",
      "epoch: 019, batch: 174, loss: 0.002 \n",
      "epoch: 019, batch: 175, loss: 0.016 \n",
      "epoch: 019, batch: 176, loss: 1.849 \n",
      "epoch: 019, batch: 177, loss: 0.009 \n",
      "epoch: 019, batch: 178, loss: 0.050 \n",
      "epoch: 019, batch: 179, loss: 0.004 \n",
      "epoch: 019, batch: 180, loss: 0.005 \n",
      "epoch: 019, batch: 181, loss: 0.011 \n",
      "epoch: 019, batch: 182, loss: 0.004 \n",
      "epoch: 019, batch: 183, loss: 0.004 \n",
      "epoch: 019, batch: 184, loss: 0.006 \n",
      "epoch: 019, batch: 185, loss: 0.013 \n",
      "epoch: 019, batch: 186, loss: 0.018 \n",
      "epoch: 019, batch: 187, loss: 0.026 \n",
      "epoch: 019, batch: 188, loss: 0.024 \n",
      "epoch: 019, batch: 189, loss: 0.006 \n",
      "epoch: 019, batch: 190, loss: 0.049 \n",
      "epoch: 019, batch: 191, loss: 0.015 \n",
      "epoch: 019, batch: 192, loss: 0.058 \n",
      "epoch: 019, batch: 193, loss: 0.011 \n",
      "epoch: 019, batch: 194, loss: 0.046 \n",
      "epoch: 019, batch: 195, loss: 0.031 \n",
      "epoch: 019, batch: 196, loss: 0.608 \n",
      "epoch: 019, batch: 197, loss: 0.001 \n",
      "epoch: 019, batch: 198, loss: 0.201 \n",
      "epoch: 019, batch: 199, loss: 0.096 \n",
      "epoch: 019, batch: 200, loss: 0.000 \n",
      "epoch: 019, batch: 201, loss: 0.001 \n",
      "epoch: 019, batch: 202, loss: 0.001 \n",
      "epoch: 019, batch: 203, loss: 0.000 \n",
      "epoch: 019, batch: 204, loss: 0.001 \n",
      "epoch: 019, batch: 205, loss: 0.001 \n",
      "epoch: 019, batch: 206, loss: 0.010 \n",
      "epoch: 019, batch: 207, loss: 0.001 \n",
      "epoch: 019, batch: 208, loss: 0.001 \n",
      "epoch: 019, batch: 209, loss: 0.001 \n",
      "epoch: 019, batch: 210, loss: 0.006 \n",
      "epoch: 019, batch: 211, loss: 0.001 \n",
      "epoch: 019, batch: 212, loss: 0.000 \n",
      "epoch: 019, batch: 213, loss: 0.015 \n",
      "epoch: 019, batch: 214, loss: 0.001 \n",
      "epoch: 019, batch: 215, loss: 0.012 \n",
      "epoch: 019, batch: 216, loss: 0.021 \n",
      "epoch: 019, batch: 217, loss: 0.057 \n",
      "epoch: 019, batch: 218, loss: 0.003 \n",
      "epoch: 019, batch: 219, loss: 0.002 \n",
      "epoch: 019, batch: 220, loss: 0.028 \n",
      "epoch: 019, batch: 221, loss: 0.032 \n",
      "epoch: 019, batch: 222, loss: 0.002 \n",
      "epoch: 019, batch: 223, loss: 0.002 \n",
      "epoch: 019, batch: 224, loss: 0.001 \n",
      "epoch: 019, batch: 225, loss: 0.017 \n",
      "epoch: 019, batch: 226, loss: 0.003 \n",
      "epoch: 019, batch: 227, loss: 0.003 \n",
      "epoch: 019 ------------------------------------------------\n",
      "\n",
      "[train] loss: 13.655\n",
      "\n",
      "[validation] bulls_recall: 95.235%\n",
      "\n",
      "[validation] no_bulls_recall: 49.195%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.7221504290501441\n",
      "\n",
      "\n",
      "Final nb epochs : 14\n",
      "Best validation score (= best bulls_fscore) : 0.8533425481428878\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows : real (no_bulls and bulls)  ;  columns : predicted (same) ): \n",
      "345  |  9\n",
      "1447  |  7365\n",
      "\n",
      "[test] accuracy: 84.115%\n",
      "\n",
      "\n",
      "[test] bulls_recall: 97.455%\n",
      "\n",
      "[test] bulls_precision: 19.252%\n",
      "\n",
      "\n",
      "[test] no_bulls_recall: 83.579%\n",
      "\n",
      "[test] no_bulls_precision: 99.878%\n",
      "\n",
      "\n",
      "[test] scoring metric (average recall): 0.905169947385597\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model_vgg16_norm(pretrained=True, freeze=False)\n",
    "name_model = \"model_vgg16simple_norm_pretrained_batchsize128_recov\"\n",
    "batch_size = 128\n",
    "trainloader, validationloader, testloader, weight_bulls, weight_no_bulls = audio_importation(shuffle=True)\n",
    "epochs = 20\n",
    "\n",
    "final_model = training(model=model, name_model=name_model, epochs=epochs, batch_size=batch_size, device=device)\n",
    "\n",
    "test(model=final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001, batch: 001, loss: 0.772 \n",
      "epoch: 001, batch: 002, loss: 0.416 \n",
      "epoch: 001, batch: 003, loss: 0.476 \n",
      "epoch: 001, batch: 004, loss: 0.254 \n",
      "epoch: 001, batch: 005, loss: 1.685 \n",
      "epoch: 001, batch: 006, loss: 0.143 \n",
      "epoch: 001, batch: 007, loss: 0.291 \n",
      "epoch: 001, batch: 008, loss: 0.254 \n",
      "epoch: 001, batch: 009, loss: 0.270 \n",
      "epoch: 001, batch: 010, loss: 1.027 \n",
      "epoch: 001, batch: 011, loss: 0.154 \n",
      "epoch: 001, batch: 012, loss: 1.491 \n",
      "epoch: 001, batch: 013, loss: 0.144 \n",
      "epoch: 001, batch: 014, loss: 1.407 \n",
      "epoch: 001, batch: 015, loss: 0.183 \n",
      "epoch: 001, batch: 016, loss: 0.253 \n",
      "epoch: 001, batch: 017, loss: 0.414 \n",
      "epoch: 001, batch: 018, loss: 0.368 \n",
      "epoch: 001, batch: 019, loss: 0.095 \n",
      "epoch: 001, batch: 020, loss: 0.473 \n",
      "epoch: 001, batch: 021, loss: 0.279 \n",
      "epoch: 001, batch: 022, loss: 0.185 \n",
      "epoch: 001, batch: 023, loss: 0.169 \n",
      "epoch: 001, batch: 024, loss: 0.618 \n",
      "epoch: 001, batch: 025, loss: 0.092 \n",
      "epoch: 001, batch: 026, loss: 0.549 \n",
      "epoch: 001, batch: 027, loss: 0.112 \n",
      "epoch: 001, batch: 028, loss: 0.146 \n",
      "epoch: 001, batch: 029, loss: 0.003 \n",
      "epoch: 001 ------------------------------------------------\n",
      "\n",
      "[train] loss: 13.226\n",
      "\n",
      "[validation] bulls_recall: 89.073%\n",
      "\n",
      "[validation] no_bulls_recall: 52.982%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.7102770778848639\n",
      "\n",
      "epoch: 002, batch: 001, loss: 2.413 \n",
      "epoch: 002, batch: 002, loss: 0.090 \n",
      "epoch: 002, batch: 003, loss: 0.269 \n",
      "epoch: 002, batch: 004, loss: 0.466 \n",
      "epoch: 002, batch: 005, loss: 0.224 \n",
      "epoch: 002, batch: 006, loss: 0.143 \n",
      "epoch: 002, batch: 007, loss: 0.232 \n",
      "epoch: 002, batch: 008, loss: 0.168 \n",
      "epoch: 002, batch: 009, loss: 0.181 \n",
      "epoch: 002, batch: 010, loss: 0.130 \n",
      "epoch: 002, batch: 011, loss: 0.039 \n",
      "epoch: 002, batch: 012, loss: 0.056 \n",
      "epoch: 002, batch: 013, loss: 0.592 \n",
      "epoch: 002, batch: 014, loss: 0.070 \n",
      "epoch: 002, batch: 015, loss: 0.047 \n",
      "epoch: 002, batch: 016, loss: 0.038 \n",
      "epoch: 002, batch: 017, loss: 0.126 \n",
      "epoch: 002, batch: 018, loss: 0.076 \n",
      "epoch: 002, batch: 019, loss: 0.395 \n",
      "epoch: 002, batch: 020, loss: 0.062 \n",
      "epoch: 002, batch: 021, loss: 0.005 \n",
      "epoch: 002, batch: 022, loss: 0.263 \n",
      "epoch: 002, batch: 023, loss: 0.072 \n",
      "epoch: 002, batch: 024, loss: 0.243 \n",
      "epoch: 002, batch: 025, loss: 0.028 \n",
      "epoch: 002, batch: 026, loss: 0.018 \n",
      "epoch: 002, batch: 027, loss: 0.043 \n",
      "epoch: 002, batch: 028, loss: 0.018 \n",
      "epoch: 002, batch: 029, loss: 0.060 \n",
      "epoch: 002 ------------------------------------------------\n",
      "\n",
      "[train] loss: 7.469\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 4.465%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5223118613613531\n",
      "\n",
      "epoch: 003, batch: 001, loss: 0.090 \n",
      "epoch: 003, batch: 002, loss: 0.027 \n",
      "epoch: 003, batch: 003, loss: 0.099 \n",
      "epoch: 003, batch: 004, loss: 0.872 \n",
      "epoch: 003, batch: 005, loss: 0.020 \n",
      "epoch: 003, batch: 006, loss: 0.043 \n",
      "epoch: 003, batch: 007, loss: 0.019 \n",
      "epoch: 003, batch: 008, loss: 0.157 \n",
      "epoch: 003, batch: 009, loss: 0.074 \n",
      "epoch: 003, batch: 010, loss: 0.053 \n",
      "epoch: 003, batch: 011, loss: 0.058 \n",
      "epoch: 003, batch: 012, loss: 0.012 \n",
      "epoch: 003, batch: 013, loss: 0.224 \n",
      "epoch: 003, batch: 014, loss: 0.068 \n",
      "epoch: 003, batch: 015, loss: 0.042 \n",
      "epoch: 003, batch: 016, loss: 0.013 \n",
      "epoch: 003, batch: 017, loss: 0.100 \n",
      "epoch: 003, batch: 018, loss: 0.477 \n",
      "epoch: 003, batch: 019, loss: 0.093 \n",
      "epoch: 003, batch: 020, loss: 0.046 \n",
      "epoch: 003, batch: 021, loss: 1.728 \n",
      "epoch: 003, batch: 022, loss: 0.025 \n",
      "epoch: 003, batch: 023, loss: 0.035 \n",
      "epoch: 003, batch: 024, loss: 1.224 \n",
      "epoch: 003, batch: 025, loss: 0.121 \n",
      "epoch: 003, batch: 026, loss: 0.095 \n",
      "epoch: 003, batch: 027, loss: 0.044 \n",
      "epoch: 003, batch: 028, loss: 0.031 \n",
      "epoch: 003, batch: 029, loss: 0.008 \n",
      "epoch: 003 ------------------------------------------------\n",
      "\n",
      "[train] loss: 6.076\n",
      "\n",
      "[validation] bulls_recall: 97.196%\n",
      "\n",
      "[validation] no_bulls_recall: 5.854%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5152487741133343\n",
      "\n",
      "epoch: 004, batch: 001, loss: 0.247 \n",
      "epoch: 004, batch: 002, loss: 0.026 \n",
      "epoch: 004, batch: 003, loss: 0.103 \n",
      "epoch: 004, batch: 004, loss: 0.167 \n",
      "epoch: 004, batch: 005, loss: 0.166 \n",
      "epoch: 004, batch: 006, loss: 0.049 \n",
      "epoch: 004, batch: 007, loss: 0.090 \n",
      "epoch: 004, batch: 008, loss: 0.035 \n",
      "epoch: 004, batch: 009, loss: 0.021 \n",
      "epoch: 004, batch: 010, loss: 0.031 \n",
      "epoch: 004, batch: 011, loss: 0.206 \n",
      "epoch: 004, batch: 012, loss: 0.025 \n",
      "epoch: 004, batch: 013, loss: 0.359 \n",
      "epoch: 004, batch: 014, loss: 0.633 \n",
      "epoch: 004, batch: 015, loss: 0.012 \n",
      "epoch: 004, batch: 016, loss: 0.009 \n",
      "epoch: 004, batch: 017, loss: 0.007 \n",
      "epoch: 004, batch: 018, loss: 0.031 \n",
      "epoch: 004, batch: 019, loss: 0.026 \n",
      "epoch: 004, batch: 020, loss: 0.039 \n",
      "epoch: 004, batch: 021, loss: 0.011 \n",
      "epoch: 004, batch: 022, loss: 0.297 \n",
      "epoch: 004, batch: 023, loss: 0.035 \n",
      "epoch: 004, batch: 024, loss: 0.035 \n",
      "epoch: 004, batch: 025, loss: 0.060 \n",
      "epoch: 004, batch: 026, loss: 0.332 \n",
      "epoch: 004, batch: 027, loss: 0.010 \n",
      "epoch: 004, batch: 028, loss: 0.011 \n",
      "epoch: 004, batch: 029, loss: 0.162 \n",
      "epoch: 004 ------------------------------------------------\n",
      "\n",
      "[train] loss: 4.086\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 1.822%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5090940597594443\n",
      "\n",
      "epoch: 005, batch: 001, loss: 0.023 \n",
      "epoch: 005, batch: 002, loss: 2.396 \n",
      "epoch: 005, batch: 003, loss: 0.017 \n",
      "epoch: 005, batch: 004, loss: 0.706 \n",
      "epoch: 005, batch: 005, loss: 0.033 \n",
      "epoch: 005, batch: 006, loss: 0.012 \n",
      "epoch: 005, batch: 007, loss: 0.025 \n",
      "epoch: 005, batch: 008, loss: 0.041 \n",
      "epoch: 005, batch: 009, loss: 0.097 \n",
      "epoch: 005, batch: 010, loss: 0.126 \n",
      "epoch: 005, batch: 011, loss: 0.139 \n",
      "epoch: 005, batch: 012, loss: 0.002 \n",
      "epoch: 005, batch: 013, loss: 0.067 \n",
      "epoch: 005, batch: 014, loss: 0.151 \n",
      "epoch: 005, batch: 015, loss: 0.098 \n",
      "epoch: 005, batch: 016, loss: 0.388 \n",
      "epoch: 005, batch: 017, loss: 0.295 \n",
      "epoch: 005, batch: 018, loss: 0.109 \n",
      "epoch: 005, batch: 019, loss: 0.027 \n",
      "epoch: 005, batch: 020, loss: 0.015 \n",
      "epoch: 005, batch: 021, loss: 0.012 \n",
      "epoch: 005, batch: 022, loss: 0.239 \n",
      "epoch: 005, batch: 023, loss: 0.082 \n",
      "epoch: 005, batch: 024, loss: 0.028 \n",
      "epoch: 005, batch: 025, loss: 0.017 \n",
      "epoch: 005, batch: 026, loss: 0.028 \n",
      "epoch: 005, batch: 027, loss: 0.019 \n",
      "epoch: 005, batch: 028, loss: 0.033 \n",
      "epoch: 005, batch: 029, loss: 0.006 \n",
      "epoch: 005 ------------------------------------------------\n",
      "\n",
      "[train] loss: 3.650\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 6.276%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5313643893492149\n",
      "\n",
      "epoch: 006, batch: 001, loss: 0.026 \n",
      "epoch: 006, batch: 002, loss: 0.007 \n",
      "epoch: 006, batch: 003, loss: 0.014 \n",
      "epoch: 006, batch: 004, loss: 0.025 \n",
      "epoch: 006, batch: 005, loss: 0.093 \n",
      "epoch: 006, batch: 006, loss: 0.031 \n",
      "epoch: 006, batch: 007, loss: 0.009 \n",
      "epoch: 006, batch: 008, loss: 0.029 \n",
      "epoch: 006, batch: 009, loss: 0.202 \n",
      "epoch: 006, batch: 010, loss: 0.048 \n",
      "epoch: 006, batch: 011, loss: 0.021 \n",
      "epoch: 006, batch: 012, loss: 0.007 \n",
      "epoch: 006, batch: 013, loss: 0.378 \n",
      "epoch: 006, batch: 014, loss: 0.063 \n",
      "epoch: 006, batch: 015, loss: 1.643 \n",
      "epoch: 006, batch: 016, loss: 0.071 \n",
      "epoch: 006, batch: 017, loss: 0.172 \n",
      "epoch: 006, batch: 018, loss: 0.336 \n",
      "epoch: 006, batch: 019, loss: 0.039 \n",
      "epoch: 006, batch: 020, loss: 0.196 \n",
      "epoch: 006, batch: 021, loss: 0.070 \n",
      "epoch: 006, batch: 022, loss: 0.021 \n",
      "epoch: 006, batch: 023, loss: 0.192 \n",
      "epoch: 006, batch: 024, loss: 0.061 \n",
      "epoch: 006, batch: 025, loss: 0.255 \n",
      "epoch: 006, batch: 026, loss: 0.703 \n",
      "epoch: 006, batch: 027, loss: 0.132 \n",
      "epoch: 006, batch: 028, loss: 0.052 \n",
      "epoch: 006, batch: 029, loss: 0.002 \n",
      "epoch: 006 ------------------------------------------------\n",
      "\n",
      "[train] loss: 5.779\n",
      "\n",
      "[validation] bulls_recall: 86.552%\n",
      "\n",
      "[validation] no_bulls_recall: 8.497%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.47524677795047443\n",
      "\n",
      "\n",
      "Final nb epochs : 1\n",
      "Best validation score (= best bulls_fscore) : 0.7102770778848639\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows : real (no_bulls and bulls)  ;  columns : predicted (same) ): \n",
      "263  |  91\n",
      "3384  |  5428\n",
      "\n",
      "[test] accuracy: 62.088%\n",
      "\n",
      "\n",
      "[test] bulls_recall: 74.292%\n",
      "\n",
      "[test] bulls_precision: 7.211%\n",
      "\n",
      "\n",
      "[test] no_bulls_recall: 61.598%\n",
      "\n",
      "[test] no_bulls_precision: 98.351%\n",
      "\n",
      "\n",
      "[test] scoring metric (average recall): 0.6794471896318366\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model_vgg16_norm(pretrained=True, freeze=False)\n",
    "name_model = \"model_vgg16simple_norm_pretrained_batchsize1024_recov\"\n",
    "batch_size = 1024\n",
    "trainloader, validationloader, testloader, weight_bulls, weight_no_bulls = audio_importation(shuffle=True)\n",
    "epochs = 20\n",
    "\n",
    "final_model = training(model=model, name_model=name_model, epochs=epochs, batch_size=batch_size, device=device)\n",
    "\n",
    "test(model=final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001, batch: 001, loss: 0.642 \n",
      "epoch: 001, batch: 002, loss: 0.302 \n",
      "epoch: 001, batch: 003, loss: 0.153 \n",
      "epoch: 001, batch: 004, loss: 0.272 \n",
      "epoch: 001 ------------------------------------------------\n",
      "\n",
      "[train] loss: 2.033\n",
      "\n",
      "[validation] bulls_recall: 5.322%\n",
      "\n",
      "[validation] no_bulls_recall: 91.025%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.4817354624439042\n",
      "\n",
      "epoch: 002, batch: 001, loss: 0.383 \n",
      "epoch: 002, batch: 002, loss: 1.580 \n",
      "epoch: 002, batch: 003, loss: 0.673 \n",
      "epoch: 002, batch: 004, loss: 0.284 \n",
      "epoch: 002 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.721\n",
      "\n",
      "[validation] bulls_recall: 15.126%\n",
      "\n",
      "[validation] no_bulls_recall: 87.537%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5133150850297674\n",
      "\n",
      "epoch: 003, batch: 001, loss: 0.313 \n",
      "epoch: 003, batch: 002, loss: 0.754 \n",
      "epoch: 003, batch: 003, loss: 0.131 \n",
      "epoch: 003, batch: 004, loss: 0.189 \n",
      "epoch: 003 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.500\n",
      "\n",
      "[validation] bulls_recall: 94.675%\n",
      "\n",
      "[validation] no_bulls_recall: 37.043%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.6585919292789613\n",
      "\n",
      "epoch: 004, batch: 001, loss: 0.096 \n",
      "epoch: 004, batch: 002, loss: 0.188 \n",
      "epoch: 004, batch: 003, loss: 0.592 \n",
      "epoch: 004, batch: 004, loss: 0.532 \n",
      "epoch: 004 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.278\n",
      "\n",
      "[validation] bulls_recall: 95.235%\n",
      "\n",
      "[validation] no_bulls_recall: 29.857%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.6254605442227364\n",
      "\n",
      "epoch: 005, batch: 001, loss: 0.055 \n",
      "epoch: 005, batch: 002, loss: 0.581 \n",
      "epoch: 005, batch: 003, loss: 0.256 \n",
      "epoch: 005, batch: 004, loss: 0.101 \n",
      "epoch: 005 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.044\n",
      "\n",
      "[validation] bulls_recall: 92.154%\n",
      "\n",
      "[validation] no_bulls_recall: 34.511%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.6333248085479716\n",
      "\n",
      "epoch: 006, batch: 001, loss: 0.149 \n",
      "epoch: 006, batch: 002, loss: 0.009 \n",
      "epoch: 006, batch: 003, loss: 0.155 \n",
      "epoch: 006, batch: 004, loss: 0.418 \n",
      "epoch: 006 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.279\n",
      "\n",
      "[validation] bulls_recall: 99.997%\n",
      "\n",
      "[validation] no_bulls_recall: 5.254%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5262549870493174\n",
      "\n",
      "epoch: 007, batch: 001, loss: 0.283 \n",
      "epoch: 007, batch: 002, loss: 0.103 \n",
      "epoch: 007, batch: 003, loss: 0.181 \n",
      "epoch: 007, batch: 004, loss: 0.119 \n",
      "epoch: 007 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.140\n",
      "\n",
      "[validation] bulls_recall: 68.906%\n",
      "\n",
      "[validation] no_bulls_recall: 92.713%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.8080953492298405\n",
      "\n",
      "epoch: 008, batch: 001, loss: 0.111 \n",
      "epoch: 008, batch: 002, loss: 0.101 \n",
      "epoch: 008, batch: 003, loss: 0.303 \n",
      "epoch: 008, batch: 004, loss: 0.076 \n",
      "epoch: 008 ------------------------------------------------\n",
      "\n",
      "[train] loss: 1.144\n",
      "\n",
      "[validation] bulls_recall: 95.796%\n",
      "\n",
      "[validation] no_bulls_recall: 28.413%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.6210417786126746\n",
      "\n",
      "epoch: 009, batch: 001, loss: 0.334 \n",
      "epoch: 009, batch: 002, loss: 0.226 \n",
      "epoch: 009, batch: 003, loss: 0.173 \n",
      "epoch: 009, batch: 004, loss: 0.047 \n",
      "epoch: 009 ------------------------------------------------\n",
      "\n",
      "[train] loss: 0.907\n",
      "\n",
      "[validation] bulls_recall: 95.516%\n",
      "\n",
      "[validation] no_bulls_recall: 21.459%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5848751071869538\n",
      "\n",
      "epoch: 010, batch: 001, loss: 0.016 \n",
      "epoch: 010, batch: 002, loss: 2.803 \n",
      "epoch: 010, batch: 003, loss: 0.178 \n",
      "epoch: 010, batch: 004, loss: 0.020 \n",
      "epoch: 010 ------------------------------------------------\n",
      "\n",
      "[train] loss: 0.850\n",
      "\n",
      "[validation] bulls_recall: 99.157%\n",
      "\n",
      "[validation] no_bulls_recall: 17.983%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5856988048905243\n",
      "\n",
      "epoch: 011, batch: 001, loss: 0.127 \n",
      "epoch: 011, batch: 002, loss: 0.094 \n",
      "epoch: 011, batch: 003, loss: 0.071 \n",
      "epoch: 011, batch: 004, loss: 0.015 \n",
      "epoch: 011 ------------------------------------------------\n",
      "\n",
      "[train] loss: 0.736\n",
      "\n",
      "[validation] bulls_recall: 99.717%\n",
      "\n",
      "[validation] no_bulls_recall: 9.141%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5442924095877264\n",
      "\n",
      "epoch: 012, batch: 001, loss: 0.067 \n",
      "epoch: 012, batch: 002, loss: 0.170 \n",
      "epoch: 012, batch: 003, loss: 0.137 \n",
      "epoch: 012, batch: 004, loss: 0.000 \n",
      "epoch: 012 ------------------------------------------------\n",
      "\n",
      "[train] loss: 0.691\n",
      "\n",
      "[validation] bulls_recall: 99.717%\n",
      "\n",
      "[validation] no_bulls_recall: 8.853%\n",
      "\n",
      "[validation] scoring metric (average recall): 0.5428484480681902\n",
      "\n",
      "\n",
      "Final nb epochs : 7\n",
      "Best validation score (= best bulls_fscore) : 0.8080953492298405\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows : real (no_bulls and bulls)  ;  columns : predicted (same) ): \n",
      "240  |  114\n",
      "402  |  8410\n",
      "\n",
      "[test] accuracy: 94.370%\n",
      "\n",
      "\n",
      "[test] bulls_recall: 67.795%\n",
      "\n",
      "[test] bulls_precision: 37.383%\n",
      "\n",
      "\n",
      "[test] no_bulls_recall: 95.438%\n",
      "\n",
      "[test] no_bulls_precision: 98.662%\n",
      "\n",
      "\n",
      "[test] scoring metric (average recall): 0.816163128991405\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model_vgg16_norm(pretrained=True, freeze=False)\n",
    "name_model = \"model_vgg16simple_norm_pretrained_batchsize8192_recov\"\n",
    "batch_size = 8192\n",
    "trainloader, validationloader, testloader, weight_bulls, weight_no_bulls = audio_importation(shuffle=True)\n",
    "epochs = 20\n",
    "\n",
    "final_model = training(model=model, name_model=name_model, epochs=epochs, batch_size=batch_size, device=device)\n",
    "\n",
    "test(model=final_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
